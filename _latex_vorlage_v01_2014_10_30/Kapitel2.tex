\section{Theoretische Grundlagen}\label{Kapitel:Theoretische Grundlagen}
Um das in Abschnitt~\ref{sec2:Zielstellung} erwähnte Ziel zu erreichen, sollten zunächst die theoretische Grundlagen geschaffen werden, bevor die praktische Umsetzung bzw. Implementierung stattfindet. Im Folgenden werden Theorien zur Umfeldmodellierung vorgestellt. Offensichtlich erfordert die Umfeldmodellierung die Wahrnehmung der Umgebung, weshalb als nächstes das Sensorsystem für die Umgebungswahrnehmung erörtert wird.
\subsection{Umfeldmodellierung}
Für Perzeption eines autonomen Fahrzeuges gibt es im wesentlichen zwei Bestandteilen \citep{Badue.2019}. Zum einen ist die Eigenlokalisierung. Die aktuelle Pose, das heißt die Position und Orientierung des eigenen Fahrzuges, ist hierbei zu ermitteln. Zum anderen ist die Umgebung um das Fahrzeug zu erfassen. Dies wird als Umfeldmodellierung genannt. Diese beiden Aspekte werden in vielen Forschungen und Anwendungen zu einem Problem zusammengefasst. Dies ist als SLAM (Simultaneous Localization And Mapping) bekannt. Jedoch trennen sich diese beiden Aspekte im Rahmen dieser Arbeit und die Aufmerksamkeit ist auf Umfeldmodellierung zu lenken. Hierbei wird eine Annahme getroffen, dass die Eigenpose des Fahrzeugs selbst ohne Information der Umfeldmodell ausreichend präzis ist. Das am IfF (Institut für Fahrzeugtechnik) bereits bestehende Framwork verwendet bestimmte Algorithmen wie das Kalman-Filter, um genaue GPS-Informationen des Fahrzeugs zu erhalten.
\\In Bezug auf Robotik und autonomes Fahren dient Umfeldmodellierung als ein kompaktes Verfahren, mit dem die Umgebung des Fahrzeugs mathematisch beschrieben werden kann~\citep{Pieringer.2013}. Dies hat eine unverzichtbare solide Grundlage für das Design und die anschließende Implementierung aller fortschrittlichen autonomen Fahrfunktionen gelegt.
\subsubsection{Mögliche Umfeldmodelle} 
Die zur Modellierung der Umgebung verwendeten Methoden basieren auf verschiedenen entsprechenden Umfeldmodellen. Die maßgebliche Umfeldmodelle bauen auf erfolgreichen Erfahrungen in dem Themenbereich der Robotik auf~\citep{Pieringer.2013}. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/Umfeldmodelle_Klassen.pdf}
	\caption{Mögliche Umfeldmodelle für autonome Fahrzeuge}
	\label{fig:Umfeldmodelle_Klassen}
\end{figure}
Wie in Abbildung~\ref{fig:Umfeldmodelle_Klassen} dargestellt, stehen aktuell drei Hauptumweltmodelle in der Forschungs- und Automobilindustrie zur Verfügung~\citep{Hegerhorst.2018}. Sie sind objektbasierte Umfeldmodelle, gitterbasierte Umfeldmodelle und hybride Umfeldmodelle. In den folgenden Abschnitten werden sie vorgestellt.
\subsubsection{Objektbasierte Modelle}
Objektbasierte Modelle werden auch als merkmalsbasierte Umfeldmodelle (engl. landmark-based oder feature map) bezeichnet~\citep{Thrun.2005}. Hierbei werden die Merkmalen, die für Erfassung der Umgebung günstig sind, durch Modelle beschrieben werden~\citep{Wurm.2010}. Außerdem sollten die Merkmalen zuverlässig beobachtet und gemessen werden~\citep{Buschka.2005}. Die Modelle werden im Praxis als bestimmte Objektklasse beschrieben. Jede Klasse wird mit hervorragenden und maßgeblichen Eingenschaften versehen, die deutlich mittels zutreffenden Sensoren beobachtbar sind~\citep{Winner.2015}. Für die Klassen lassen sich darüber hinaus die zu Objekt passende Geometrieformen bestimmen~\citep{Pieringer.2013}. Daher ist die Performance des Modells abhängig davon, ob die zu modellierten Objekte ausreichend präzis und einfach beschrieben werden können. Hierbei sind die Genauigkeit gegen der Zeit- und Speicheraufwand abzuwägen. Ein Beispiel ist das in Abblidung~\ref{fig:FeatureMap} gezeigte Umfeldmodell. Auf der linken Seite sind Merkmale dargestellt und das Bild rechts zeigt das generierte Umfeldmodell.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/FeatureMap.pdf}
	\caption{Ein objektbasiertes Umfeldmodell~\citep{FawadAhmad.2020}}
	\label{fig:FeatureMap}
\end{figure}
\\Objektbasierte Umfeldmodelle sind vor allem geeignet für Szenen, wo die Objekte entweder im großen offenen Raum mit vordefinierten Merkmalen (z.B. Autobahn) oder dynamisch und einfach modelliert (z.B. Fußgänger oder Fahrzeuge) sind~\citep{Hegerhorst.2018}~\citep{Wurm.2010}. Da es im Rahmen dieser Arbeit ein statisches Umfeld im urbanen Raum angeht, ist dieses Modell unangemessen und sollte daher verzichtet werden.  
\subsubsection{Gitterbasierte Modelle}
\label{Abschnitt:Gitterbasierte Modelle}
In gitterbasierten Modellen wird die zentrale Idee der probabilistischen Robotik eingeführt, um die Wahrscheinlichkeitsverteilung unbeobachteter Zustände eines Systems mit gegebenen Beobachtungen und Messungen zu abschätzen. Zur Modellierung des Umfelds ist der zentrale und entscheidende Zustand der sogenannte Belegungszustand. Der Belegungszustand erweist sich, ob eine Gitterzelle belegt ist. Daraus ergibt sich eine Zufallsvariable X, den Belegungszustand repräsentiert. Die Variable X kann zwei Werte annehmen, welche 0 und 1 sind. Die entsprechen dabei, dass die Gitterzelle frei und belegt ist.
\\Das Modell, welches auf der obenerwähnten Idee aufbaut, wird als Occupancy Grid beschrieben. Das Occupancy Grid ist ein mehrdimensionales Zufallsfeld, das zum Speichern einer stochastischen Schätzung des Belegungszustands jeder Zelle im räumlichen Gitter verwendet wird~\citep{Elfes.1989}. Wie in Abbildung~\ref{fig:EbeneVonOccupancyGrid} gezeigt, lässt sich Occupancy Grid in zwei Ebenen zerlegen.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Ebene von Occupancy Grid.pdf}
	\caption{Zwei Ebenen von Occupancy Grid}
	\label{fig:EbeneVonOccupancyGrid}
\end{figure}
\\Auf der ersten Ebene wird die Raumdiskretisierung ausgeführt. Im Rahmen dieser Arbeit wird das Umfeld als zweidimensionaler Raum dargestellt. Die Diskretisierung des Raums bedeutet hierbei, dass die Fahrzeugumgebung durch ein Raster diskreter und fester Größe dargestellt wird~\citep{Hegerhorst.2018}. Die grafische Darstellung ist in Abbildung~\ref{fig:Raumdiskretisierung} gezeigt. Zu jeder Zelle wird außerdem zusätzliche Informationen hinzugefügt. In Hinsicht auf Umfeldmodellierung ist die entscheidende Information der Belegungszustand der Zelle. Zur Vereinfachung der Modellierung, wird eine Annahme auf dieser Ebene zugleich getroffen, dass der Belegungszustand einer Gitterzelle ist unabhängig von diejenige der Nachbarzellen. Obwohl diese Annahme mit der Realität unvereinbar zu sein scheint, ist es erwiesen, dass Occupancy Grid Modell in der Praxis unter dieser Annahme robust ist und zudem die Rechenkomplexität reduzieren kann~\citep{Thrun.2005}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Raumdiskretisierung.pdf}
	\caption{Raumdiskretisierung der Umgebung um Fahrzeug \citep{Winner.2015}}
	\label{fig:Raumdiskretisierung}
\end{figure}
\\Auf der zweiten Ebene ist der probabilistische Ansatz eingeführt, welcher aus dem Themengebiet von Robotik stammt~\citep{Pieringer.2013}. Der Ansatz beruht auf Raumdiskretisierung und wird in der Praxis für jede einzelne Zelle eingesetzt. Der Ansatz lässt sich, wie in Abbildung~\ref{fig:OccupancyGrid} gezeigt, in viele Komponenten unterteilen. Im Zentrum des Modells steht ein Algorithmus-Framework, das als binärer Bayes-Filter oder der binäre Bayessche Filter (engl. Binary Bayes Filter) bekanntlich ist. Die Eingaben des Frameworks umfassen Messungswerte, inverses Sensormodell und Anfangsbedienungen. Die Ausgabe ist A-posteriori-Wahrscheinlichkeit von dem Zufallsereignis, die Möglichkeit repräsentiert, dass eine Zelle als besetzt betrachtet wird. Um die Konzept von Occupancy Grid zu verdeutlichen, wird im Folgenden auf jede Komponente vertieft eingegangen.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/OccupancyGrid.pdf}
	\caption{Bestandteile des Modells Ocuupancy Grid}
	\label{fig:OccupancyGrid}
\end{figure}
\\Der Bayessche Filter ist zuerst zu beleuchten, mit dem die Funktionen und Bedeutungen der anderen Bestandteilen des Modells eng verbunden sind. Der Bayes-Filter ist eine rekursive Berechnungsvorschrift zur Schätzung von Wahrscheinlichkeitsverteilungen unbeobachteter Zustände eines Systems mit gegebenen Beobachtungen und Messungen~\citep{Thrun.2005}. Die Zustandsschätzung befasst sich mit dem Problem der Schätzung von Größen, die nicht direkt beobachtbar sind, sondern abgeleitet aus den Sensordaten werden können. Das Ziel ist den Zustand $x$ eines Systems zu schätzen\footnote{Präzis sollte die Formel $X=x$ verwendet, um den Zustand zu beschreiben, wobei X eine Zufallsvariable ist und x ist der spezifische Wert, den X in Echtzeit annimmt. Zur Vereinfachung der Notation wird die Formel $X=x$ im Rahmen dieser Arbeit sowie in vielen Literaturen als $x$ bezeichnet.}, wenn Beobachtung $z$ und Kontrolle u angegeben sind. Das heißt, die in Gleichung~\ref{Gleichung:Zustandschaetzung} gezeigte mathematische Formel sollte bestimmt werden. Hierbei entspricht $x_t$ dem Zustand zum Zeitpunkt t. $z_{1:t}$ bezeichnet die Beobachtungen bzw. die Messgrößen von den Zuständen, die sich von Zeitstempel 1 bis t erstrecken. Zudem gibt $u_{1:t}$ die Kontrollen an, die sich von Zeitstempel 1 bis t erstrecken. Die linke Seite der Gleichung $bel_(x_t)$ verkörpert den Glauben (engl. belief) der Wahrheit, dass der Zustand $x_t$ ist~\citep{Thrun.2005}.
\begin{equation}\label{Gleichung:Zustandschaetzung}
	bel(x_t)=p(x_{t}|z_{1:t},u_{1:t})
\end{equation}
Um die Wahrscheinlichkeitsverteilung einzugehen und eine rekursive Form zu entdecken, wird der stochastische Prozess von Zustandsänderung als Hidden Markov Model (HMM) betrachtet, das auch als dynamic Bayes network (DBN) bezeichnet wird. Unter Anwendung dieser Annahme gilt: Die Wahrscheinlichkeit eines Zustands bei dem Zeitstempel $t$ ist einschließlich abhängig von Zustand bei dem Zeitstempel $t-1$ und nicht von Zuständen bei den Zeitstempeln, die früher als $t-1$ sind. Mathematisch wird HMM als eine Gleichung in~\ref{Gleichung:HMM} beschrieben.
\begin{equation}\label{Gleichung:HMM}
 	p(x_{t}|x_{1:t})=p(x_t|x_{t-1}) 
\end{equation}
Außerdem beschreibt Hidden Markov Model, wie in Abbildung~\ref{fig:HiddeMarkovModel} dargestellt, die vereinfachte Zusammenhang zwischen dem Zustand $x$, der Messgröße $z$ und der Kontrolle $u$. Der Zustand zum Zeitpunkt $t$ ist abhängig von dem Zustand zum Zeitpunkt $t-1$ und der Kontrolle $u_t$. Die Messgröße $z_t$ hängt stochastisch vom Zustand zum Zeitpunkt $t$ ab.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/HMM.pdf}
	\caption{Hidden Markov Model (HMM) \citep{Thrun.2005}}
	\label{fig:HiddeMarkovModel}
\end{figure}
Zusätzlich wird unter Anwendung des Satzes von Bayes und des Gesetzes der totalen Wahrscheinlichkeit wird die Formel~\ref{Gleichung:Zustandschaetzung} in einen rekursiven Ausdruck abgeleitet, was als Bayes-Filter bekanntlich ist. Die Ableitung findet sich in~\citep{Thrun.2005} und wird hier weggelassen. Der daraus resultierte Algorithmus befinden sich in Tabelle~\ref{tab:AlgorithmBF}.
\begin{table}[ht]
	\caption{Der Algorithmus des Bayes-Filters~\cite{Thrun.2005}}
	\small
	\centering
	\label{tab:AlgorithmBF}
	\begin{tabular}{ll}
		\toprule
		\textbf{Algorithm Bayes Filter($bel(x_{t-1}),u_t,z_t$):}\\
		for all $x_t$ do\\
		~~~~$\overline{bel}(x_t)=\int{p(x_t|u_t,x_{t-1})bel(x_{t-1})dx_{t-1}}$\\ 	
		~~~~$bel(x_t)=\eta p(z_t|x_t)\overline{bel(x_t)}$\\	
		endfor\\
		return $bel(x_t)$\\		
		\toprule
	\end{tabular}
\end{table}
Der Algorithmus besteht aus 2 Schritten, die als Prädiktion (engl. prediction) und Korrektur (engl. Correction oder update) bekanntlich sind. Der erste Schritt wird dadurch ausführt, dass der Glauben bzw. die Wahrscheinlichkeitsverteilung über den Zustand $x_t$ - basierend auf dem vorherigen Glauben über den Zustand $x_{t-1}$ und Kontrolle $u_t$ - berechnet werden sollte. Der zweite Schritt ist eine Korrektur bzw. ein Update des prognostizierte Glaubens, indem die beobachte Informationen des Zustands bzw. die Messgrößen der Sensoren fusioniert und berüchtigt werden. Der Wert $bel(x_t)$ wird als A-posteriori-Verteilung bezeichnet. Im Gegensatz zu A-priori-Verteilung verkörpert A-posteriori-Verteilung den theoretisch präziseren Glauben, nachdem die Messgrößen von Sensoren durch ein Sensormodell zur Genauigkeit des Glaubens beitragen. Dieser Algorithmus bildet eine Grundlage, auf der viele weitere Algorithmen für bestimmte Szenarien entwickelt werden. Dazu gehören bekannte Gauß-Filter mit ihren Varianten, Particle-Filter und der diskrete Bayes-Filter. Der binäre Bayes-Filter, der in dieser Arbeit eine große Rolle spielt, ist ein spezieller Fall des Bayes-Filters bzw. des diskreten Bayes-Filter.
\\Der binäre Bayes-Filter, der durch den grundlegenden Bayes-Filter eingeführt wird, erfordert eine Annahme. Es wird angenommen, dass der Zustand einschließlich zwei Möglichkeiten besitzen. Das heißt, die Zufallsvariable, die den Zustand repräsentiert, kann nur zwei Werte annehmen. Bei Occupancy Grid kann der wichtigste und auch einzige Zustand der Belegungszustand sein, der lediglich zwei Fälle - belegt oder frei - hat. Aus diesem Grund ist der binäre Bayes-Filter dafür zutreffend. Darüber hinaus wird eine weitere Annahme getroffen, dass der Belegungszustand bei Occupancy Grid statisch ist. Dies bedeutet, dass sich der Belegungszustand im Laufe der Zeit nicht ändert und die Kontrolle $u$ hat keine Auswirkung auf den Belegungszustand. Somit wird das Schema des stochastischen Prozesses der Zustandsveränderung von Abbildung~\ref{fig:HiddeMarkovModel} nach Abbildung~\ref{fig:reducedHMM} vereinfacht, indem die Kontrollen ausgeklammert werden. Nach diesen beiden Annahmen ist klar, dass der Algorithmus des Bayes-Filters in Occupancy Grid den Schritt Prädiktion nicht mehr enthält. Die A-posteriori-Verteilung der Zustand $bel(x_t)$ ist einschließlich berechnet mit Informationen von Messdaten und dem vorherigen Zustand $bel(x_{t-1})$.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/reducedHMM.pdf}
	\caption{Das reduzierte HMM \citep{Thrun.2005}}
	\label{fig:reducedHMM}
\end{figure}
\\Anhand der Vereinfachung des Modells sollte der grundlegende Bayes-Filter entsprechend vereinfacht werden. Außerdem sollte der vereinfachte Algorithmus ein inverses Sensormodell verwenden. Das inverse Sensormodell gibt anstatt $p(z_t|x)$ eine Verteilung über die binäre Zustandsvariable als Funktion der Messung $p(x|z_t)$ an \citep{Thrun.2005}. Ein Grund für die Verwendung des inversen Sensormodells ist die Leichtigkeit, eine Funktion zu entwickeln, die die Wahrscheinlichkeitsverteilung von Sensordaten berechnet. Es ist zum Beispiel relativ simpel ein Modell zu entwerfen, womit die Wahrscheinlichkeit des Belegungszustands einer Zelle oder mehrerer Zellen anhand der Sensordaten bestimmt werden kann. Ein Vorwärtssensormodell ist dagegen in diesem Fall erstaunlich schwierig. Mit dem Ziel, einen vereinfachten Algorithmus zu finden, der unter Verwendung eines inversen Sensormodells das Glauben $bel(x_t)$ berechnen kann, sollte die mathematische Ableitung nach ~\citep{Thrun.2005}~\cite{Weiss.1306200715062007}~\citep{Hegerhorst.2018} folgend vorgestellt.
\\Da der Belegungszustand statisch ist und die Kontrolle $u$ somit ignoriert wird, kann die Gleichung~\ref{Gleichung:Zustandschaetzung} in eine vereinfachte Gleichung~\ref{Gleichung:Glauben} umgewandelt werden.
\begin{equation}
	\label{Gleichung:Glauben}
	bel(x_t)=p(x_t|z_{1:t},u_{1:t})=p(x_t|z_{1:t})
\end{equation}
Bei Occuancy Grid ist der interessierende Zustand der Belegungszustand. Zur Vereinfachung der Notation wird das Glauben, dass die Zelle i des Gitters zum Zeitpunkt t belegt ist, als Gleichung~\ref{Gleichung:Glauben_belegt} bezeichnet.
\begin{equation}
	\label{Gleichung:Glauben_belegt}
	bel_t(m_i)=p(m_i|z_{1:t})
\end{equation}
Analog dafür ergibt sich das Glauben, dass die Zelle i des Gitters zum Zeitpunkt t frei ist, aus Gleichung ~\ref{Gleichung:Glauben_frei}.
\begin{equation}
	\label{Gleichung:Glauben_frei}
	bel_t(\overline{m_i})=p(\overline{m_i}|z_{1:t})
\end{equation}
Mit Hilfe des bedingten Satzes der Bayes ergibt sich die Gleichung~\ref{Gleichung:Glauben_belegt} zu
\begin{equation}
	\label{Gleichung:Ableitung_01}
	bel_t(m_i)=p(m_i|z_{1:t})=\frac{p(z_t|m_i,z_{1:t-1})p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}
\end{equation}
Unter Annahme eines Hidden-Markov-Modells wird die Gleichung~\ref{Gleichung:Ableitung_01} zu
\begin{equation}
	\label{Gleichung:Ableitung_02}
	bel_t(m_i)=\frac{p(z_t|m_i,z_{1:t-1})p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(z_t|m_i)p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}
\end{equation}
Zur Wahrscheinlichkeit $p(z_t|m_i)$ wird der Satz des Bayes wiederum eingesetzt, womit die Gleichung~\ref{Gleichung:Ableitung_02} wird zu
\begin{equation}
	\label{Gleichung:Ableitung_03}
	bel_t(m_i)=\frac{p(z_t|m_i)p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(m_i|z_t)p(z_t)p(m_i|z_{1:t-1})}{p(m_i)p(z_t|z_{1:t-1})}
\end{equation}
Analog dazu hat der gegenteilige Zustand den Glauben
\begin{equation}
	\label{Gleichung:Ableitung_04}
	bel_t(\overline{m_i})=1-bel_t(m_i)=\frac{p(z_t|\overline{m_i})p(\overline{m_i}|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(\overline{m_i}|z_t)p(z_t)p(\overline{m_i}|z_{1:t-1})}{p(\overline{m_i})p(z_t|z_{1:t-1})}
\end{equation}
Dividiert Gleichung~\ref{Gleichung:Ableitung_03} durch der Gleichung~\ref{Gleichung:Ableitung_04}, so ergibt sich
\begin{equation}
	\label{Gleichung:Ableitung_05}
	\frac{bel_t(m_i)}{1-bel_t(m_i)}=\frac{p(m_i|z_t)}{1-p(m_i|z_t)}\frac{p(m_i|z_{1:t-1})}{1-p(m_i|z_{1:t-1})}\frac{1-p(m_i)}{p(m_i)}
\end{equation}
Die Gleichung~\ref{Gleichung:Ableitung_05} bietet eine perfekte mathematische Darstellung bzw. Erklärung an, was die Angaben und die Ausgabe des binären Bayes-Filters sind. Die Ausgabe ist das Glauben bzw. die A-posteriori-Wahrscheinlichkeit des Ereignisses, dass die Zelle $m_i$ belegt ist, welches den Term $bel_t(m_i)$ in Gleichung~\ref{Gleichung:Ableitung_05} entspricht. Der Term ${p(m_i|z_t)}$ ist, wie oben erzählt, das inverse Sensormodell. Es ist ersichtlich, dass eine bedeutende Beziehung zwischen dem Sensormodell bzw. der Beschreibung des Sensormodells und dem Sensortyp. Darauf wird in Abschnitt~\ref{Abschnitt:Sensor} mit der Erfassung der Umgebung vertieft eingegangen. Der Term $p(m_i|z_{1:t-1})$ beweist dabei das wichtige Merkmal des binären Bayes-Filters, dass das Verfahren der Schätzung auf Rekursion beruht. Die Anfangsbedingung bzw. die A-priori-Wahrscheinlichkeit wird als Term $p(m_i)$ in Gleichung~\ref{Gleichung:Ableitung_05} bezeichnet. Die A-priori-Wahrscheinlichkeit gibt den Glauben an, vordem alle Messdaten von Sensorik berücksichtigt werden. Typischerweise wird bei Occupancy Grid anfänglich $p_(m_i)$ ein Wert von 0,5 angegeben, weil es zu Beginn keine Information über den Belegungszustand gibt. Die Wahrscheinlichkeit, dass eine Gitterzelle belegt ist, ist die gleiche wie die Wahrscheinlichkeit, dass sie nicht belegt ist. Daher wird die Gleichung~\ref{Gleichung:Ableitung_05} zu
\begin{equation}
	\label{Gleichung:Ableitung_06}
	bel_t(m_i)=\frac{Y}{Y+1}
\end{equation}
mit
\begin{equation*}
	\label{Gleichung:Ableitung_07}
	Y=\frac{p(m_i|z_t)}{1-p(m_i|z_t)}\frac{p(m_i|z_{1:t-1})}{1-p(m_i|z_{1:t-1})}
\end{equation*}
Zusammenfassend ist das gitterbasierte Modell eignet für eine statische Umgebung im urbanen Raum. Außerdem bietet das Modell einen Vorteil, einen Freiraum neben belegten Objekten zu modellieren, was eine Grundlage der darauffolgenden Navigation schaffen.
\subsubsection{Hybride Umfeldmodelle}
Um ein Umfeld zu modellieren, welches komplizierte Szenarien repräsentieren kann, werden selbstverständlich Hybride Umfeldmodelle aufgefordert. Dadurch werden die Einschränkungen der beiden vorherigen Basismodelle eliminiert und ihre Vorteilen ausgenutzt. Es gibt unterschiedliche Kriterien und Methoden zum Erstellen eines hybriden Umfeldmodells. Das~\cite{.0612201908122019} betreffende Modell, ist ein beliebtes Beispiel von hybriden Umfeldmodellen. Im Prinzip ist das Modell eine Kombination von einem objektbasierten Umfeldmodell und einem gitterbasierten Umfeldmodell. Hierbei beschreibt das objektbasierte Umfeldmodell dynamische Objekte, wohingegen das gitterbasierten Umfeldmodell bzw. Occupancy Grid den statischen Raum darstellen. Auf diese Weise ist das fusionierte Modell generell in der Lage eine Umgebung, wo sich dynamische und statischen Objekte befinden, vollständig und zutreffend zu beschreiben. Darüber hinaus kann die objektbasierte Umfeldmodellierung mit aktueller Technik z.B. Deep-Learning präziser und effizienter durchgeführt werden, während die semantische Navigation weiterhin direkt im gitterbasierten Umfeldmodell verlaufen kann\cite{.0612201908122019}. Da das Umfeld im Rahmen dieser Arbeit als statische Umgebung betrachtet wird, wird ein Hybrides Umfeldmodell aufgrund seiner Komplexität und Redundanz nicht verwendet.
\subsection{Sensorik und ihr inverses Sensormodell}
\label{Abschnitt:Sensor}
Zweifellos dient Wahrnehmung bzw. Erfassung als eine wichtige Voraussetzung für Umfeldmodelleirung, weil sie die Informationsquelle bietet. Die Wahrnehmung eines Fahrzeugs umfasst im Wesentlichen die Bestimmung der eigenen Position samt Orientierung und die Abtastung der Umgebung um das Fahrzeug. Die Eingenlokalisierung ist im Rahmen dieser Arbeit nebensächlich und durch die vorgegebene GPS-Information bestimmt. Darauf soll in dieser Arbeit nicht näher eingegangen werden. In diesem Abschnitt liegt der Schwerpunkt auf den Sensoren, mit denen die Umgebung modelliert wird. Darüber hinaus werden die von IfF-Versuchsfahrzeug verwendeten Laserscanner und das in Abschnitt~\ref{Abschnitt:Gitterbasierte Modelle} erwähnte inverse Sensormodell erläutert.
\subsubsection{Überblick über die verschiedenen Sensoren zur Umfeldmodellierung}
Um ein zuverlässiges Umfeldmodell zu entwickeln und das Modell danach in der Praxis effektiv umzusetzen, spielt die Auswahl der erfassenden Sensoren entweder in der Akademie oder in der Industrie eine große Rolle. Die wichtigsten und am weitesten verbreiteten Fahrzeugsensoren zur Wahrnehmung der Umgebung sind Kameras, fernes Infrarot- (engl.Far-infrared, als FIR abgekürzt) Radar-, LiDAR (Light Detection and Ranging)- und Ultraschallsensoren. Nach~\citep{Mohammed.2020} sind die Vorteilen neben der Nachteilen in Tabelle~\ref{tab:Vergleich der Sensoren} aufgelistet.
\\Es ist erwähnenswert, dass Kameras aufgrund ihrer niedrigen Preise akademisch und industriell beliebt sind. Es wird häufig verwendet, um objektbasierte Umfeldmodelle mithilfe von Computer Vision zu erstellen. Immer mehr Algorithmen werden entwickelt, um die Tiefeninformation von Bildern zu berechnen. Obwohl die Erkennungsqualität begrenzt ist, wurde aus historischen Gründen eine große Anzahl von Radargeräten an Testfahrzeugen angebracht, sodass die Radar-basierte Forschung und Entwicklung noch nicht abgeschlossen ist. Der Preis von LiDAR-Senor ist relativ hoch, aber sein absoluter Vorteil liegt in der Genauigkeit und Auflösung von Tiefeninformationen und Positionsinformationen, und es eignet sich für die Erstellung von Occupancy Grid.
\\Im Rahmen dieser Arbeit ist die am IfF bereits bestehende Fahrzeugarchitektur mit Ibeo-LUX-Laserscanner versehen. Daher werden folgend in Abschnitt~\ref{Abschnitt:Laserscanner} der Mechanismus des Laserscanners und das daraus resultierende Sensormodell erläutert. Außerdem werden die technische Details bei Einführung der inversen Sensormodellierung vorgestellt, weil die realen technischen Größen dabei ein wichtiger Faktor sind.
\begin{longtable}[htbp]{|m{0.15\textwidth}<{\centering}|m{0.4\textwidth}<{\centering}|m{0.4\textwidth}<{\centering}|}
	\caption{Vorteile und Nachteile von Kamera, fernes Infrarotsensor,  Radar-, Ultraschall- und Lidarsensor~\citep{Mohammed.2020}}
	\centering
	\label{tab:Vergleich der Sensoren}
	\endfirsthead
	\endhead
	\hline	
	\textbf{Sensor} & \textbf{Vorteile} & \textbf{Nachteile}\\ \hline
	Kamera& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine hohe Auflösung und Farbskalen über das gesamte Sichtfeld haben 
		\item eine farbenfrohe Perspektive der Umgebung bieten 
		\item eine 3D-Geometrie von Objekten bei Stereokameras bereitstellen
		\item kostengünstig Im Vergleich zu Lidar sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item ein leistungsfähiges Berechnungssystem benötigen, um nützliche Daten zu extrahieren 
		\item empfindlich auf starken Regen, Nebel und Schneefall reagieren 
		\item eine 3D-Geometrie von Objekten bei Stereokameras bereitstellen
		\item begrenzte Reichweite besitzen
	\end{itemize} 
	\\ \hline
	
	FIR-Sensor& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item nicht von der Lichtbedingungen und Objektoberflächenmerkmale beeinflusst werden können
		\item eine bessere Sicht durch Staub, Nebel und Schnee als Kameras  haben 
		\item eine horizontale Erfassungsreichweite bis zu 200m oder mehr abdecken 
		\item im Vergleich zu Lidar billiger und kleiner sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item anspruchsvolle Rechenquellen und robuste Algorithmen erfordern
		\item schwierig Ziele in Szenarien mit kaltem Klima zu unterscheiden  
		\item niedrigere Auflösung im Vergleich zur sichtbaren Kamera haben
		\item keine Information über Entfernung bieten
	\end{itemize} 
	\\ \hline
	
	Radarsensor& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item lange Strecken bei schlechten Sichtverhältnissen vor dem Auto sehen 
		\item klein, leicht und erschwinglich sind 
		\item weniger Strom als ein Lidar-Sensor benötigen
		\item im Vergleich zu Lidar robuster gegen Ausfälle sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine geringe Genauigkeit und Auflösung bieten
		\item begrenzte Informationen  (z. B. weder genaue Form- noch Farbinformationen) bekommen
		\item das Problem wegen der gegenseitigen Beeinflussung von Radarsensoren haben
		\item schlechte Azimut- und Höhenauflösung verfügen
		\item ohne einer Erhöhung der Leistung Radardämpfung zeigen
	\end{itemize} 
	\\ \hline
	
	Ultraschall-\newline sensor & 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item lange Strecken bei schlechten Sichtverhältnissen vor dem Auto sehen 
		\item klein, leicht und erschwinglich sind 
		\item weniger Strom als ein Lidar-Sensor benötigen
		\item im Vergleich zu Lidar robuster gegen Ausfälle sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine geringe Genauigkeit und Auflösung bieten
		\item begrenzte Informationen  (z. B. weder genaue Form- noch Farbinformationen) bekommen
		\item das Problem wegen der gegenseitigen Beeinflussung von Radarsensoren haben
		\item schlechte Azimut- und Höhenauflösung verfügen
		\item ohne einer Erhöhung der Leistung Radardämpfung zeigen
	\end{itemize} 
	\\ \hline
	
	LiDAR-Sensor & 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item große Entfernungen vor dem Auto bei guten Sichtverhältnissen erfassen
		\item volle $360^\circ$- und 3D-Punktwolken bieten 
		\item eine gute Genauigkeit und Auflösung haben
		\item keine signifikanten Interferenzen bei mehreren Lidarsensoren haben
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item teurer als Radar und Kamera sind
		\item kleine Objekte (wie Drähte und Stangen) nicht entdecken können
		\item eine schlechte Kontrastunterscheidung bei der Erkennung nasser Oberflächen haben
		\item durch unterschiedliche klimatische Bedingungen beeinflusst werden
	\end{itemize} 
	\\ \hline
\end{longtable} 
\subsubsection{Funktionsweise des Lasersensors}
\label{Abschnitt:Laserscanner}
Ist ein angemessenes Sensormodell zu finden, ist es sinnvoll das Mechanismus, die Eingenschaften und die Gründe der Unsicherheit zu untersuchen. Die Angemessenheit hierbei bedeutet, dass eine Abwägung bzw. ein Kompromiss immer nach verschiedenen Anwendungsszenarien gemacht werden muss. 
\\Laserscanner beruht auf dem Prinzip ToF (Time-of-flight). Nach diesem Prinzip wird die Entfernung zwischen dem zu erfassenden Ziel und Laserscanner dadurch berechnet, dass die Zeit gemessen wird, die ein Lichtimpuls benötigt, um von der Lichtquelle zum beobachteten Ziel und dann zum Detektor (normalerweise zusammen mit der Lichtquelle) zu gelangen~\citep{Siciliano.2008}. Im Prinzip ist Lasersensor ähnlich wie Radarsensor, wobei nur Infrarot-, Ultraviolett- oder Strahlen aus dem Bereich des sichtbaren Lichts anstelle von Mikrowellen eingesetzt werden~\citep{Winner.2015}. Die mathematische Beschreibung des Prinzips lässt sich in Gleichung~\ref{Gleichung:Tof} darstellen. Dabei bezeichnet d den Abstand zwischen Lasersensor und dem zu erfassenden Objekt. Das Lichtgeschwindigkeit wird als c dargestellt. Bei einigen hochpräzisen Lasersensoren wird Lichtausbreitungsmedium auch berücksichtigt und dazu wird c der Umgebung gemäß kompensiert. Zeit t benötigt das Licht um die Ausbreitungsstrecke zu decken, die doppelte Entfernung zwischen Laserscanner und Objekt ist. Die Zeit wird in der Tat gemessen und in Abstand d übergeführt. Der Sensor sendet periodisch Lichtimpulse aus und berechnet die durchschnittliche Zielentfernung basierend auf der Zeit des Rückimpulses~\citep{Siciliano.2008}.
\begin{equation}
	\label{Gleichung:Tof}
	d=\frac{c\cdot t}{2}
\end{equation}
Im Bereich des selbstfahrenden Fahren wird der Lichtpuls mit nicht nur eine Ausrichtung ausgestrahlt, weil ein relativ großer Beobachtungsbereich mehrere Lichtstrahlen erfordert, die in verschiedene Richtungen emittiert werden. Aktuell gibt es zwei verschiedene LiDAR-Systeme. Zum einen ist das feststehende Sensor, in dem mehrere Sende-/ Empfangseinheiten in unterschiedlichen Ausrichtungen angeordnet werden~\citep{Effertz.2009}. Zum anderen wird das rotierende LiDAR-System dadurch realisiert, dass der Lichtimpuls mittels einer drehbaren Spiegeleinheit abgelenkt wird~\citep{Effertz.2009}. Der in dieser Arbeit verwendete Laserscanner Ibeo-LUX gehört zu dem zweiten Sensorsystem.
\subsubsection{Theorie des inversen Sensormodells}
Die Aufgabe des inversen Sensormodells besteht darin, den in~\ref{Abschnitt:Gitterbasierte Modelle} erwähnten mathematischen Ausdruck $p(m_i|z)$ zu finden, der die Wahrscheinlichkeitsverteilung des Belegungszustands der Zelle mit dem Index i beschreibt. Nach~\citep{Pieringer.2013} lässt sich das inverse Sensormodell im Prinzip in drei Bestandteile zerlegen. Wie in Abbildung~\ref{fig:Bestandteile_Sensormodell} gezeigt, handelt es sich hierbei um Hinderniskartierung, Freiraummodellierung und Beschreibung unbekannter Gebiete.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/Bestandteile_Sensormodell.pdf}
	\caption{Bestandteile des Prinzips von Inverses Sensormodell }
	\label{fig:Bestandteile_Sensormodell}
\end{figure}
\\Unter Hinderniskartierung wird das Verfahren verstanden, dass die vom Sensor detektierten Objekte in das gitterbasierte Umfeldmodell bzw. das Occupancy Grid Map übertragen werden~\citep{Pieringer.2013}. Zwei Probleme sind in diesem Bestandteil des inversen Sensormodells zu lösen. Zum einen gewinnt es an Relevanz, welche Form für das detektierte Objekt bzw. das Hindernis angenommen wird~\citep{Pieringer.2013}. Die Form (z.B. Linie oder Ellipse), die das Hindernis repräsentiert, ist theoretisch eng mit der Unsicherheitsquellen des Laserscanners verbunden. Jedoch wird die Form in der Praxis ausgewählt unter Berücksichtigung der Ausführlichkeit bzw. Genauigkeit und Echtzeitanforderung. Zum anderen ist das Problem, mit welchem Zahlenwert die Wahrscheinlichkeit der kartierten Zelle erfüllt ist. Diese beiden Probleme werden nachstehend bei der tatsächlichen Sensormodellierung ausführlicher erörtert.
\\Freiraum ist bei dem Umfeldmodell der beobachtbare Bereich zwischen dem Sensor und dem erfassten Objekt. Analog zur Hinderniskartierung steht die Bestimmung der Form des Freiraums und der Wahrscheinlichkeit der betreffenden Zelle in Zentrum der Freiraummodellierung. Jedoch hängt die Form des Freiraums von der oben bestimmten Hindernisform. Beispielweise wird der Freiraum als Linie oder Dreiecke modelliert, wenn die Hindernisse punktförmig oder linieförmig beschrieben werden. Bei Wahrscheinlichkeitsverteilung über den Freiraum spielt die Ursache der Unsicherheit eine große Rolle. Mit zunehmender Entfernung wird beispielsweise die vom Laserscanner erkannte Entfernung zum Hindernis weniger zuverlässig. Aus diesem Grund ist dabei ein Modell zu entwickeln, die Unsicherheit in gewissem Grade widerspiegeln kann. In der Anwendung sind ebenso die Korrektheit und die Zeitaufwand zu gewichten.
\\Der Raum innerhalb der Reichweite des Laserscanners, der weder ein Hindernis noch ein freier Raum ist, ist ein unbekannter Bereich des Modells. Ein typisches Beispiel dafür ist der Raum hinter hinter Hindernissen. Im Allgemeinen wird der Wahrscheinlichkeit einer unbekannten Zell als die A-priori-Wahrscheinlichkeit zugewiesen. Der Grund liegt darin, dass keine neuen Informationen über den Belegungszustand eingegeben werden. Typischerweise wird die A-priori-Wahrscheinlichkeit bzw. die Wahrscheinlichkeit einer unbekannten Zelle als $0,5$ zugewiesen.
\\Die obigen drei Teile werden nicht getrennt, sondern gleichzeitig in der tatsächlichen Implementierung ausgeführt. Das inverse Sensormodell ist einer der Schlüsselbestandteile von Occupancy Grid. Seine Genauigkeit und Einfachheit bestimmen die Qualität des Modells und den Zeitaufwand des Systems. In der Technik wird es häufig in Kombination mit tatsächlichen Anwendungsszenarien und Sensoreigenschaften erstellt.
\subsubsection{Technische Details von Ibeo-LUX}
In der am IfF bereits bestehenden Fahrzeugarchitektur werden Laserscanner Ibeo-LUX von Ibeo Automotive Systems GmbH für Erfassung der Umgebung um das selbstfahrende Fahrzeug verwendet. Das Golf 7 ist mit vier IBEO-LUX-4L ausgestattet. Neben 4 IBEO-LUX-4L Laserscannern sind auf der Vorder- und Rückseite des Passat IBEO-LUX-8L-Laserscanner installiert. Um ein angemessenes Sensormodell für den Laserscanner zu entwickeln, ist es voraussetzt, dass die technische Details des Sensors zur Verfügung stehen. Nach~\citep{IbeoAutomotiveSystemsGmbH.2017} sind die relevanten technischen Parameter in Tabelle~\ref{tab:technische Details von Ibeo LUX} aufgelistet.
\begin{table}[ht]
	\caption{Technische Details von Ibeo LUX}
	\label{tab:technische Details von Ibeo LUX}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Technische Daten} & \textbf{Wert}\\
		\hline
		Reichweite & 50m mit $10\%$ Remission\\
		\hline
		Genauigkeit & 10cm\\
		\hline
		Entfernungsauflösung & 4cm\\
		\hline
		Horizontaler Öffnungswinkel & $110^\circ$ $(50^\circ$ bis $-60^\circ)$ \\
		\hline
		Vertikaler Öffnungswinkel & $6,4^\circ$ (LUX-8L) / $3,2^\circ$ (LUX-4L)\\
		\hline
		Horizontale Winkelauflösung & $0,25^\circ$\\
		\hline
		Vertikale Winkelauflösung & $0,8^\circ$\\
		\hline
		Bildrate & 25 Hz\\
		\hline
		Multi-Layer & 8 (LUX-8L) / 4 (LUX-4L)\\
		\hline
		Ausgabe & Punktwolke und Objektdaten\\
		\hline
		Abmaße (B$\times$T$\times$H) & 164,5$\times$93,2$\times$88mm\\
		\hline
		Gewicht & 998,7g\\
		\hline
	\end{tabular}
\end{table}
\subsubsection{Das zu verwendende Sensormodell}
Nach Einführung der Theorie des inversen Sensormodells und der technischen Daten des verwendeten Ibeo-LUX-Laserscanners wird in diesem Abschnitt ein geeignetes Sensormodell entwickelt, um die Wirkung der Sensorinformation auf Glauben des Zellenbelegungszustands zu beschreiben. Hierbei wird ein Kompromiss zwischen Genauigkeit und Effizienz geschlossen. Aufgrund der Messunsicherheit und der in Tabelle~\ref{tab:technische Details von Ibeo LUX} aufgelisteten Laserscanner-Spezifikationen erfolgt die Sensormodellierung in zwei Schritten. Im ersten Schritt wird die Form des Hindernis mitsamt des entsprechenden Freiraums festgestellt. Darauffolgend wird es bestimmt, welcher Wahrscheinlichkeit in welchem Bereich zugewiesen wird~\citep{Pieringer.2013}.
\\Ein genaues Modell sollte die Wahrscheinlichkeit jeder Zelle in Abhängigkeit von der Position auf der Karte, der Strahlbreite und dem Abstand zum Zentrum des Strahls berechnen~\citep{Homm.2106201024062010}. Wenn die Positionsunsicherheit beträchtlich ist, sollte eine kreis- oder ellipsenförmige Form für Hindernis unter Anwendung einer zweidimensionalen Gaußfunktion angenommen werden~\citep{Pieringer.2013}. Steht eine niedrige Winkelauflösung eines Sensor zur Verfügung, kann die Form zu einer Linie vereinfacht werden. Wenn der Sensor ausreichend genaue Tiefeninformationen hat, lässt sich die Form weiter zu einem Punkt vereinfachen. 
\\Im Rahmen dieser Arbeit wird die Auflösung der Zelle als $0,1m$ zugewiesen. Außerdem ist es sinnvoll, die maximale erfasste Entfernung $d_{max}$ des Laserscanners zu beschränken, obwohl laut Tabelle~\ref{tab:technische Details von Ibeo LUX} eine Reichweite 50m besteht.Dies kann die durch die große Entfernung verursachte Unsicherheit verringern. Nach dem Test wird der Wert von $d_{max}$ als 10m bestimmt. Die horizontale Winkelauflösung $\Delta\theta$ beträgt nach Tabelle~\ref{tab:technische Details von Ibeo LUX} $0,25^\circ$ oder 0,004363(rad). Durch Multiplizieren von $d_{max}$ und $\Delta\theta$ beträgt der Wert des Kreisbogens $0,043$, der die wegen der Strahlbreite entstehende Divergenz beschreibt. Da $0,043<0,1$ gilt, lässt sich der Einfluss von Strahlbreite vernachlässigen. Zudem wird angenommen, dass die Genauigkeit von $0,1m$ ausreichend genau ist. Damit ist es deutlich, dass Hindernisse im Rahmen dieser Arbeit aufgrund der Sensorspezifikation als Punkte beschrieben werden können. Daraus lassen sich herleiten, dass das entsprechende Freiraummodell als Linie dargestellt wird. Um ein Objekt zu detektieren, dessen Abmessung größer als Auflösung ist, ist der bekannte Begriff Raycasting zu einsetzen. Hierbei werden die einzelnen physikalischen Strahlen des Laserscanners zwischen dem Sensor und einem Objekt nachgebildet. Basierend darauf wird der nächste Schritt der Modellierung eines Sensors simplifiziert und es wird nur erwartet, dass das inverse Sensormodell einziges Laserstrahls beschreiben kann. Während der Implementierung werden alle Laserstrahlen mit demselben Sensormodell behandelt. Das inverse Modell eines einzelnen Strahls ist eindimensional und das von einem idealen Laserscanner verwendete Modell ist in Abbildung~\ref{fig:ideal_sensormodell} dargestellt. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/ideal_sensormodell.pdf}
	\caption{Das ideale Sensormodell}
	\label{fig:ideal_sensormodell}
\end{figure}
Das Diagramm veranschaulicht die ideale Zusammenhang zwischen der Belegungswahrscheinlichkeit der Zelle mit dem Index i und dem Abstand vom Laserscanner. Es ist angenommen, dass sich ein punktförmiges Objekt in einer Entfernung von D befindet. Ohne Messabweichung bzw. Unsicherheit besitzt das ideale Modell eine besonders einfache Funktion. Vor dem Objekt bzw. dem Hindernis ist es angenommen, dass es kein anderes Hindernis existiert. Die Wahrscheinlichkeit der Zelle, die von Laserscanner mit einem Abstand von D entfernt, beträgt 1. Hinter dem Hindernis sind alle Zelle verborgen, weshalb die Wahrscheinlichkeit unverändert bleibt und als A-priori-Wahrscheinlichkeit von $0,50$ angegeben wird. 
\\Jedoch unterliegt jede Messung aus verschiedenen Gründen einer gewissen  Messunsicherheit~\citep{Hegerhorst.2018}, weshalb das ideale Sensormodell eine bescheidene Genauigkeit bietet. Unter Berücksichtigung der Messunsicherheit kann das inverses Sensormodell von ideal vereinfachend bis stark komplex sein~\citep{Pieringer.2013}. Allerdings wird die Funktion, die das inverse Sensormodell definiert, in der Praxis nach der bisherigen Erfahrungen bestimmt. Basierend auf~\citep{Weiss.1306200715062007}~\citep{Pieringer.2013}~\citep{Hegerhorst.2018} wird im Rahmen dieser Arbeit je nach Situation zwei bestimmte abschnittsweise definierte Funktionen angewendet. Die beide Funktionen weisen darauf hin, dass die Zellen innerhalb des minimalen erfassbaren Abstands mit einer niedrigen und konstanten Wahrscheinlichkeit hinzugefügt werden. Das inverse Sensormodell ist eine Erweiterung des idealen Sensormodells, wenn ein Hindernis detektiert wird. Wie in Abbildung~\ref{fig:sesormodellmitD} dargestellt, ist der Freiraum vor dem detektierten Hindernis durch eine monoton ansteigende lineare Funktion zu beschreiben. Der Belegungswahrscheinlichkeit des als Hindernis erkannten Quadrats wird ein höherer Wert zugewiesen, z. B. 0,9. Wie beim idealen Modell wird auch bei diesem Modell hinter dem Hindernis ein Wahrscheinlichkeitswert von 0,5 zugewiesen.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/sesormodellmitD.pdf}
	\caption{Das inverses Sensormodell, wenn ein Hindernis detektiert wird}
	\label{fig:sesormodellmitD}
\end{figure}
Hierbei wird die mit größerer Entfernung entstehende Messunsicherheit abgebildet, indem die Belegungswahrscheinlichkeit mit zunehmender Distanz von dem Laserscanner erhöht wird~\citep{Hegerhorst.2018}. Besteht kein Hindernis, wird die Funktion in die in Abbildung~\ref{fig:sesormodellohneD} gezeigte Beschreibung umgewandelt. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/sesormodellohneD.pdf}
	\caption{Das inverses Sensormodell, wenn kein Hindernis detektiert wird}
	\label{fig:sesormodellohneD}
\end{figure}
In diesem Fall steigt die Wahrscheinlichkeitsfunktion im Bereich der maximalen Erfassungsentfernung und der minimalen Entfernung monoton an. Bei maximaler Entfernung steigt der Wahrscheinlichkeitswert auf 0,5.
\\Da diese Funktionen linear und einfach sind, wird die Echtzeitanforderung in gewissem Maß gewährleistet. Darüber hinaus werden die Steigung, der minimale bzw. maximale Abstand und die Wahrscheinlichkeit der Zelle mit dem Abstand parametrisiert und  bei der folgenden Implementierung justiert. Zusätzlich werden die Steigung, der minimale oder maximale Abstand und die Wahrscheinlichkeit der Zelle, die sich mit diesen beiden Abständen befindet, so parametrisiert, dass sie je nach Anwendung variieren können.
