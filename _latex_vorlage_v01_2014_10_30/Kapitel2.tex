\section{Theoretische Grundlagen}
Um das in~\nameref{sec:Einleitung} \ref{sec2:Zielstellung} erwähnte Ziel zu erreichen, sollten zunächst die theoretische Grundlagen geschaffen, bevor die praktische Umsetzung bzw. Implementierung stattfindet. Im Folgenden werden die für Umfeldmodellierung relevanten Theorie vorgestellt. Es ist offensichtlich, dass für die Umfeldmodellierung eine Wahrnehmung über das Umfeld gefordert, weshalb die für Umfeldwahrnehmung Sensorik darauffolgend gesprochen wird.

\subsection{Umfeldmodellierung}
Für Perzeption eines autonomen Fahrzeuges gibt es im wesentlichen zwei Bestandteilen \citep{Badue.2019}. Zum einen ist die Lokalisation. Die aktuelle Pose, das heißt die Position und Orientierung des eigenen Fahrzuges, ist hierbei zu ermitteln. Zum anderen ist die Umgebung um das Fahrzeug zu erfassen. Dabei wird es als Umfeldmodellierung genannt. Diese zwei Aspekte werden in vieler Forschung und Anwendung als ein Problem gekoppelt. Dies ist als SLAM (Simultaneous localization and mapping) bekannt. Jedoch trennen sich diese zwei Aspekte im Rahmen dieser Arbeit und die Aufmerksamkeit ist auf Umfeldmodellierung zu lenken. Hierbei wird eine Annahme getroffen, dass die Eigenpose des Fahrzeugs ohne Information der Umfeldmodell genug präzis ist. Im bestehenden ifF-Framework wird die Eigenpose mit GPS-Daten unter Anwendung des Kalmann-Filters übergeben.
\\In Bezug auf Robotik und autonomes Fahren dient Umfeldmodellierung als ein kompaktes Verfahren zu der mathematischen Repräsentation von der Umgebung um ein Auto.\citep{Pieringer.2013} Das schafft eine unentbehrliche solide Grundlage, auf der der Entwurf und die darauffolgende Verwirklichung aller höheren automatisierten Fahrfunktion.
\subsubsection{Mögliche Umfeldmodelle} 
Methoden zur Modellierung eines Umfelds basieren sich auf verschiedene entsprechenden Umfeldmodelle. Die maßgebliche Umfeldmodelle bauen auf erfolgreichen Erfahrung in dem Themenbereich der Robotik\citep{Pieringer.2013}. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/Umfeldmodelle_Klassen.pdf}
	\caption{Mögliche Umfeldmodelle für autonome Fahrzeuge}
	\label{fig:Umfeldmodelle_Klassen}
\end{figure}
Wie in Abbildung~\ref{fig:Umfeldmodelle_Klassen} gezeigt, stehen aktuell in Forschung und Automobilindustrie meistens drei mögliche Umfeldmodelle zur Verfügung\citep{Hegerhorst.2018}.
\subsubsection{Objektbasierte Modelle}
Objektbasierte Modelle werden auch als merkmalbasierte Umfeldmodelle (engl. landmark-based oder feature map) genannt\citep{Thrun.2005}. Hierbei werden die Merkmalen, die für Erfassung der Umgebung günstig sind, durch Modelle beschrieben werden\citep{Wurm.2010}. Außerdem sollten die Merkmalen zuverlässig beobachtet und gemessen werden\citep{Buschka.2005}. Die Modelle werden im Praxis als bestimmte Objektklasse beschrieben. Jede Klasse wird mit hervorragenden und maßgeblichen Eingenschaften versehen, die deutlich durch die zutreffende Sensorik beobachtbar ist\citep{Winner.2015}. Für die Klassen lassen sich darüber hinaus die zu Objekt passende Geometrieformen bestimmen\citep{Pieringer.2013}. Daher ist die Performance des Modells abhängig davon, ob die zu modellierten Objekte genug präzis und einfach beschrieben werden können. Hierbei sind die Genauigkeit gegen der Zeit- und Speicheraufwand abzuwägen. Ein Beispiel ist ein in Abblidung~\ref{fig:FeatureMap} gezeigtes Umfeldmodell. Auf der linken Seite sind Merkmale dargestellt und das Bild rechts zeigt das generierte Umfeldmodell.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/FeatureMap.pdf}
	\caption{Ein objektbasiertes Umfeldmodell.~\citep{FawadAhmad.2020}}
	\label{fig:FeatureMap}
\end{figure}
\\Objektbasierte Umfeldmodelle sind vor allem eignet für Szenen, wo die Objekte entweder im großen offenen Räume mit vordefinierten Merkmalen (z.B. Autobahn) oder dynamisch und einfach modelliert (z.B. Fußgänger oder Fahrzeuge) sind\citep{Hegerhorst.2018}\citep{Wurm.2010}. Da es im Rahmen dieser Arbeit ein statisches Umfeld im urbanen Raum angeht, ist dieses Modell ungeeignet und daher zu verzichten.  
\subsubsection{Gitterbasierte Modelle}
\label{Abschnitt:Gitterbasierte Modelle}
In gitterbasierten Modellen wird die zentrale Idee der probabilistischen Robotik eingeführt, die Wahrscheinlichkeitsverteilung unbeobachteter Zustände eines Systems bei gegebenen Beobachtung und Messungen zu schätzen. Zur Modellierung des Umfelds ist der zentrale und entschiedene Zustand der sogenannte Belegungszustand. Der Belegungszustand erweist sich, ob eine Gitterzelle belegt ist. Daraus ergibt sich eine Zufallsvariable X, den Belegungszustand repräsentiert. Die Variable X kann zwei Werte annehmen, welche 0 und 1 sind. Die entsprechen dabei, dass das Gitter frei und belegt ist.
\\Ein Modell, welches auf der obenerwähnten Idee aufbaut, wird als Occupancy Grid beschrieben. Das Occupancy Grid ist ein mehrdimensionales Zufallsfeld, das stochastische Schätzungen des Belegungszustands der Zellen in einem räumlichen Gitter halten~\citep{Elfes.1989}. Wie in Abbildung~\ref{fig:EbeneVonOccupancyGrid} gezeigt, lässt Occupancy Grid sich in zwei Ebenen zerlegen.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Ebene von Occupancy Grid.pdf}
	\caption{Zwei Ebenen von Occupancy Grid}
	\label{fig:EbeneVonOccupancyGrid}
\end{figure}
\\Auf der ersten Ebene wird die Raumdiskretisierung ausgeführt. Im Rahmen dieser Arbeit wird das Umfeld als zweidimensionalen Raum dargestellt. Die Diskretisierung des Raumes bedeutet hierbei, dass die Fahrzeugumgebung durch Gitter diskreter und fester Größe dargestellt wird~\citep{Hegerhorst.2018}. Die grafische Darstellung ist in Abbildung~\ref{fig:Raumdiskretisierung} gezeigt. Außerdem wird jeder Zelle zusätzliche Informationen hinzugefügt. In Hinsicht auf Umfeldmodellierung ist die entschiedene Information die Belegungszustand der Zelle. Zur Vereinfachung der Modellierung, wird eine Annahme auf dieser Ebene zugleich getroffen, dass die Belegungszustand einer Gitterzelle ist unabhängig von diejenige der Nachbarzellen. Obwohl die Annahme anders als Realität aussieht, ist es erwiesen, dass Occupancy Grid Modell in Praxis unter dieser Annahme robust ist und zudem die Rechenkomplexität reduzieren kann~\citep{Thrun.2005}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Raumdiskretisierung.pdf}
	\caption{Raumdiskretisierung der Umgebung um Fahrzeug \citep{Winner.2015}}
	\label{fig:Raumdiskretisierung}
\end{figure}
\\Auf der zweiten Ebene ist der probabilistische Ansatz eingeführt, welcher aus Themengebiet von Robotik stammen~\cite{Pieringer.2013}. Der Ansatz beruht auf Raumdiskretisierung und wird in der Praxis für jede einzelne Zelle eingesetzt. Der Ansatz lässt sich, wie in Abbildung~\ref{fig:OccupancyGrid} gezeigt, in viele Komponenten aufteilen. Im Zentrum des Modells steht ein Algorithmus-Framework, der als binärer Bayes-Filter (engl. Binary Bayes Filter) bekanntlich ist. Die Eingaben von dem Framework bestehen aus Messungswerte, inverses Sensormodell und Anfangsbedienungen. Die Ausgabe ist A-posteriori-Wahrscheinlichkeit von dem Zufallsereignis, wenn die Zelle belegt ist. Um die Konzept von Occupancy Grid zu beleuchten, wird im Folgenden auf jede Komponente vertieftet eingegangen.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/OccupancyGrid.pdf}
	\caption{Bestandteile des Modells Ocuupancy Grid}
	\label{fig:OccupancyGrid}
\end{figure}
\\Der Binary-Baye-Filter ist zuerst zu beleuchten, mit dem die Funktionen und Bedeutungen von anderen Bestandteilen des Modells eng verbunden sind. Der Bayes-Filter ist ein rekursives Berechnungsvorschrift zur Schätzung von Wahrscheinlichkeitsverteilungen unbeobachteter Zustände eines Systems bei gegebenen Beobachtungen und Messungen~\citep{Thrun.2005}. Die Zustandsschätzung befasst sich mit dem Problem der Schätzung  von Größen aus Sensordaten, die nicht direkt beobachtbar sind, aber abgeleitet werden können. Das Ziel ist den Zustand $x$ eines Systems zu schätzen\footnote{Präzis wird den Zustand $X=x$ formuliert, wobei X eine Zufallsvariable ist und x ist der spezifische Wert, den X in Echtzeit annimmt. Zur Vereinfachung der Notation wird die Formulierung $X=x$ im Rahmen dieser Arbeit sowie in vieler Literaturen als $x$ bezeichnet.}, wenn Beobachtung $z$ und Kontrolle u gegeben sind. Das heißt, die in Gleichung~\ref{Gleichung:Zustandschaetzung} gezeigte mathematische Formulierung sollte bestimmt werden. Hierbei entspricht $x_t$ Zustand zum Zeitpunkt t. $z_{1:t}$ bezeichnet die Beobachtungen bzw. die Messgrößen von den Zuständen, die sich von Zeitstempel 1 bis t erstrecken. Zudem gibt $u_{1:t}$ die Kontrollen an, die sich von Zeitstempel 1 bis t erstrecken. Die linke Seite der Gleichung $bel_(x_t)$ verkörpert den Glauben (engl. belief) der Wahrheit, dass der Zustand $x_t$ ist~\citep{Thrun.2005}.
\begin{equation}\label{Gleichung:Zustandschaetzung}
	bel(x_t)=p(x_{t}|z_{1:t},u_{1:t})
\end{equation}
Um die Wahrscheinlichkeitsverteilung einzugehen und eine rekursive Form zu entdecken, ist der stochastische Prozess der Zustandsänderung als Hidden Markov Model (HMM), auch dynamic Bayes network (DBN) genannt, zu betrachten. Unter Anwendung dieser Annahme gilt: Die Wahrscheinlichkeit eines Zustandes bei Zeitstempel $t$ ($x_t$) ist einschließlich abhängig von Zustand bei Zeitstempel $t-1$ ($x_{t-1}$) und nicht von Zuständen bei Zeitstempel, die früher als $t-1$ sind. Mathematisch wird HMM als eine Gleichung in \ref{Gleichung:HMM} beschrieben.
\begin{equation}\label{Gleichung:HMM}
 	p(x_{t}|x_{1:t})=p(x_t|x_{t-1}) 
\end{equation}
Außerdem beschreibt Hidden Markov Model, wie in Abbildung~\ref{fig:HiddeMarkovModel} dargestellt, die vereinfachte Zusammenhang zwischen Zustand $x$, Messgröße $z$ und Kontrolle $u$. Der Zustand zum Zeitpunkt $t$ ist abhängig von dem Zustand zum Zeitpunkt $t-1$ und der Kontrolle $u_t$. Die Messgröße $z_t$ hängt stochastisch vom Zustand zum Zeitpunkt $t$ ab.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/HMM.pdf}
	\caption{Hidden Markov Model (HMM) \citep{Thrun.2005}}
	\label{fig:HiddeMarkovModel}
\end{figure}
Unter zusätzliche Anwendung des Satzes von Bayes und des Gesetzes der totalen Wahrscheinlichkeit wird die Formulierung~\ref{Gleichung:Zustandschaetzung} in einen rekursiven Ausdruck abgeleitet, was als Bayes-Filter bekanntlich ist. Die Ableitung findet sich in~\citep{Thrun.2005}. Der daraus resultierte Algorithmus lautet in Tabelle~\ref{tab:AlgorithmBF}:
\begin{table}[ht]
	\caption{Der Algorithmus des Bayes-Filters~\cite{Thrun.2005}}
	\small
	\centering
	\label{tab:AlgorithmBF}
	\begin{tabular}{ll}
		\toprule
		\textbf{Algorithm Bayes Filter($bel(x_{t-1}),u_t,z_t$):}\\
		for all $x_t$ do\\
		~~~~$\overline{bel}(x_t)=\int{p(x_t|u_t,x_{t-1})bel(x_{t-1})dx_{t-1}}$\\ 	
		~~~~$bel(x_t)=\eta p(z_t|x_t)\overline{bel(x_t)}$\\	
		endfor\\
		return $bel(x_t)$\\		
		\toprule
	\end{tabular}
\end{table}
Der Algorithmus umfasst 2 Schritte, welche als Prädiktion (engl. prediction) und Korrektur (engl. Correction oder update) bekanntlich sind. Der erste Schritt wird dadurch ausführt, dass der Glauben bzw. die Wahrscheinlichkeitsverteilung über den Zustand $x_t$ - basierend auf dem vorherigen Glauben über den Zustand $x_{t-1}$ und Kontrolle $u_t$ - berechnet werden sollte. Der zweite Schritt ist eine Korrektur bzw. ein Update des prognostizierte Glauben, indem die beobachte Informationen des Zustandes bzw. die Messgrößen der Sensorik fusioniert und berüchtigt wird. Der Wert $bel(x_t)$ wird als A-posteriori-Verteilung genannt. Im Gegensatz zu A-priori-Verteilung verkörpert A-posteriori-Verteilung den theoretisch präziseren Glauben, nachdem die Messgrößen von Sensorik durch ein Sensormodell die Genauigkeit des Glaubens beiträgt. Dieser Algorithmus bildet eine Grundlage, auf der viele weitere Algorithmen für bestimmte Szenarien entwickelt werden. Dazu gehören bekanntlich Gauß-Filter mit ihren Varianten, Particle-Filter und der diskrete Bayes-Filter. Der binäre Bayes-Filter, der eine große Rolle in dieser Arbeit spielt, ist ein spezieller Fall des Bayes-Filters bzw. des diskreten Bayes-Filter.
\\Eingeführt von dem zugrunde liegenden Bayes-Filters, benötigt der binäre Bayes-Filter eine Annahme. Es ist angenommen, dass der Zustand einschließlich zwei Möglichkeiten besitzen. Das heißt, der Zufallsvariable, der den Zustand repräsentiert, kann nur zwei Werte annimmt. Bei Occupancy Grid kann der wichtige und auch einzige Zustand der Belegungszustand, welche lediglich zwei Fälle - belegt oder frei - sein. Aus diesem Grund ist der binäre Bayes-Filter dafür zutreffend. Darüber hinaus wird eine weitere Annahme getroffen, dass der Belegungszustand bei Occupancy Grid statisch ist. Das heißt, dass der Belegungszustand sich nicht im Laufe der Zeit verändert und die Kontrolle $u$ hat keine Wirkung auf den Belegungszustand. Somit ist das Schema des stochastischen Prozesses der Zustandsveränderung von Abbildung~\ref{fig:HiddeMarkovModel} auf Abbildung~\ref{fig:reducedHMM} reduziert, indem die Kontrollen ausgeklammert werden. Es ist nach dieser zwei Annahme deutlich, dass der Algorithmus des Bayes-Filters in Occupancy Grid den Schritt Prädiktion nicht mehr enthält. Die A-posteriori-Verteilung der Zustand $bel(x_t)$ ist einschließlich berechnet mit Information von Messdaten und der vorherige Zustand $bel(x_{t-1})$.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/reducedHMM.pdf}
	\caption{Das reduzierte HMM \citep{Thrun.2005}}
	\label{fig:reducedHMM}
\end{figure}
\\Anhand der Vereinfachung des Modells sollte der grundlegende Bayes-Filter entsprechend vereinfacht werden. Außerdem sollte der vereinfachte Algorithmus ein inverses Sensormodell. Das inverse Sensormodell gibt anstatt $p(z_t|x)$ eine Verteilung über die binäre Zustandsvariable als Funktion der Messung $p(x|z_t)$ an \citep{Thrun.2005}. Ein Grund, das ein inverses Sensormodell eingesetzt wird, ist die Leichtigkeit, eine Funktion zu entwickeln, die die Wahrscheinlichkeitsverteilung von Sensordaten berechnet. Es ist zum Beispiel relativ simpel ein Modell zu entwerfen, womit die Wahrscheinlichkeit der Belegungszustand einer Zelle oder mehrerer Zellen anhand der Sensordaten bestimmt werden kann. Ein Vorwärtsensormodell ist dagegen in diesem Fall erstaunlich schwierig. Mit dem Ziel, ein vereinfachter Algorithmus, der ein inverses Sensormodell verwendet, zur Berechnung des Glauben $bel(x_t)$ zu finden, sollte die mathematische Ableitung nach ~\citep{Thrun.2005}~\cite{Weiss.1306200715062007}~\citep{Hegerhorst.2018} folgend vorgestellt.
\\Da Belegungszustand statisch ist und Kontrolle $u$ somit ignoriert wird, kann die Zielgleichung~\ref{Gleichung:Zustandschaetzung} zur vereinfachten Gleichung~\ref{Gleichung:Glauben}.
\begin{equation}
	\label{Gleichung:Glauben}
	bel(x_t)=p(x_t|z_{1:t},u_{1:t})=p(x_t|z_{1:t})
\end{equation}
Bei Occuancy Grid ist der interessierte Zustand der Belegungszustand. Zur Vereinfachung der Notation wird das Glauben, dass die Zelle i des Gitters zum Zeitpunkt t belegt ist, als Gleichung ~\ref{Gleichung:Glauben_belegt} bezeichnet.
\begin{equation}
	\label{Gleichung:Glauben_belegt}
	bel_t(m_i)=p(m_i|z_{1:t})
\end{equation}
Analog dafür ergibt sich das Glauben, dass die Zelle i des Gitters zum Zeitpunkt t frei ist, zur Gleichung ~\ref{Gleichung:Glauben_frei}
\begin{equation}
	\label{Gleichung:Glauben_frei}
	bel_t(\overline{m_i})=p(\overline{m_i}|z_{1:t})
\end{equation}
Mit Hilfe des bedingten Satzes der Bayes ergibt sich die Gleichung~\ref{Gleichung:Glauben_belegt} zu
\begin{equation}
	\label{Gleichung:Ableitung_01}
	bel_t(m_i)=p(m_i|z_{1:t})=\frac{p(z_t|m_i,z_{1:t-1})p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}
\end{equation}
Unter Annahme eines Hidden-Markov-Modells wird die Gleichung~\ref{Gleichung:Ableitung_01} zu
\begin{equation}
	\label{Gleichung:Ableitung_02}
	bel_t(m_i)=\frac{p(z_t|m_i,z_{1:t-1})p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(z_t|m_i)p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}
\end{equation}
Zur Wahrscheinlichkeit $p(z_t|m_i)$ wird der Satz des Bayes wiederum eingesetzt, womit wird die Gleichung~\ref{Gleichung:Ableitung_02} zu
\begin{equation}
	\label{Gleichung:Ableitung_03}
	bel_t(m_i)=\frac{p(z_t|m_i)p(m_i|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(m_i|z_t)p(z_t)p(m_i|z_{1:t-1})}{p(m_i)p(z_t|z_{1:t-1})}
\end{equation}
Analog dazu hat der gegenteilige Zustand den Glauben
\begin{equation}
	\label{Gleichung:Ableitung_04}
	bel_t(\overline{m_i})=1-bel_t(m_i)=\frac{p(z_t|\overline{m_i})p(\overline{m_i}|z_{1:t-1})}{p(z_t|z_{1:t-1})}=\frac{p(\overline{m_i}|z_t)p(z_t)p(\overline{m_i}|z_{1:t-1})}{p(\overline{m_i})p(z_t|z_{1:t-1})}
\end{equation}
Dividiert Gleichung~\ref{Gleichung:Ableitung_03} durch der Gleichung~\ref{Gleichung:Ableitung_04}, so ergibt sich
\begin{equation}
	\label{Gleichung:Ableitung_05}
	\frac{bel_t(m_i)}{1-bel_t(m_i)}=\frac{p(m_i|z_t)}{1-p(m_i|z_t)}\frac{p(m_i|z_{1:t-1})}{1-p(m_i|z_{1:t-1})}\frac{1-p(m_i)}{p(m_i)}
\end{equation}
Die Gleichung~\ref{Gleichung:Ableitung_05} bietet eine perfekte mathematische Darstellung bzw. Erklärung an, was die Angaben und die Ausgabe des binären Bayes-Filters sind. Die Ausgabe ist das Glauben bzw. die A-posteriori-Wahrscheinlichkeit eines Ereignis, dass die Zelle $m_i$ belegt ist, welches den Term $bel_t(m_i)$ in Gleichung~\ref{Gleichung:Ableitung_05} entspricht. Der Term ${p(m_i|z_t)}$ ist, wie oben erzählt, das inverses Sensormodell. Es ist ersichtlich, dass eine bedeutende Zusammenhang zwischen dem Modell bzw. der Beschreibung des Modells und den Arten der Sensoren. Darauf wird in Abschnitt ~\ref{Abschnitt:Sensor} mit der Erfassung des Umgebung vertieftet eingegangen. Der Term $p(m_i|z_{1:t-1})$ beweist dabei die wichtige Eingenschaft des binären Bayes-Filters, dass das Verfahren der Schätzung auf Rekursion beruht. Die Anfangsbedingung bzw. die A-priori-Wahrscheinlichkeit ist als der Term $p(m_i)$ in Gleichung~\ref{Gleichung:Ableitung_05} bezeichnet. Die A-priori-Wahrscheinlichkeit gibt den Glauben an, vordem alle Messdaten von Sensorik berüchtigt werden. Typischerweise wird bei Occupancy Grid anfänglich $p_(m_i)$ den Wert 0,5 gegeben, weil es keine Information über die Belegungszustand gibt. Die Wahrscheinlichkeit, dass eine Gitterzelle belegt ist, ist die gleichen wie die, dass sie nicht belegt ist. Daher wird die Gleichung ~\ref{Gleichung:Ableitung_05} zu
\begin{equation}
	\label{Gleichung:Ableitung_06}
	bel_t(m_i)=\frac{Y}{Y+1}
\end{equation}
mit
\begin{equation}
	\label{Gleichung:Ableitung_07}
	Y=\frac{p(m_i|z_t)}{1-p(m_i|z_t)}\frac{p(m_i|z_{1:t-1})}{1-p(m_i|z_{1:t-1})}
\end{equation}
Zusammenfassend ist das gitterbasierte Modell eignet für statische Umgebung im urbanen Raum. Außerdem bietet das Modell einen Vorteil, neben belegte Objekte einen Freiraum zu modellieren, was eine Grundlage der darauffolgenden Navigation schaffen.
\subsubsection{Hybride Umfeldmodelle}
Um ein Umfeld zu modellieren, welches komplizierte Szenarien repräsentieren kann, ist selbstverständlich Hybride Umfeldmodelle aufgefordert. Dadurch lassen sich die Einschränkung von jedem grundlegenden Modell eliminieren und die Vorteilen ausnutzen. Es gibt unterschiedliche Kriterien und Methoden um ein hybrides Umfeldmodell zu bilden. Das Modell, das~\cite{.0612201908122019} angeht, ist ein populäres Beispiel von hybriden Umfeldmodellen. Im Prinzip ist das Modell eine Kombination von einem objektbasierten Umfeldmodell und einem gitterbasierten Umfeldmodell. Hierbei beschreibt das objektbasierte Umfeldmodell dynamische Objekte, wohingegen das gitterbasierten Umfeldmodell bzw. Occupancy-Grid-Map den statischen Raum darstellen. Auf dieser Weise ist das fusionierte Modell generell in der Lage eine Umgebung, wo sich dynamische und statischen Objekte befinden, vollständig und zutreffend zu beschreiben. Darüber hinaus kann die objektbasierte Umfeldmodellierung mit aktueller Technik z.B. Deep-Learning präziser und effizienter durchgeführt werden, während die semantische Navigation noch direkt im gitterbasierten Umfeldmodell verlaufen kann\cite{.0612201908122019}. Wird die Umgebung im Rahmen dieser Arbeit als ein statisches Umfeld betrachtet, wird ein Hybrides Umfeldmodell wegen Komplexität und Überflüssigkeit nicht angewandt.
\subsection{Sensorik und ihr inverses Sensormodell}
\label{Abschnitt:Sensor}
Zweifellos dient eine Wahrnehmung bzw. eine Erfassung als eine wichtige Voraussetzung zur Umfeldmodelleirung, weil sie die Informationsquelle bietet. Wahrnehmung eines Fahrzeugs besteht wesentlich aus die Bestimmung der eigenen Position samt Orientierung und die Erfassung der Umgebung um das eigenen Fahrzeug. Die Lokalisierung ist im Rahmen dieser Arbeit nebensächlich und durch die vorgegebene GPS-Information bestimmt. Darauf soll an dieser Arbeit nicht näher eingegangen werden.
\subsubsection{Überblick über verschiedene Sensoren zur Umfeldmodellierung}
Um ein zuverlässiges Umfeldmodell zu entwickeln und danach das Modell in Praxis effektiv umzusetzen, spielt einer Auswahl der erfassenden Sensoren entweder in Akademie oder in Industrie eine große Rolle. Die wichtigsten und am weitverbreitetsten Fahrzeugsensoren zur Wahrnehmung der Umgebung sind Kameras, fernes Infrarot- (engl.Far-infrared, als FIR abgekürzt) Radar-, LiDAR (Light Detection and Ranging) - und Ultraschallsensoren. Nach~\citep{Mohammed.2020} sind die Vorteilen neben der Nachteilen in Tabelle~\ref{tab:Vergleich der Sensoren} aufgelistet.
\begin{longtable}{|m{0.15\textwidth}<{\centering}|m{0.4\textwidth}<{\centering}|m{0.4\textwidth}<{\centering}|}
	\caption{Vorteile und Nachteile von Kamera, fernes Infrarotsensor,  Radar-, Ultraschall- und Lidarsensor~\citep{Mohammed.2020}}
	\centering
	\label{tab:Vergleich der Sensoren}
	\endfirsthead
	\endhead
	\hline	
	\textbf{Sensor} & \textbf{Vorteile} & \textbf{Nachteile}\\ \hline
	Kamera& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine hohe Auflösung und Farbskalen über das gesamte Sichtfeld haben 
		\item eine farbenfrohe Perspektive der Umgebung bieten 
		\item eine 3D-Geometrie von Objekten bei Stereokameras bereitstellen
		\item kostengünstig Im Vergleich zu Lidar sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item ein leistungsfähiges Berechnungssystem benötigen, um nützliche Daten zu extrahieren 
		\item empfindlich auf starken Regen, Nebel und Schneefall reagieren 
		\item eine 3D-Geometrie von Objekten bei Stereokameras bereitstellen
		\item begrenzte Reichweite besitzen
	\end{itemize} 
	\\ \hline
	
	FIR-Sensor& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item nicht von der Lichtbedingungen und Objektoberflächenmerkmale beeinflusst werden können
		\item eine bessere Sicht durch Staub, Nebel und Schnee als Kameras  haben 
		\item eine horizontale Erfassungsreichweite bis zu 200m oder mehr abdecken 
		\item im Vergleich zu Lidar billiger und kleiner sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item anspruchsvolle Rechenquellen und robuste Algorithmen erfordern
		\item schwierig Ziele in Szenarien mit kaltem Klima zu unterscheiden  
		\item niedrigere Auflösung im Vergleich zur sichtbaren Kamera haben
		\item keine Information über Entfernung bieten
	\end{itemize} 
	\\ \hline
	
	Radarsensor& 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item lange Strecken bei schlechten Sichtverhältnissen vor dem Auto sehen 
		\item klein, leicht und erschwinglich sind 
		\item weniger Strom als ein Lidar-Sensor benötigen
		\item im Vergleich zu Lidar robuster gegen Ausfälle sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine geringe Genauigkeit und Auflösung bieten
		\item begrenzte Informationen  (z. B. weder genaue Form- noch Farbinformationen) bekommen
		\item das Problem wegen der gegenseitigen Beeinflussung von Radarsensoren haben
		\item schlechte Azimut- und Höhenauflösung verfügen
		\item ohne einer Erhöhung der Leistung Radardämpfung zeigen
	\end{itemize} 
	\\ \hline
	
	Ultraschall-\newline sensor & 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item lange Strecken bei schlechten Sichtverhältnissen vor dem Auto sehen 
		\item klein, leicht und erschwinglich sind 
		\item weniger Strom als ein Lidar-Sensor benötigen
		\item im Vergleich zu Lidar robuster gegen Ausfälle sind
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item eine geringe Genauigkeit und Auflösung bieten
		\item begrenzte Informationen  (z. B. weder genaue Form- noch Farbinformationen) bekommen
		\item das Problem wegen der gegenseitigen Beeinflussung von Radarsensoren haben
		\item schlechte Azimut- und Höhenauflösung verfügen
		\item ohne einer Erhöhung der Leistung Radardämpfung zeigen
	\end{itemize} 
	\\ \hline
	
	LiDAR-Sensor & 
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item große Entfernungen vor dem Auto bei guten Sichtverhältnissen erfassen
		\item volle $360^\circ$- und 3D-Punktwolken bieten 
		\item eine gute Genauigkeit und Auflösung haben
		\item keine signifikanten Interferenzen bei mehreren Lidarsensoren haben
	\end{itemize}&
	\begin{itemize}  
		\setlength\itemsep{0em} 
		\item teurer als Radar und Kamera sind
		\item kleine Objekte (wie Drähte und Stangen) nicht entdecken können
		\item eine schlechte Kontrastunterscheidung bei der Erkennung nasser Oberflächen haben
		\item durch unterschiedliche klimatische Bedingungen beeinflusst werden
	\end{itemize} 
	\\ \hline
\end{longtable}
Im Rahmen dieser Arbeit ist die am ifF (Institut für Fahrzeugtechnik) bereits bestehende Fahrzeugarchitektur mit Ibeo LUX Laserscanner versehen. Daher wird folgend in Abschnitt~\ref{Abschnitt:Laserscanner} auf der Mechanismus und das darauf resultierende Sensormodell des Laserscanners eingegangen. Außerdem werden die technische Details bei Einführung der inversen Sensormodellierung vorgestellt, weil die reale technische Größen dabei ein wichtiger Faktor sind.  
\subsubsection{Funktionsprinzip des Lasersensors}
Ist ein angemessenes Sensormodell zu finden, ist es sinnvoll das Mechanismus, die Eingenschaften und die Gründe des Unsicherheit zu untersuchen. Die Angemessenheit hierbei bedeutet, dass eine Abwägung bzw. ein Kompromiss immer nach verschiedenen Anwendungsszenarien gemacht werden muss. 
\\Laserscanner beruht auf dem Prinzip ToF (Time-of-flight). Nach diesem Prinzip wird die Entfernung zwischen dem Ziel und Laserscanner dadurch berechnet, dass die Zeit gemessen wird, die ein Lichtimpuls benötigt, um von der Lichtquelle zum beobachteten Ziel und dann zum Detektor (normalerweise zusammen mit der Lichtquelle) zu gelangen~\citep{Siciliano.2008}. Im Prinzip ist Laserscanner ähnlich wie Radarsensor, wobei nur anstatt Mikrowellen beim Laserscanner Infrarot-, Ultraviolett- oder Strahlen aus dem Bereich des sichtbaren Lichts eingesetzt werden~\citep{Winner.2015}. Mathematische Beschreibung des Prinzips lässt sich in Gleichung~\ref{Gleichung:Tof} darstellen. Dabei bezeichnet d den Abstand zwischen Laserscanner und dem detektierten Objekt. Das Lichtgeschwindigkeit wird als c dargestellt. In einigen hochpräzisen Lasersensoren wird Lichtausbreitungsmedium auch berücksichtigt und dazu wird c der Umgebung gemäß kompensiert. Zeit t benötigt das Licht um die Ausbreitungsstrecke zu decken, die doppelte Entfernung zwischen Laserscanner und Objekt ist. Es wird in der Tat gemessen und in Abstand	d überführt. Der Sensor sendet periodisch Lichtimpulse aus und berechnet eine durchschnittliche Zielentfernung von der Zeit der zurückkehrenden Impulse~\citep{Siciliano.2008}.
\begin{equation}
	\label{Gleichung:Tof}
	d=\frac{c\cdot t}{2}
\end{equation}
Im Bereich des selbstfahrenden Fahren wird der Lichtpuls mit nicht nur eine Ausrichtung ausgestrahlt, weil ein relativ großer Beobachtungsbereich mehrere in unterschiedlichen Richtungen ausgesendet Lichtstrahl benötigt. Aktuell gibt es zwei verschiedenen LiDAR-Systeme. Zum einen ist das feststehende Sensor, in dem mehrere Sende- / Empfangseinheiten mit unterschiedlicher Ausrichtungen angeordnet werden~\citep{Effertz.2009}. Zum anderen ist das rotierende LiDAR-System dadurch realisiert, dass der Lichtimpuls über eine drehbare Spiegeleinheit abgelenkt~\citep{Effertz.2009}. Das in dieser Arbeit verwendete Laserscanner Ibeo-LUX-8L gehört zu dem zweiten Sensorsystem.
\subsubsection{Theorie des inversen Sensormodells}
Ein inverses Sensormodell hat die Aufgabe, den schon in~\ref{Abschnitt:Gitterbasierte Modelle} erwähnten mathematischen Ausdruck $p(m_i|z)$ zu finden, d.h. die Wahrscheinlichkeitsverteilung des Belegungszustands der Zelle mit Index i zu beschreiben. Nach~\citep{Pieringer.2013} lässt sich das inverse Sensormodell im Prinzip in drei Bestandteile zerlegen. Die sind, wie in Abbildung gezeigt, Hinderniskartierung, Freiraummodellierung und Beschreibung unbekannter Gebiete.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/Bestandteile_Sensormodell.pdf}
	\caption{Bestandteile des Prinzips von Inverses Sensormodell }
	\label{fig:Bestandteile_Sensormodell}
\end{figure}
\\Unter Hinderniskartierung werden das Verfahren verstanden, dass die vom Sensor detektierten Objekte in das gitterbasierte Umfeldmodell bzw. das Occupancy Grid Map eingebracht werden~\citep{Pieringer.2013}. Zwei Probleme sind in diesem Bestandteil des inversen Sensormodell zu lösen. Zum einen gewinnt es die Relevanz, welche Form für das detektierte Objekt bzw. das Hindernis angenommen wird~\citep{Pieringer.2013}. Die Form (z.B. Linie oder Ellipse), die das Hindernis repräsentiert, ist theoretisch eng mit Unsicherheitsquellen des Laserscanners verbunden. Jedoch wird die Form in der Praxis ausgewählt unter Berücksichtigung der Ausführlichkeit bzw. Genauigkeit und Echtzeitanforderung. Zum anderen ist das Problem, mit welchem Zahlenwert die Wahrscheinlichkeit der kartierten Zelle erfüllt ist. Diese zwei Probleme werden folgend bei der tatsächlichen Sensormodellierung vertieftet eingegangen.
\\Bei Freiraum handelt sich um den beobachtbaren Bereich zwischen Sensor und dem detektieren Objekt. Analog zur Hinderniskartierung stehen die Bestimmung von der Form des Freiraums und der Wahrscheinlichkeit der betreffenden Zelle in Zentrum der Freiraummodellierung. Jedoch ist die Form des Freiraums abhängig von der oben bestimmten Hindernisform. Beispielweise wird der Freiraum als Linie oder Dreiecke modelliert, wenn die Hindernisse punktförmig oder linieförmig beschrieben werden. Bei Wahrscheinlichkeitsverteilung über den Freiraum spielt die Gründe der Unsicherheit eine große Spiele. Zum Beispiel wird die von Laserscanner erfasste Entfernungsinformation von dem Hindernis mit zunehmender Distanz weniger sicher. Auf diesem Grund ist dabei ein Modell zu entwickeln, die Unsicherheit in gewissem Grade widerspiegeln kann. In Anwendung sind ebenso die Korrektheit und die Zeitaufwand zu gewichten.
\\Der sich innerhalb der Reichweite von Laserscanner befindende Raum, der weder Hindernis noch Freiraum ist, ist der unbekannte Bereich des Modell. Ein typisches Beispiel dafür ist der Raum hinter dem Hindernis. Normalerweise wird der Wahrscheinlichkeit der unbekannten Zell die A-priori-Wahrscheinlichkeit zugewiesen. Der Grund liegt darin, dass keine neue Informationen über den Belegungszustand eingegeben werden. Typischerweise wird die A-priori-Wahrscheinlichkeit bzw. die Wahrscheinlichkeit der unbekannte Zellen als $0,5$ zugewiesen.
\subsubsection{Technische Details von Ibeo-LUX-8L}
In die am IfF bereits bestehende Fahrzeugarchitektur ist Laserscanner Ibeo-LUX-8L von Ibeo Automotive Systems GmbH für Erfassung der Umgebung um das selbstfahrende Fahrzeug verwendet. Um ein angemessenes Sensormodell für das Laserscanner zu entwickeln, ist es voraussetzt, dass die technische Details von dem Sensor zur Verfügung steht.
\\
\begin{table}[ht]
	\caption{Tabular technische Details von Ibeo LUX 8L}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Technische Daten} & \textbf{Wert}\\
		\hline
		Reichweite & 50m mit $10\%$ Remission\\
		\hline
		Genauigkeit & 10cm\\
		\hline
		Entfernungsauflösung & 4cm\\
		\hline
		Horizontaler Öffnungswinkel & $110^\circ ?50^\circ bis -60^\circ?$ \\
		\hline
		Vertikaler Öffnungswinkel & $6.4^\circ$\\
		\hline
		Horizontale Winkelauflösung & $0.25^\circ$\\
		\hline
		Vertikale Winkelauflösung & $0.8^\circ$\\
		\hline
		Bildrate & 25.0 Hz\\
		\hline
		Multi-Layer & 8 (2 Paare von 4 Layers)\\
		\hline
		Ausgabe & Roh- und Objektdaten\\
		\hline
		Abmaße (B$\times$T$\times$H) & 164,5$\times$93,2$\times$88mm\\
		\hline
		Gewicht & 998,7g\\
		\hline
	\end{tabular}
\end{table}
