\section{Implementierung}
\label{Kapitel:Implementierung}
Basierend auf den theoretischen Grundlagen von Kapitel~\ref{Kapitel:Theoretische Grundlagen} liegt der Schwerpunkt dieses Kapitels auf der tatsächlichen Implementierung des Umfeldmodells im Ros-System. Darüber hinaus werden einige Features für die Erweiterung des System oder die Integration von anderen Funktionen hinzugefügt.

\subsection{Versuchsfahrzeug}
Bevor mit Implementierung des in Kapitel~\ref{Kapitel:Theoretische Grundlagen} entwickelten Umfeldmodells begonnen wird, werden die relevanten Informationen über das Versuchsfahrzeug mitsamt die darin eingebauten Sensoren dokumentiert und in der eigentlichen Implementierung parametriert.
\subsubsection{Dimension über Versuchsfahrzeug}
\label{Abschnitt:DimensionVonAuto}
Bei Implementierung im Rahmen dieser Arbeit ist es auch bedeutungsvoll, die Position bzw. den belegten Raum des Versuchsfahrzeugs zu modellieren und dokumentieren, was einen konkreten Beitrag zur kollisionsfrei Navigation leistet. Außerdem ist die Information über die Anordnung der Lasersensoren eng verbunden mit der Abmessung des Fahrzeugs. Daher wird die Dimension des Fahrzeugs als ein wichtiges Element betrachtet. Die Abbildung~\ref{fig:DimensionVonAuto} zeigt, dass die wichtige Größen von Abmessung des Fahrzeugs parametriert werden. Obwohl die Zeichnungsbemaßung eigentlich redundant ist, wird sie mit Absicht angewendet, um die Darstellung der wichtigen Größen sichtbar zu machen. Der Rot Punkt bezeichnet hierbei die Koordinatenursprung des Fahrzeugkoordinatensystem und befindet sich mittig auf der Hinterachse~\citep{Hegerhorst.2018}. Die X-Achse des Fahrzeugkoordinatensystem zeigt die Längsrichtung des Fahrzeugs nach vorne~\citep{Hegerhorst.2018}. Die Y-Achse verläuft senkrecht zur X-Achse und zeigt nach links des Fahrtrichtung. Die Koordinatenursprung dient als ein Bezugspunkt und die Größen, z.B. die Lage eines Sensors sowie die Position eines detektierten Objekts, werden nur relativ zu dem Bezugssystem bzw. Fahrzeugkoordinatensystem angegeben. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/DimensionVonAuto.pdf}
	\caption{Dimension von Versuchsfahrzeug}
	\label{fig:DimensionVonAuto}
\end{figure}
\\In ifF stehen Golf7 (TIAMO) und Passat Alltrack (TEASY 3) als Versuchsfahrzeuge zur Verfügung\citep{Hegerhorst.2018}. Die der Abbildung~\ref{fig:DimensionVonAuto} entsprechenden Abmessungen von diesen Versuchsfahrzeugen werden in Tabelle~\ref{tab:Abmessung von Versuchsfahrzeuge} aufgelistet.
\begin{table}[ht]
	\caption{Abmessung von Versuchsfahrzeuge}
	\label{tab:Abmessung von Versuchsfahrzeuge}
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Abmessung} & \textbf{Golf 7 (TIAMO)} & \textbf{Passat (TEASY 3)}\\
		\hline
		L & $4.3$ & $4.6$\\
		\hline
		W & $1.8$ & $1.6$\\
		\hline
		D2F & $3.5$ & $3.6$\\
		\hline
		D2E & $0.8$ & $1.0$\\
		\hline
		D2L & $0.9$ & $0.8$\\
		\hline
		D2R & $0.9$ & $0.8$\\
		\hline
	\end{tabular}
\end{table}
\subsubsection{Einbauposition der Ibeo-Laserscanner}
Die Anzahl und die Anordnung der im Versuchsfahrzeug installierten Laserscanner dienen auch als wichtigen Parametern bei Implementierung, denn diese Informationen liefern den Startpunkt des Strahls jedes Sensors. In Abbildung~\ref{fig:DimensionVonAuto} sind die Einbauposition und der Erfassungsbereich jedes Sensors dargestellt. Dazu werden die tatsächlichen Werte in Tabelle~\ref{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei TIAMO} und Tabelle~\ref{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat} gegeben. In den Tabellen bezeichnet x die x-Koordinate im Fahrzeugkoordinatensystem und b die y-Koordinate. Der Winkel $\theta$ beschreibt die ausgesandte Richtung des Anfangsstrahls. Der Anfangsstrahl jedes Laserscanners ist gegen den Uhrzeigersinn zur Endstrahl. Der Winkelbereich des Erfassungsraum des Sensors ist nach der Tabelle~\ref{tab:technische Details von Ibeo LUX} auf $110^\circ$ begrenzt. Dieser Wert wird in der Praxis entsprechend der Performance des Umfeldmodells angepasst.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/AnordnungDerLaserscanner.pdf}
	\caption{Einbauposition und Erfassungsbereich der Ibeo-Laserscanner}
	\label{fig:AnordnungDerLaserscanner}
\end{figure}
\begin{table}[ht]
	\caption{Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Golf 7 (TIAMO))}
	\label{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei TIAMO}
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Sensor ID} & \textbf{x (m)} & \textbf{y (m)} & \textbf{Winkel $\theta$ des Anfangsstrahls ($^\circ$)}\\
		\hline
		1 & $3$ & $-0.9$ & $-10$\\
		\hline
		2 & $3$ & $0.9$ & $80$\\
		\hline
		3 & $-0.7$ & $0.9$ & $170$\\
		\hline
		4 & $-0.7$ & $-0.9$ & $-100$\\
		\hline
	\end{tabular}
\end{table}
\begin{table}[ht]
	\caption{Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat (TEASY 3)}
	\label{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat}
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Sensor ID} & \textbf{x (m)} & \textbf{y (m)} & \textbf{Winkel $\theta$ des Anfangsstrahls ($^\circ$)}\\
		\hline
		1 & $3.3$ & $-0.8$ & $-35$\\
		\hline
		2 & $3.6$ & $0$ & $45$\\
		\hline
		3 & $3.3$ & $0.8$ & $125$\\
		\hline
		4 & $-0.5$ & $0.8$ & $145$\\
		\hline
		5 & $-1$ & $0$ & $-135$\\
		\hline
		6 & $-0.5$ & $-0.8$ & $-55$\\
		\hline
	\end{tabular}
\end{table}
\subsection{Framework ROS zur Implementierung}
Eine der zentralen Aufgaben dieser Arbeit handelt sich um die Konvertierung von dem am IfF bereits bestehenden MATLAB/Simulink-Modell nach~\ac{ROS}. \ac{ROS} ist ein Framework zum Schreiben von Robotersoftware. Es handelt sich um eine Sammlung von Tools, Bibliotheken und Konventionen, die darauf abzielen, die Erstellung komplexer und robuster Roboterverhalten auf einer Vielzahl von Roboterplattformen zu vereinfachen\citep{Quigley.2015}. Obwohl diese Idee aus dem Bereich der Robotik stammt, machen ihre verschiedenen guten Eigenschaften ihre Investition in den Bereich des autonomen Fahrens sehr bedeutsam. Um eine klare Programmstruktur und eine genaue und effiziente Umsetzung des in Kapitel~\ref{Kapitel:Theoretische Grundlagen} genannten Umfeldmodells zu erhalten, ist eine kurze Einführung in die ROS-Grundlagen und Funktionsmodule in Bezug auf diesen Artikel erforderlich.
\subsubsection{Grundlagen der ROS-Architektur}
Die ROS-Architektur, die in Abbildung~\ref{fig:ROS-Architektur} dargestellt, wurde entworfen und in drei Abschnitte oder Konzeptebenen unterteilt, welche sich um die Dateisystemebene (engl. The Filesystem level), die Berechnungsdiagrammebene (engl. The Computation Graph level) und die Community-Ebene (engl. The Community level) handeln~\citep{Fernandez.2015}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/ROS-Architektur.pdf}
	\caption{ROS-Architektur}
	\label{fig:ROS-Architektur}
\end{figure}
\\Auf der Dateisystemebene wird eine Gruppe von Konzepten verwendet, um zu erklären, wie ROS intern gebildet wird. Ähnlich wie bei einem Betriebssystem ist ein ROS-Programm in Ordner unterteilt, und diese Ordner enthalten Dateien, die ihre Funktionen beschreiben~\citep{Fernandez.2015}. Hierbei sind die wichtigen Konzepte zu diesem Artikel Package und Metapackage. Das Package ist die zentrale und grundlegende Dateiorganisationseinheit, die Programmierfunktionen in ROS vollständig realisieren kann. Es enthält im Allgemeinen ROS Laufzeitprozess (engl. runtime process), Quellcode (engl. Sourcecode), Konfigurationsdateien (engl. configuration files) und das Package-manifest, das zur Bereitstellung von Informationen von build-dependencies, run-dependencies und Lizenz verwendet wird. Metapackages werden in der Regel nach einer ähnlichen Funktionalität gruppiert. Andere Grundkonzepte und Begriffe auf dieser Ebene sind aufgrund der Länge des Artikels nicht detailliert und finden sich in~\citep{Fernandez.2015}\citep{Koubaa.2016}.
\\Die Berechnungsdiagrammebene ist die relevanteste Ebene für diese Arbeit, auf der die Kommunikation zwischen Prozessen und Systemen stattfindet. Die Grundkonzepte auf dieser Ebene sind, wie in Abbildung~\ref{fig:Berechnungsdiagrammebene} dargestellt, Nodes, ROS-Master, Parameter Server, Messages, Topics, Services und ROS-Bags, die alle Daten auf unterschiedliche Weise für das Diagramm bereitstellen~\citep{Fernandez.2015}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Berechnungsdiagrammebene.pdf}
	\caption{Wesentliche Grundkonzepte von Berechnungsdiagrammebene}
	\label{fig:Berechnungsdiagrammebene}
\end{figure}
Nodes sind ausführbare Dateien (engl. executables) in ROS und vervollständigen die erwartete Funktion und die zugehörigen Berechnungen. Die Nodes können miteinander kommunizieren und Daten übertragen. Daher gibt es im Allgemeinen mehrere Nodes in einem System, die unterschiedliche Funktionen ausgeführt haben. Der Datenaustausch zwischen Nodes erfolgt über Messages. ROS verwendet eine vereinfachte Nachrichtenbeschreibungssprache, um die Datenwerte zu beschreiben, die von Nodes publiziert (engl. published)~\citep{Fernandez.2015}. Damit kann ROS den richtigen Quellcode für diese Nachrichtentypen in mehreren Programmiersprachen (z.B. C++ oder Python) generieren. Zahlreiche vordefinierte Messages in ROS können direkt zum Übertragen von Daten oder zum Erstellen neuer aufgabenorientierter Messages verwendet werden. Dies erfolgt durch Definieren einer Datei mit .msg-Extension. Wenn ein Node Daten sendet, heißt es, dass das Note eine Topic publizieren. Ein anderer Knoten kann die Topic abonnieren (engl. subscribe), um die Daten abzurufen. Ein Node kann eine Topic nur abonnieren, wenn es denselben Message-Typ hat. Eine Topic kann verschiedene Subsribers und auch verschiedene Publishers haben. Wenn die Kommunikation zwischen Nodes empfangen und beantwortet (engl. receive and reply) werden muss, sollten Services anstelle von Topics verwendet werden. Services geben den Entwicklern die Möglichkeit, mit Nodes zu interagieren. Mit Parameter Server ist es möglich, Schlüssel zu verwenden, um Daten an einem zentralen Ort zu speichern und Nodes während der Ausführung zu konfigurieren oder die Nodes der Knoten zu ändern~\citep{Fernandez.2015}. Die oben genannte Kommunikation garantiert ROS-Master, der jede Nodes verwalten. Nodes werden zuerst beim Master registriert, und dann integriert der Master Nodes in das gesamte ROS-Programm. Auf diesem Grund besteht der erste Schritt darin, den Master zu starten, wenn das ROS-Programm gestartet wird. ROS-Bag ist ein Format zum Speichern und Wiedergeben aller Informationen der Messages, Topics und Services, die gewünscht werden. In dieser Arbeit wird ROS-Bag verwendet, um die Sensordaten von dem Versuchsfahrzeug zu speichern. Wenn das ROS-Bag wiedergegeben ist, simuliert es die Datenwerte von Sensoren zu messen und erfassen, was ist praktisch zum Debuggen von Implementierungsalgorithmus.
\\Die Konzepte auf ROS-Community-Ebene sind die ROS-Ressourcen, die es separaten Communities ermöglichen, Software und Wissen auszutauschen~\citep{Fernandez.2015}. Zu den Ressourcen gehören unter anderem ROS-Repositories,ROS-Distributions und ROS-Wiki. Jedoch hat diese Ebene für diesen Artikel nur eine sehr geringe Relevanz. Auf diesem Grund ist die Auseinandersetzung damit im Rahmen dieser Arbeit zu verzichten.
\\Aufgrund des oben erwähnten Mechanismus und der Philosophie von ROS hat der Aufbau der Implementierung des Umfeldmodell auf ROS einen starken Vorteil. Die dezentrale Kommunikationsmethode macht das Implementierungssystem klarer und einfacher. Außerdem sind Fehler im System leichter zu finden und sortieren. Die Aufteilung zwischen verschiedenen Funktionen erleichtert die spätere Systemerweiterung, z.B. Navigation bzw. kollisionsfreie Pfadplanung. Im Rahmen dieser Arbeit ist für die Implementierung ROS-Kinetic-Kame mit Ubuntu 16.04 (Xenial) in Benutzung.
\subsubsection{Visualisierung des Umfeldmodells in ROS}
\label{Visualisierung des Umfeldmodells in ROS}
Die Visualisierung des Modells ist ebenso wichtig wie seine Einrichtung und Implementierung. Eine gute Visualisierung spiegelt den tatsächlichen Betriebsstatus des Modells hervorragend wider. Dies hilft bei der Behebung von Programmfehlern und beim Datenaustausch mit anderen Funktionsmodulen oder Modellen im nachfolgenden Systemerweiterungsprozess. Das ROS-System bietet eine Vielzahl von Tools zur Datenvisualisierung und zum Debuggen. Das wichtigste und am weitesten verbreitete ist RVIZ. rviz ist ein 3D-Visualisierungswerkzeug von ROS, mit dem Sensordaten und Statusinformationen visualisiert werden. RVIZ unterstützt umfangreiche Datentypen, die durch Laden verschiedener Display-Typen visualisiert werden. Jeder Display hat einen eindeutigen Namen. Wichtige Display-Typen und ihre entsprechenden Message-Typen im Bereich des autonomen Fahrens sind in Tabelle~\ref{tab:RVIZ Display-Typen} aufgeführt. Aufgrund der Philosophie des verteilten Software-Frameworks von ROS muss das RVIZ-Visualisierungstool nur den passenden Message-Typ und die passende Topic auswählen, wenn Daten auf einer Topic visualisiert werden sollen.
\begin{table}[ht]
	\caption{Display-Typen und ihre entsprechenden Message-Typen in RVIZ}
	\label{tab:RVIZ Display-Typen}
	\small
	\centering
	%\setlength\tabcolsep{2pt}
	\begin{tabular}{|c|c|c|}
		
		\hline
		\textbf{Display-Typ} & \textbf{Message-Typ} & \textbf{Beschreibung}\\
		\hline
		Grid Cells & nav\_msgs/GridCells & Zellen aus einem Raster\\
		\hline
		Point Cloud 2 & sensor\_msgs/PointCloud2 & Daten aus einer Punktwolke\\
		\hline
		Map & nav\_msgs/OccupancyGrid & eine Karte in der Grundebene\\
		\hline
		Path & nav\_msgs/Path & ein Pfad\\
		\hline
		Pose & geometry\_msgs/PoseStamped & eine 3D-Pose\\
		\hline
		Pose Array & geometry\_msgs/PoseArray &mehrere Posen\\
		\hline
		Image & sensor\_msgs/Image & ein neues Rendering-Bild\\
		\hline
		Laser Scan & sensor\_msgs/LaserScan & Daten von einem Laserscan\\
		\hline
		Odometry & nav\_msgs/Odometry & Kilometerzähler-Posen aus der Zeit\\
		\hline
		TF & tf2\_msgs/TFMessage & die Koordinatentransformation\\
		\hline
	\end{tabular}
\end{table}
\\Für das auf diesen Artikel bezogene Umgebungsmodell gibt es zwei grundlegende Visualisierungsoptionen. Zum einen ist Display-Typ Map, das nav\_msgs/OccupancyGrid message anzeigt. Die Informationen in nav\_msgs/OccupancyGrid umfassen die Koordinaten des ursprünglichen Standorts, die Auflösung sowie die Länge und Breite der Karte und die Kartendaten (engl. Map data) in jeder Gitterzelle. Map data werden in zwei Situationen betrachtet. Einer ist, dass der Belegungszustand unbekannt ist und der Wert in diesem Fall -1 ist. Die andere ist, dass die Wahrscheinlichkeit der Belegung bekannt ist und der Wert in diesem Fall 0 bis 100 beträgt. Wie in Abbildung~\ref{fig:Display_Map} gezeigt, wenn Map value von einer Gitterzelle -1 ist, wird die Zellenfläche ausgegraut dargestellt. Wenn Map Value von 0 auf 100 steigt, verändert sich die entsprechende Zelle in einem Farbverlauf von Weiß zu Schwarz.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Display_Map.pdf}
	\caption{Display mit Map}
	\label{fig:Display_Map}
\end{figure}
\\Die zweite Möglichkeit der Visualisierung eines Umfeldmodells in RVIZ ist die Verwendung von GridCells. Dies darstellt die Daten von Message-Typ nav\_msgs/GridCells. Darin handelt sich um die Informationen über die Länge und Breite sowie die Koordinaten jeder Zelle. GridCells-Display ist nur für die Visualisierung des vom Entwickler angegebenen Bereichs verantwortlich. Es ist von der Belegungswahrscheinlichkeit getrennt und wird einfach, leicht und flexibel. Je nach Aufgabe des Entwicklers oder Debugging-Anforderungen können unterschiedliche Wahrscheinlichkeitsbereiche angezeigt werden. Darüber hinaus ermöglicht es einen starken Kontrast von Farben mit unterschiedlichen Belegungswahrscheinlichkeiten. Im Gegensatz dazu ist die Graustufendarstellung von dem oben erwähnten Map nicht offensichtlich und für die Programmentwicklung und die Erkennung der Datenkorrektheit nicht geeignet. Ein Anwendungsbeispiel besteht darin, wie in Abbildung~\ref{fig:Display_GridCell} gezeigt, Gitterzellen mit unterschiedlichen Belegungswahrscheinlichkeiten in verschiedenen Topics zu organisieren und dann die verschiedenen Topics mit verschiedenen offensichtlichen Farben zu visualisieren. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Display_GridCell.pdf}
	\caption{Display mit GridCell}
	\label{fig:Display_GridCell}
\end{figure}
Neben der Flexibilität bietet GridCells-Display einige gute Vorteile gegenüber Map-Display. Zunächst kann die jeder Gitterzelle zugewiesenen zusätzlichen Informationstypen und -werten selbst definiert werden, was eine direktere Bedingung für die zukünftige Erweiterung und Verbesserung des Modells darstellt. Selbst wenn nur die Belegungswahrscheinlichkeit zu berücksichtigen ist, kann die Wahrscheinlichkeit (0 bis 100) als Ganzes betrachtet werden, anstatt den Wert -1 allein zu verwenden bzw. umrechnen, um das Unbekannte auszudrücken. Darüber hinaus erleichtert die Verwendung von GridCells-Display die anschließende Binärisierung von Werten und Bildern. Wie in Abbildung~\ref{fig:Dispaly_Grid_Cell_Binary} gezeigt, kann die Binärisierung durch Einstellen des Schwellenwerts, der durch Experimente oder Deep-Learning erhalten wurde, leicht erzielt werden. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Dispaly_Grid_Cell_Binary.pdf}
	\caption{Display mit GridCell nach Binärisierung}
	\label{fig:Dispaly_Grid_Cell_Binary}
\end{figure}
Daher im Rahmen dieser Arbeit wird GridCells-Display verwendet, um eine Visualisierung zu erreichen. Es gibt aber ein kleines Problem, das bei der Verwendung von GridCells besondere Aufmerksamkeit und Lösung erfordert. Durch tatsächliche Experimente ist bekannt, dass bei sehr großen Positionskoordinaten von GridCells (z. B. 10 bis 6 Potenzen) die Darstellung von Gitterzellen in RVIZ deformiert wird oder sogar verschwindt. Daher können bei der Implementierung des Modells die vom GPS erhaltenen UTM-Koordinateninformationen nicht direkt als Koordinaten für die Anzeige der Gitterzellen verwendet werden. Vor der eigentlichen Visualisierung werden zwei Abweichungen X\_VISUAL\_OFFSET und Y\_VISUAL\_OFFSET so eingestellt, dass der Koordinatenwert der Zellen nahe am Ursprung liegt, wodurch die Genauigkeit der Visualisierung sichergestellt wird. Dieses Abweichungspaar wird durch die anfänglichen Fahrzeugkoordinateninformationen bestimmt, die bei der Initialisierung des Modells erhalten werden, was sich in der nächsten Erläuterung des Funktionsblocks widerspiegelt.

\subsection{Koordinatensysteme}
Daten von verschiedenen Informationsquellen bzw. Sensoren sind häufig mittels unterschiedlichen Koordinatensystemen gegeben. Auf diesem Grund wird die Konvertierung zwischen verschiedenen Koordinatensystemen bei der Realisierung des Umfeldmodells oft durchgeführt. Hierbei gibt es 3 wesentliche Koordinatensysteme, deren Klärung für das Verständnis der nachfolgenden Funktionsbausteine dieser Arbeit sehr hilfreich ist. Wie in Abbildung~\ref{fig:Koordinaten3} gezeigt, sind diese 3 Koordinatensysteme Weltkoordinatensystem (engl. Global Coordinate System, als \ac{GCS} abgekürzt), Ankerkoordinatensystem (engl. Anchor Coordinate System, als \ac{ACS} abgekürzt) und Fahrzeugkoordinatensystem (engl. Vehicle Coordinate System, als \ac{VCS} abgekürzt).
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Koordinaten3.pdf}
	\caption{3 wesentliche Koordinatensysteme im Umfeldmodell}
	\label{fig:Koordinaten3}
\end{figure}
\subsubsection{\ac{GCS}}
\label{Abschnitt:GCS}
Das Weltkoordinatensystem ist das grundlegendste Koordinatensystem. Die vom GPS-Sensor erhaltenen Informationen zur Fahrzeugpose basieren auf dem Weltkoordinatensystem. Im tatsächlichen Gebrauch sind dafür zwei Umrechnungen erforderlich. Das erste ist die Notwendigkeit, die Abweichung zwischen dem Ursprung des Fahrzeugkoordinatensystems (der Mitte der Hinterachse des Fahrzeugs) und dem tatsächlichen Standort der GPS-Antenne (einer bestimmten Position auf dem Dach) zu kompensieren. Außerdem ist die Beschreibung bzw. die Berechnung der geographischen Koordinaten mittels UTM-Koordinatensystem (von englisch Universal Transverse Mercator coordinate system) notwendig. Diese beiden Berechnungen werden nach~\citep{Hegerhorst.2018} im Vorverarbeitungsprozess unter Verwendung einiger Algorithmen von ifF abgeschlossen und werden hier nicht ausführlich erläutert. Außerdem ist das UTM-Koordinatensystem tatsächlich  ein nordweisendes, rechtsdrehendes Koordinatensystem. Jedoch wird naher in Abschnitt~\ref{Abschnitt:GPS-Information} in ein gebräuchliches, linksdrehendes Koordinatensystem umgerechnet. Im Rahmen dieser Arbeit beziehen sich die Koordinaten im Weltkoordinatensystem auf die verarbeitete bzw. umgerechnete  UTM-Koordinateninformationen.
\subsubsection{\ac{VCS}}
In Abbildung~\ref{fig:Koordinaten3} wird das blaue Rechteck verwendet, um das Fahrzeug einfach darzustellen. Wie in Abschnitt~\ref{Abschnitt:DimensionVonAuto} erwähnt, liegt der Ursprung des Fahrzeugkoordinatensystems in der Mitte der Hinterachse des Fahrzeugs. Die X-Achse des VCS zeigt die Längsrichtung des Fahrzeugs nach vorne. Die Y-Achse verläuft senkrecht zur X-Achse und zeigt nach links des Fahrtrichtung. In dieser Arbeit sind die mittels VCS angegebenen Originaldaten die Punktwolkenpositionsinformationen des Laserscanners.  und der Ausdruck der vom Fahrzeug eingenommenen Position. Darüber hinaus erfordert die Darstellung des vom Fahrzeug abgedeckten Raums auch die Hilfe von Fahrzeugkoordinatensystem. Hierbei ist zu beachten, dass die Koordinateninformation der Punktwolke jedes Laserscanners tatsächlich auf dem unabhängigen Koordinatensystem jedes Laserscanners basiert. Unter dem bestehenden Rahmen von ifF wird jedoch die Umrechnung zwischen jedem Sensorkoordinatensystem und dem Fahrzeugkoordinatensystem somit die Kombinierung aller Sensordaten während der Vorverarbeitung abgeschlossen. Schließlich wird in Form von ROS-Bag die Punktwolke aller Sensoren basierend auf den Koordinateninformationen des Fahrzeugkoordinatensystems bereitgestellt.

\subsubsection{\ac{ACS}}
Ankerkoordinatensystem ist ein Hilfskoordinatensystem, das auf den Erfahrungen von ~\citep{Weiss.1306200715062007}~\citep{Pieringer.2013} basiert. Aufgrund des Speicherbedarfs und der Performance ist es unmöglich und auch unnötig, einen sehr großen Bereich von Umgebungsinformationen aufzuzeichnen und zu aktualisieren. Daher ist ein Wahrnehmungsbereich des Fahrzeugs, wie das schwarze Quadrats in Abbildung~\ref{fig:Koordinaten3} geplant. Dieser Wahrnehmungsbereich befindet sich im engen Raum des Fahrzeugs und bewegt sich mit der Änderung der Positionsinformationen des Fahrzeugs. Um die Position und Größe des Bereichs vollständig anzuzeigen, wird neben der Länge und Breite des Bereichs auch ein Ankerpunkt benötigt. Normalerweise wird dieser Ankerpunkt in der unteren linken Ecke des Wahrnehmungsbereichs eingerichtet. Das mit diesem Ankerpunkt als Ursprung festgelegte Koordinatensystem wird als Ankerkoordinatensystem bezeichnet. Es ist jedoch anzumerken, dass dieses Koordinatensystem nur mit der Position des Fahrzeugs verschoben wird. Die Richtung seiner Koordinatenachse ändert sich nicht, da das rotierende Koordinatensystem Aliasing und geringe Qualität des Umfeldmodells verursacht~\citep{Weiss.1306200715062007}~\citep{Hegerhorst.2018}. Zusätzlich wird innerhalb dieses Bereichs der Raum in eine Gitterzelle diskretisiert,siehe Abbildung~\ref{fig:Diskretisierung der Umgebung}. Der Ursprung des ACS ist der Ausgangspunkt der in Abschnitt~\ref{Abschnitt:Gitterbasierte Modelle} erwähnten Diskretisierung und auch die 0-Stelle des Index. Abbildung ~\ref{fig:Diskretisierung der Umgebung} zeigt auch die Einschränkungen des Umfeldmodells hinsichtlich der Position des Fahrzeugs auf der Karte. Wenn sich die Position des Fahrzeugs nicht wesentlich ändert, muss die Position des Ursprungs des ACS nicht jederzeit aktualisiert werden. Um den Fahrbereich des Fahrzeugs weiter einzuschränken, wird er im Allgemeinen nach~\citep{Weiss.1306200715062007}~\citep{Hegerhorst.2018} als mittlerer Teil der Karte festgelegt. Wenn das Fahrzeug den Bereich verlässt, wird das ACS aktualisiert, wodurch sich der Rechenaufwand verringern. Darüber hinaus wird in dieser Arbeit der Grenzwert des Bereichs parametrisiert und als Schnittstelle für das spätere Verwendung und Weiterentwicklung bereitgestellt.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Diskretisierung der Umgebung.pdf}
	\caption{Anordnung der Position des Autos auf der Karte~\citep{Hegerhorst.2018}}
	\label{fig:Diskretisierung der Umgebung}
\end{figure}
\subsubsection{Zusammenhang zwischen Koordinatensystemen}
Zwischen den oben erläuterten Koordinatensystemen besteht ein Zusammenhang und die Umrechnung zwischen GCS, ACS und VCS gewinnt bei Implementierung des Umfeldmodells große Bedeutung. Wenn die x-Koordinate des Ankerpunkts anchor\_x und die x-Koordinate des Fahrzeugs pos\_x im GCS bekannt sind, wie in Abbildung~\ref{fig:Koordinaten3} gezeigt, kann die x-Koordinate des Fahrzeugs im ACS durch die Formel offset\_x=pox\_x-anchor\_x erhalten werden. Dabei ist die Umrechnung auf der y-Achse ist analog zur x-Achse. \\Darüber hinaus gibt es zwei Punkte, die besondere Aufmerksamkeit erfordern. Das erste ist die Aktualisierung bzw. Initialisierung von ACS. Im Modell wird auch die Zeit diskretisiert, um sich an Computerberechnungen anzupassen. Zu jedem einzelnen Zeitpunkt wird das ACS getestet, ob es aktualisiert werden muss und wie es sich bewegt. Dieser Prozess kann durch das in Abbildung~\ref{fig:ACS_Update} gezeigte Programmablaufdiagramm dargestellt werden. Dabei repräsentieren X\_1 und X\_2 jeweils die linke und rechte Grenze der X-Achse des grün befahrbaren Bereichs in Abbildung~\ref{fig:Diskretisierung der Umgebung}. Y\_1 und Y\_2 repräsentieren jeweils die unteren und oberen Grenzen des Bereichs. Außerdem geben dx und dy als positive Werte die Entfernung an, um die der Ursprung des ACS verschoben werden muss. Diese Werte sind so parametriert, dass sie je nach Anwendungsszenario jederzeit geändert werden können. Dabei beschreiben pox\_x, pox\_y und offset\_x, offset\_y die Position des Fahrzeugs im Weltkoordinatensystem und im Ankerkoordinatensystem. Der Kern des Algorithmus besteht darin, zu überprüfen, ob die Position des Fahrzeugs eine bestimmte Grenze überschritten hat, und sich entsprechend zu bewegen. Wenn beispielsweise offset\_x $>$ X\_2 gilt ist, bedeutet dies, dass die Position des Fahrzeugs die Grenze des befahrbaren Bereichs berührt oder überschritten hat. In diesem Fall bewegt sich der Anker nach rechts, indem der Wert der x-Koordinate erhöht wird, sodass das Fahrzeug immer in der Mitte der Rasterkarte bleibt. Dieser ganze Prozess wird als Funktionsmodul mit der Bezeichnung Update ACS betrachtet und zum Entwerfen der Initialisierung von ACS verwendet, wie in Abbildung~\ref{fig:InitializationOfACS} dargestellt. Die Initialisierung des ACS erfolgt gleichzeitig mit der Initialisierung des gesamten Umfeldmodells. Wenn gültige Fahrzeugpositionsinformationen erhalten werden, werden die Anfangskoordinaten des Fahrzeugs auch der Anfangsposition des Ankers zugewiesen, wodurch die Anzahl der Bewegungen des ACS verringert wird. Anschließend wird mit dem Aktualisierungsmodul die Position des Ankers automatisch angepasst, bis sich die Fahrzeugposition innerhalb des eingestellten Fahrbereichs befindet.
\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{pics/ACS_Update.pdf}
	\caption{Programmablaufplan der Aktualisierung von ACS}
	\label{fig:ACS_Update}
\end{figure}
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/InitializationOfACS.pdf}
	\caption{Initialisierung von ACS}
	\label{fig:InitializationOfACS}
\end{figure}
\\Der zweite Punkt ist, dass Punktwolkeninformationen und die Visualisierung der Fahrzeugkarosseriestruktur von Koordinaten unter VCS in Koordinaten unter ACS umrechnet werden müssen, da der Ausgangspunkt der Diskretisierung Anker ist. Dieser Punkt wird im nächsten Abschnitt zur Verarbeitung von Sensorinformationen ausführlich erläutert. 
\subsection{Verarbeitung von Sensordaten}
\label{Verarbeitung von Sensordaten}
Für das Umfeldmodells in dieser Arbeit sind die beiden wichtigsten Sensorinformationen GPS-Informationen von dGPS-Moduls und Hindernisinformationen von Laserscannern. Unter Verwendung des vorhandenen Frameworks und Algorithmus in IfF werden GPS-Informationen in Form von UTM-Koordinaten angegeben. Wie in Kapitel~\ref{Kapitel:Theoretische Grundlagen} erwähnt, sind im Rahmen dieser Arbeit die beiden Themen Eigenlokalisierung und Umfeldmodellierung entkoppelt, und der Schwerpunkt liegt auf der Umfeldmodellierung. Daher wird hier in Hinsicht auf die Erfassung und Verarbeitung der Daten Laserscannern vertieft eingegangen.
\subsubsection{GPS-Information}
\label{Abschnitt:GPS-Information}
Die wesentliche Information, die GPS liefert, ist die Pose des Fahrzeugs, die die Positionsinformation $pos\_x$ mit $pos\_y$ und Orientierungsinformation $pos\_psi$ enthält. Hierbei ist aber zu beachten, dass das ausgewählte UTM-Koordinatensystem ein nordweisendes, rechtsdrehendes Koordinatensystem ist~\citep{Hegerhorst.2018}. Daher ist es bei der tatsächlichen Verarbeitung erforderlich, den Richtungswinkel in dem in Abschnitt~\ref{Abschnitt:GCS} erwähnten linksdrehendes Koordinatensystem GCS durch Berechnung mittels Formel~\ref{Gleichung:Richtungswinkel umrechnen} zu berechnen. Dabei bezeichnet $car\_get\_psi$ die ursprüngliche Datengröße des Fahrzeugrichtungswinkels. Diese Umrechnungsbeziehung kann auch durch Abbildung dargestellt werden. Diese Umrechnungsbeziehung kann durch Abbildung~\ref{fig:Richtungswinkel umrechnen} visuell dargestellt werden.
\begin{equation}\label{Gleichung:Richtungswinkel umrechnen}
	pos\_psy=-car\_get\_psi+90^\circ
\end{equation}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.4\textwidth]{pics/RichtungswinkelUmrechnen.pdf}
	\caption{Umrechnung des Orientierungswinkels in GCS}
	\label{fig:Richtungswinkel umrechnen}
\end{figure}
\subsubsection{Laserscanner-Information}
\label{Laserscanner-Information}
Die Daten von Ibeo-Laserscanner haben zwei Ausgabeformate. Eines sind Rohdaten, die auf einer Punktwolke basieren, und das andere sind Objektinformationen nach der Verarbeitung von Rohdaten. Die geometrische Form des Objekts ist ein Rechteck. Das vorhandene Framework in IfF verwendet hauptsächlich Objektinformation, um ein Umfeldmodell bzw. eine Rasterkarte zu erstellen. In~\citep{Hegerhorst.2018} werden die Positions- und Größeninformationen von Objekten verwendet, gefolgt von Kartierung statischer Hindernisse. Wie in Abbildung~\ref{fig:KartierungMitObjekt} gezeigt, besteht der Kernschritt des Algorithmus darin, die Pose des Objekts in der Rasterkarte zu bestimmen, es als Punktwolkeninformation zu diskretisieren bzw. umrechnen und schließlich die belegten Zellen zu markieren. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/KartierungMitObjekt.pdf}
	\caption{Kartierungsalgorithmus mit Objektinformation von Laserscanner~\citep{Hegerhorst.2018}}
	\label{fig:KartierungMitObjekt}
\end{figure}
Die Verwendung dieses Ansatzes weist jedoch mehrere Nachteile auf. Wie in Kapitel~\ref{Kapitel:Theoretische Grundlagen} erläutert, besteht einer der Vorteile der Verwendung des gitterbasierten Modells darin, dass es Hindernisse beliebiger Form ausdrücken kann. Bei Verwendung der Objektinformationen werden Hindernisse in diesem Fall jedoch immer durch Rechtecke dargestellt, wodurch dieser Vorteil zunichte gemacht wird. Zweitens werden in tatsächlichen Anwendungen z.B. mehrere diskrete Punkte als kontinuierliches Hindernis falsch eingeschätzt. Außerdem werden die Scanpunkte langer gerader Objekte hart durch einen Box dargestellt und daher in kleinere Boxen aufgeteilt oder gar nicht nicht ausgegeben\citep{Hegerhorst.2018}.  Dies führt zu Ungenauigkeiten und geringer Qualität des Modells. Schließlich erfordert die Verwendung von Objektinformationen einen weiteren Schritt zur Umwandlung in eine Punktwolke, was den Rechenaufwand erhöht. Es ist direkter und natürlicher, die Punktwolkeninformationen des Laserscanners direkt zu verwenden.
\\Als nächstes wird die Verarbeitung von Punktwolkeninformationen mittels des in Abbildung~\ref{fig:PAP_PCL} gezeigte Flussdiagramm ausführlich erläutert. Der Ibeo-Laserscanner liefert über den ROS-Treiber verschiedene Dateninformationen und publiziert diese zu den entsprechenden Topics. Das wichtigste ist, dass Topic $as\_tx/point\_cloud$ Information liefert, deren Messagetyp $sensor\_msgs/PointCloud2$ ist. Es ist anzumerken, dass diese Daten tatsächlich vom Datentyp \textless$pcl::PointXYZL$\textgreater~der \ac{PCL}-Standardbibliothek gekapselt und geliefert werden. Daher wird in der tatsächlichen Codeimplementierung Zeiger (engl. pointer) verwendet, um die 4 Beschreibungsinformationen der Punktwolke in \textless$pcl : : PointXYZL$\textgreater~zu lesen. Sie handelt sich um X-, Y- und Z-Koordinaten des Fahrzeugkoordinatensystems und der Schicht (engl. layer), in der sich die Punktwolke befindet.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.28\textwidth]{pics/PAP_PCL.pdf}
	\caption{Programmablaufplan der Laserscannerdaten}
	\label{fig:PAP_PCL}
\end{figure}
\\Im Versuchsfahrzeug Passat (siehe Abbildung~\ref{fig:AnordnungDerLaserscanner}) sind Sensor 2 und Sensor 5 am Fahrzeug mit Ibeo-LUX-8L ausgestattet. Die restlichen Laserscanner sind Ibeo-LUX-4L. Ibeo-LUX-8L wird tatsächlich durch die Drehung des Objektivs konstruiert, um den vertikalen Erfassungsbereich zu verdoppeln. Wenn es in Kombination mit Ibeo-LUX-4L verwendet wird, ist der Erfassungsbereich zu zwei benachbarten Zeitpunkten bei derselben Frequenz inkonsistent. Beispielsweise ist die bei Zeitpunkt $t_1$ erfasste Punktwolke nur in den Schichten 0 bis 3 verteilt, während die bei $t_2$ erfasste Punktwolke sich einschließlich in den Schichten 4 bis 7 befinden. Diese Inkonsistenz kann durch Binär-Bayes-Filter die Korrektheit und Stabilität des Modells beeinträchtigen. Aus diesem Grund wird im Funktionsblock $Layes Filter$ das Datenframe, das 4 bis 7 Schichten von Punktwolkeninformationen enthält, verworfen. Diese Methode ist direkt und einfach und verbessert nachweislich die Stabilität des Modells.
\\Im Funktionsblock $Change VCS to ACS$ wird die im Fahrzeugkoordinatensystem vorliegende Position jedes Punkt von Punktwolke in Ankerkoordinatensystem umgerechnet. Um die Umrechnung durchzuführen, ist ein~\ac{HCS}, wie in Abbildung~\ref{fig:VCS2ACS} gezeigt, erstellt.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/VCS2ACS.pdf}
	\caption{Darstellung eines Hilfskoordinatensystem}
	\label{fig:VCS2ACS}
\end{figure}
Dann lässt sich die Koordinatenumwandlung in 2 Schritte zerlegen. Der erste Schritt besteht darin, das Referenzkoordinatensystem jedes Punktes von ACS in HCS umzuwandeln. Die mathematische Beschreibung dieses Schritts ist in Gleichung~\ref{Gleichung:RotaionTransform} gezeigt.
\begin{equation}\label{Gleichung:RotaionTransform}
	{}^{H}\textbf{P}_{}={}^{H}\textbf{R}_{V}~{}^{V}\textbf{P}_{}
\end{equation} 
Dabei bezeichnet ${}^{V}\textbf{P}_{}$ und ${}^{H}\textbf{P}_{}$ den Koordinatenvektor eines bestimmten Punktes in VCS bzw. HCS. Die lassen sich mit~Gleichung~\ref{Gleichung:V_P} und~\ref{Gleichung:H_P} beschreiben. 
\begin{equation}
	\label{Gleichung:V_P}
	{}^{V}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{V}{x}_{}\\
		{}^{V}{y}_{}\\
	\end{pmatrix}
\end{equation}
\begin{equation}
	\label{Gleichung:H_P}
	{}^{H}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{H}{x}_{}\\
		{}^{H}{y}_{}\\
	\end{pmatrix}
\end{equation}
${}^{H}\textbf{R}_{V}$ ist als Drehmatrix oder Rotationsmatrix genannt und ihre konkrete Beschreibung befindet sich in Gleichung~\ref{Gleichung:RotaionMatrix}. Darunter wird der Wert von $pos\_psi$ direkt für $\psi$ verwendet, da GCS und ACS immer in die gleiche Richtung zeigen. 
\begin{equation}
	\label{Gleichung:RotaionMatrix}
	{}^{H}\textbf{R}_{V} = 
	\begin{pmatrix}
		cos(\psi) & -sin(\psi)\\
		sin(\psi) & cos(\psi)\\
	\end{pmatrix}
\end{equation}
Der zweite Schritt ist die Umwandlung von HCS in ACS, die durch einfache Vektoraddition erhalten wird. Die mathematische Formel befindet sich in~\ref{Gleichung:HCS2ACS}. Analog bezeichnet ${}^{A}\textbf{P}_{}$ den Positionsvektor in ACS. Offset-Vektor D stellt die Abweichung von ACS und HCS dar, sodass kein bestimmtes Koordinatensystem angegeben werden muss.
\begin{equation}\label{Gleichung:HCS2ACS}
	{}^{A}\textbf{P}_{}={}^{H}\textbf{P}_{}+\textbf{D}
\end{equation}
mit
\begin{equation*}
	\textbf{D} = 
	\begin{pmatrix}
		offset\_x\\
		offset\_y\\
	\end{pmatrix}
\end{equation*} und \begin{equation*}
	{}^{A}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{A}{x}_{}\\
		{}^{A}{y}_{}\\
	\end{pmatrix}
\end{equation*}
Zusammenfassend kann die x-Koordinate und die y-Koordinate des Punktes im ACS unter Verwendung der Gleichungen~\ref{Gleichung:XinACS} bzw. \ref{Gleichung:YinACS} berechnet werden.
\begin{equation}\label{Gleichung:XinACS}
	{}^{A}{x}_{}=cos(\psi)\times{}^{V}{x}_{}-sin(\psi)\times{}^{V}{y}_{}+offset\_x
\end{equation}
\begin{equation}\label{Gleichung:YinACS}
	{}^{A}{y}_{}=sin(\psi)\times{}^{V}{x}_{}+cos(\psi)\times{}^{V}{y}_{}+offset\_y
\end{equation}
Funktionsblock $Range~Filter$ in Abbildung~\ref{fig:PAP_PCL} handelt sich um, dass alle Punkte von Punktwolken außer Erfassungsbereich bzw. Umfeldmodelldimension ausgefiltert werden. In Übereinstimmung mit dem IfF-Framework verfügt die Umfeldmodell bzw. Rasterkarte über 400$\times$400 Gitterzellen. Jede Gitterzelle ist 0,25 m$\times$0,25 m groß, daher wird auch die Auflösung der Rasterkarte als 0,25 m bezeichnet. In diesem Fall werden alle erfasste Punkte herausgefiltert, deren x- oder y-Koordinate 100 m im ACS-Koordinatensystem überschreitet. Natürlich werden auch die Anzahl der Gitterzellen und die Auflösung der Karte so parametrisiert, dass sie sich entsprechend den tatsächlichen Anwendungsanforderungen ändern können. Durch das Anordnen des Funktionsblocks $Range~Filter$ vor der Kartierung des Hindernis können unnötige Daten im Voraus verworfen und nutzlose Berechnungen vermieden werden.
\\Obwohl das Umfeldmodell in dieser Arbeit ein zweidimensionales Occupancy Grid Map ist, enthält die vom Ibeo-Laserscanner erhaltene Punktwolke tatsächlich dreidimensionale Informationen. Daher hat es die Höheninformationen des Punktes $z$. Im Funktionsblock $Height~Fitler$ ist die zu erkennende Höhe begrenzt und zu hohe oder zu niedrige Daten werden herausgefiltert. Dies kann erstens die abnormalen Punktwolkeninformationen beseitigen und zweitens die Anzahl von Punktwolken unterschiedlicher Höhe an derselben Stelle verringern, wodurch die Berechnungslast verringert wird. Der Grund liegt daran, dass der Beitrag von Punktwolken am selben Ort und in unterschiedlichen Höhen zum 2D-Umfeldmodell gleich und redundant ist. 
\\Im Funktionsblock $Map~PCL~to~grid$ wird die Punktwolke in den diskretisierten Gitterzellen weiter abgebildet. In der Implementierung wird ein zweistelliges 400$\times$400-Array erstellt, und jedes ihrer Gitterzelle hat einen Index in x- und y-Richtung. Jede Punktwolkeninformation wird durch Gleichung~\ref{Gleichung:Index_X} und~\ref{Gleichung:Index_Y} in einen Gitterindex umgewandelt, wobei dieses Gitter als belegt markiert wird. Im Rahme dieser Arbeit wird das Ergebnis in einem zweidimensionalen Array namens $pcl_grid$ gespeichert.
\begin{equation}
	\label{Gleichung:Index_X}
	Index\_x\approx {}^{A}{x}_{}/GS
\end{equation}
\begin{equation}
	\label{Gleichung:Index_Y}
	Index\_y\approx {}^{A}{y}_{}/GS
\end{equation}
In der Gleichungen ist GS (Grid Spacing) die Auflösung der Rasterkarte. Die Rundung in den Gleichungen bedeutet, dass die berechneten Daten abgerundet werden, bevor sie als Indexparameter verwendet werden können. Darüber hinaus hat das wiederholte Markieren eines Quadrats keine Auswirkung.
\subsubsection{Synchronization der Sensordaten}
\label{Synchronization der Sensordaten}
Unterschiedliche Sensordaten stammen aus in ROS unterschiedlichen Kanälen bzw. Themen. Die Sicherstellung der Zeitsynchronisation dieser Daten ist für die Echtzeitgenauigkeit des Modells sehr wichtig. Beispielsweise bleiben die Sensorinformationen von Lidar hinter den Informationen von GPS zurück, was dazu führt, dass die Hindernisinformationen um das Fahrzeug nicht rechtzeitig aktualisiert werden und das Modell daher ungenau ist. In ROS wird jede Informationsfreigabe von einem Zeitstempel (engl. timestamp) begleitet. Der $ApproximateTime~Policy$ Algorithmus in der Bibliothek (engl. library) von $message\_filters$ wird verwendet, um sicherzustellen, dass die Zeitstempel von Sensorinformationen aus verschiedenen Datenquellen sehr nahe oder fast gleich sind, z. B. 10 Femtosekunde (fs). Informationen, die diesen Schwellenwert überschreiten, werden als ungültig betrachtet und verworfen. Dieses Verfahren stellt nicht nur die Synchronisation von Informationen sicher, sondern kann auch die aktuellen Rahmendaten filtern, wenn eine bestimmte Datenquelle abnormal ist, wodurch die Genauigkeit der Daten sichergestellt wird.
\subsection{Implementierung von Occupancy Grid Map}
Nach der Einführung von Koordinatensystemen und der Beschreibung der Sensordatenverarbeitung wird in diesem Abschnitt der Kern des Modells, die Implementierung von Occupancy Grid Map, erläutert. Sie umfasst die Implementierung von 2 Ebenen, wie in Abbildung~\ref{fig:EbeneVonOccupancyGrid} dargestellt.
\subsubsection{Raumdiskretisierung}
Auf dieser Ebene wird die Umgebung um die Fahrzeug diskretisiert und als 2D-Rasterkarte beschrieben. Im ersten Schritt werden die Länge und Breite des Erfassungsbereichs bestimmt, und im zweiten Schritt wird die Auflösung der Rasterkarte bzw. die Größe jeder Gitterzelle festgestellt. Daraus ergibt sich die Anzahl der Zelle im gesamten Modell. Diese Werte sind parametrisiert und bieten eine Schnittstelle für nachfolgende Änderungen gemäß verschiedenen Anwendungsszenarien. Im Rahme dieser Arbeit wird das Umfeldmodell zur Anpassung an das IfF-Framework als 400$\times$400-Gitter beschrieben, wobei jede Gitterzelle 0,1$\times$0,1 Quadrat ist. Dies bedeutet, dass der Fahrzeugerkennungsbereich eine Fläche von 40 x 40 m beträgt. Es ist sehr natürlich, ein zweidimensionales Array in C++ zu verwenden, um dieses Raster zu beschreiben, das eine bestimmte Zelle im Raum direkt indizieren und den entsprechenden zusätzlichen Wert lesen kann. Hierbei werden zwei zweidimensionale Arrays erstellt, nämlich $current\_grid$ und Verlauf $history\_grid$. Ersteres wird verwendet, um die vom inversen Sensormodell erhaltenen Wahrscheinlichkeitsverteilungen zu speichern, nämlich $p(m_i|z_t)$ in Gleichung~\ref{Gleichung:Ableitung_06}. Letzteres wird verwendet, um die historisch akkumulierten A-posteriori-Wahrscheinlichkeit nach der Bayes-Filterung zu speichern, die in Gleichung~~\ref{Gleichung:Ableitung_06} als $p(m_i|z_{1:t-1})$ bezeichnet wird. Im aktuellen Frame wird der berechnete $bel_t(m_i)$ als Daten im $hitory\_grid$ des nächsten Frames verwendet.
\subsubsection{Probabilistischer Ansatz}
\label{Probabilistischer Ansatz}
Der erste Schritt in dieser Ebene ist die Zuweisung von $current\_grid$, bei der die aktuelle Belegungswahrscheinlichkeit jeder Zelle gemäß den Sensorinformationen ermittelt wird. Dies bedeutet, dass die Implementierung des in Abschnitt~\ref{Abschnitt:Das zu verwendende Sesormodell} genannten inversen Sensormodells. Wie in Abschnitt~\ref{Abschnitt:Das zu verwendende Sesormodell} erwähnt, wird das in dieser Arbeit verwendete Sensormodell durch zwei eindimensionale abschnittsweise definierte Funktionen beschrieben und für einen einzelnen Strahl verwendet. Die verschiedenen Lichtstrahlen, die von jedem Sensor emittiert werden, werden von demselben Modell beschrieben. 
\\Der Implementierungsalgorithmus kann durch das in Abbildung~\ref{fig:ImplementierungDesSensormodells} gezeigte Flussdiagramm dargestellt werden.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/ImplementierungDesSensormodells.pdf}
	\caption{Implementierung des inversen Sensormodells}
	\label{fig:ImplementierungDesSensormodells}
\end{figure}
Hier werden zwei Schleifen verwendet. Die äußere Schleife repräsentiert die Behandlung verschiedener Laserscanner am Fahrzeug. Die Zahl $laser\_num$ repräsentiert die Anzahl der Sensoren im Fahrzeug. Die innere Schleife bezeichnet die Verarbeitung verschiedener emittierter Lichtstrahlen von einem einzelnen Sensor. Dabei ist $beam\_num$ die Anzahl dieser Strahlen ist, die durch Dividieren des horizontalen Öffnungswinkels des Laserscanners durch die horizontale Winkelauflösung erreicht wird.
\\Der Funktionsblock $Calculate~position~of~laser~i~in~ACS$ dient zur Bestimmung der Ortskoordinaten des Laserscanners, dessen ID $i$ ist. Die Positionsinformationen des Sensors als Eingabeparameter des Umfeldmodell werden mit dem Fahrzeugkoordinatensystem als Referenzsystem angegeben. Die Erstellung des Umfeldmodell basiert auf dem Ankerkoordinatensystem, daher müssen die Koordinaten der Sensorposition auch in ACS bestimmt werden. Das Wesentliche dieses Problems ist immer noch das in Abschnitt~\ref{Laserscanner-Information} erwähnte Problem der Konvertierung von VCS in ACS, daher wird die Erörterung hierbei nicht wiederholt.
\\Den Zellen in Strahlrichtung werden je nach Abstand zum Laserscanner unterschiedliche Wahrscheinlichkeitswerte im Funktionsblock $Probability~distribution$ zugeordnet. Als eine Linie wird der eindimensionale Strahl vom berühmten Bresenham-Algorithmus
realisiert. Wie in Abbildung~\ref{fig:Raycasting} gezeigt, wird beispielsweise der aktuell verarbeitete Lichtstrahl durch eine blaue durchgezogene Linie dargestellt. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Raycasting.pdf}
	\caption{Raycasting mit Bresenham-Algorithmus}
	\label{fig:Raycasting}
\end{figure}
Der rote Punkt zeigt die aktuelle Position des zu verarbeitenden Sensors an und dient als Startpunkt des Strahls. Der schwarze Punkt repräsentiert die Position des Objekts und dient als Ende des Strahls. Unter Anwendung von dem Bresenham-Algorithmus werden die Zellen, denen tatsächlich Wahrscheinlichkeitswerte zugewiesen werden, grau dargestellt. Der grün gestrichelte Teil stellt den Bereich dar, den der Sensor scannen kann. Die grüne gestrichelte Linie stellt den Bereich dar, den der Sensor scannen kann. In diesem Bereich wird in verschiedene Richtungen durch die oben erwähnte innere Schleife mit dem Schritt von der Winkelauflösung abgetastet. Dies wird auch als Raycasting bezeichnet. In Bezug auf den spezifischen Wahrscheinlichkeitswert haben die Elemente von $current\_grird$, das den Zellen entspricht, die in dem in Abschnitt~\ref{Laserscanner-Information} genannten $pcl\_grid$ als belegt markiert sind, den Wert von $p\_fill$. Wird beispielsweise die Position $(3, 4)$ von $pcl\_grid$ als belegt markiert, wird der Wert $p\_fill$ dem Element $(3, 4)$ des Arrays von $current\_grid$ zugewiesen. Den Zellen innerhalb des minimal erkennbaren Abstands wird $p\_clear$ zugewiesen. Die Wahrscheinlichkeitsverteilung der in der Mitte bestehenden Zellen  werden durch eine lineare Funktion dargestellt, und ihre Steigung wird durch eine Variable $p\_slope$ dargestellt. Der Sensor erkennt, dass sich an einem bestimmten Ort ein Hindernis befindet, oder der Sensor liefert die Information, dass sich kein Hindernis befindet. Diese beiden Situationen weisen eine unterschiedliche Genauigkeit auf. Die Variable $p\_clear$ und $p\_fill$ sind jeweils ein Indikator für die Genauigkeit dieser beiden Situationen. Die Variable $p\_slope$ verkörpert, wie weit die Sensordaten von der Entfernung zwischen dem Objekt und dem Laserscanner beeinflusst werden. Die oben genannten drei Variablen müssen entsprechend den tatsächlichen Anwendungen und Szenarien sowie den Eigenschaften und der Qualität der verwendeten Sensoren angepasst werden. Anderen Zellen in der Karte wird ein Wahrscheinlichkeitswert von $50\%$ als Bereiche zugewiesen, die vom Sensor nicht erkannt werden können.
\\Nach Abschluss der Zuweisung aller Elemente im $current\_grid$ besteht der nächste Schritt in dieser Ebene darin, den binären Bayes-Filter zu verwenden, um die Belegungswahrscheinlichkeit jeder Zelle vom aktuellen Zeitstempel zu aktualisieren. Hierbei wird das Array $history\_grid$ verwendet, um die Belegungswahrscheinlichkeiten des letzten Zeitstempels zu speichern. Der Berechnungsprozess wird durch Gleichung~\ref{Gleichung:Ableitung_06} realisiert. Für jede Zelle repräsentiert der Term $p(m_i|z_t)$ den in $current\_grid$ gespeicherten Wert und der Term $p(m_i|z_{1:t-1})$ den in $history\_grid$ gespeicherten Wert. Der berechnete Term $bel_t(m_i)$ wird als der Wert in $history\_grid$ des nächsten Zeitstempels verwendet. Es ist erwähnenswert, dass jedem Element von $history\_grid$ im Ausgangszustand $50\%$ zugewiesen werden, da keine Vorkenntnisse über die Umgebung vorliegen. Bevor der binäre Bayes-Filter angewendet wird, muss außerdem überprüft werden, ob die Karte verschoben wurde. Wenn der Ort der Karte bzw. der Ankerpunkt nicht mit dem Ort des vorherigen Zeitstempels übereinstimmt, muss das Array $history\_grid$ entsprechend der Bewegungsrichtung und dem Schritt der Bewegung aktualisiert werden. Wie in Abbildung~\ref{fig:MoveOfMap} gezeigt, wird ein 16$\times$16-Raster verwendet, um dieses Problem zu veranschaulichen. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/MoveOfMap.pdf}
	\caption{Aktualisierung vom Array $Hisotry\_grid$ aufgrund der Verschiebung der Karte}
	\label{fig:MoveOfMap}
\end{figure}
Der obere Teil der Abbildung zeigt die Karte mit dem Zeitstempel t und der untere Teil zeigt die verschobene Karte mit dem Zeitstempel t + 1. In der oberen linken Ecke, der unteren rechten Ecke und der Mitte dieser Karte befinden sich Hindernisse, die durch schwarze Quadrate gekennzeichnet sind. Gleichzeitig wird ein 16$\times$16-Array erstellt und Wahrscheinlichkeitswerte zugewiesen. Es wird angenommen, dass zum Zeitpunkt $t+1$ die Karte $4$ Zellen nach rechts verschoben hat. Dann entspricht der Bereich, der durch Elemente dargestellt wird, deren x im neuen $history\_array$ gleich $0$ bis $11$ ist, dem Bereich, der durch Elemente von $4$ bis $15$ im alten $history\_grid$ dargestellt wird. Die grün markierten Bereiche werden im Modell nicht mehr berücksichtigt. Im rot angezeigten Bereich sind keine Sensordaten zu diesem Zeitpunkt vorhanden sind. Daher sollten die Elemente in diesem Bereich mit einem Wahrscheinlichkeitswert von $50\%$ initialisiert werden. Der eigentliche Prozess muss die vier Bewegungsrichtungen und Bewegungsentfernungen berücksichtigen.
\subsection{Zusätzliche Features}
Nach der Erstellung des Umfeldmodells werden dem System einige zusätzliche Funktionen für die spätere Erweiterung und den Informationsaustausch mit anderen Systemen hinzugefügt.
\subsubsection{Ausgangsinformationsfluss}
Am Ausgang des Systems sind, wie in Abbildung~\ref{fig:OutputFluss} dargestellt, zwei wichtige Ausgabedaten geplant. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/OutputFluss.pdf}
	\caption{Ausgangsinformationsfluss}
	\label{fig:OutputFluss}
\end{figure}
Die erste besteht darin, das Array auszugeben, das Occupancy Grid Map im aktuellen Modell darstellt. Jedes Element des Arrays hat seine Belegungswahrscheinlichkeit. Aufgrund der Eigenschaften des ROS-message ist das Ausgabearray ein eindimensionales Array. Daher muss in diesem Schritt das im System vorhandene zweidimensionale Array in ein eindimensionales Array eingekapselt werden. In einem anderen ROS-node, der die Daten empfängt, können das wieder in ein zweidimensionales Array umgerechnet werden. Zu diesem Zweck muss die Größe jeder Dimension des Arrays angegeben werden. Da die Wahrscheinlichkeitsgenauigkeit von $1\%$ ausreichend ist, ist die jeder Zelle zugewiesene Wahrscheinlichkeit eine Ganzzahl zwischen 0 und 100. In diesem Fall wird das Array aufgrund Speicherbedarf als Uint8-Datentyp erstellt. Die Variable $if\_publish$ wird verwendet, um zu entscheiden, ob die Ros-message im entsprechenden Ros-topic geliefert werden soll.
\\Die zweite ausgegebene Information wird verwendet, um sie in einer verwandten ROS-topic zur Visualisierung in ROS-Rviz zu liefern. Der Parameter $display\_mode$ legt fest, wie das umfeldmodell visualisiert wird. Wie in Abschnitt~\ref{Visualisierung des Umfeldmodells in ROS} erwähnt, umfassen die Visualisierungstypen $Gridcell$ und $binarized~Gridcells$.
\subsubsection{Visualisierung des Fahrzeugs}
Die Bestimmung der räumlichen Position des vom Fahrzeug abgedeckten Bereichs im Modell ist nicht Teil des Umgfeldmodells, aber hilfreich für die spätere kollisionsfreie Navigation. Gleichzeitig trägt die Visualisierung dieses Bereichs zur Vollständigkeit der Umfeldmodellvisualisierung bei. Um den vom Fahrzeug abgedeckten Bereich zu beschreiben, wird gemäß den Daten in Tabelle~\ref{tab:Abmessung von Versuchsfahrzeuge} und der Position des Ursprungs des Fahrzeugkoordinatensystems ein Rechteck erstellt, das den Fahrzeugbereich abdeckt. Dann wird das Rechteck in Punkte diskretisiert, um eine Punktwolke zu bilden. Wie die Position der Punktwolke von VCS in ACS umrechnet und dann kartiert wird, wurde in Abschnitt~\ref{Laserscanner-Information} erläutert. In ähnlicher Weise kann das Fahrzeug auch durch einige nahe gelegene Zellen dargestellt werden, die mittels einer einzigen ROS-topic in ROS-Rviz visualisiert werden können. Das tatsächliche Visualisierungsergebnis sind in Abbildung~\ref{fig:Display_Map} als den blauen Bereich dargestellt.
\subsubsection{Visualisierung von Bewegungspfaden}
Für die Bedürfnisse der nachfolgenden Navigation wird im Rahmen dieser Arbeit auch die Visualisierung des Bewegungspfades realisiert. Die Aufgabe besteht darin, eine Funktion zu kapseln, deren Eingabeparameter einen Vektor der UTM-Koordinatenpositionen des Fahrzeugs ist.  Entsprechend den Parametern dieses Vektors wird der durch diese Positionen bestimmte Pfad visualisiert. Unter dem ROS-System wird $nav::path$ für die Implementierung verwendet. Die Pose des Fahrzeugs wird hier als Parameter eingeführt. Da der Winkel von $nav::path$ durch die Quaternion bestimmt wird, muss hierbei zusätzlich ein Algorithmus zur Konvertierung vom Gierwinkel in die Quaternion verwendet werden. Da keine Planungsdaten in dieser Arbeit für die Navigation vorhanden sind, werden die vom Fahrzeug zurückgelegten Pose-Informationen aufgezeichnet und als Parameter an die Funktion zur Visualisierung des Pfades übergeben. Das tatsächliche Ergebnis ist in Abbildung~\ref{fig:path} dargestellt. 
\begin{figure}[p]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/path.pdf}
	\caption{Visualisierung von Bewegungspfaden}
	\vspace{10in}
	\label{fig:path}
\end{figure}
Diese Funktion kann als Werkzeug verwendet werden, das während der tatsächlichen Pfadplanung aufgerufen wird.
