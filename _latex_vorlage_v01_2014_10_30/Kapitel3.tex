\section{Implementierung}
\label{Kapitel:Implementierung}
Basierend auf den theoretischen Grundlagen von Kapitel~\ref{Kapitel:Theoretische Grundlagen} liegt der Schwerpunkt dieses Kapitels auf der tatsächlichen Implementierung des Umfeldmodells in~\ac{ROS}. Darüber hinaus werden einige Features für die Erweiterung des System oder die Integration von anderen Funktionen hinzugefügt.

\subsection{Versuchsfahrzeug}
Bevor mit der Implementierung des in Kapitel~\ref{Kapitel:Theoretische Grundlagen} entwickelten Umfeldmodells begonnen wird, werden die relevanten Informationen über das Versuchsfahrzeug mitsamt die darin eingebauten Sensoren dokumentiert und in der eigentlichen Implementierung parametriert.
\subsubsection{Dimension über Versuchsfahrzeug}
\label{Abschnitt:DimensionVonAuto}
Bei Implementierung im Rahmen dieser Arbeit ist es auch bedeutungsvoll, die Position bzw. den belegten Raum des Versuchsfahrzeugs zu modellieren und dokumentieren, was einen konkreten Beitrag zur kollisionsfrei Navigation leistet. Außerdem ist die Information über die Anordnung der Lasersensoren eng verbunden mit der Abmessung des Fahrzeugs. Daher wird die Dimension des Fahrzeugs als ein wichtiges Element betrachtet. Die Abbildung~\ref{fig:DimensionVonAuto} zeigt, dass die wichtige Größen von Abmessung des Fahrzeugs parametriert werden. Obwohl die Zeichnungsbemaßung eigentlich redundant ist, wird sie mit Absicht angewendet, um die Darstellung der wichtigen Größen sichtbar zu machen. Der Rot Punkt bezeichnet hierbei die Koordinatenursprung des Fahrzeugkoordinatensystem und befindet sich mittig auf der Hinterachse~\citep{Hegerhorst.2018}. Die X-Achse des Fahrzeugkoordinatensystem zeigt die Längsrichtung des Fahrzeugs nach vorne~\citep{Hegerhorst.2018}. Die Y-Achse verläuft senkrecht zur X-Achse und zeigt nach links des Fahrtrichtung. Die Koordinatenursprung dient als ein Bezugspunkt und die Größen, z.B. die Einbauposition eines Sensors sowie die Position eines detektierten Objekts, werden nur relativ zu dem Bezugssystem bzw. Fahrzeugkoordinatensystem angegeben. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/DimensionVonAuto.pdf}
	\caption{Dimension von Versuchsfahrzeug}
	\label{fig:DimensionVonAuto}
\end{figure}
\\In \ac{IfF} stehen Golf7 (TIAMO) und Passat Alltrack (TEASY 3) als Versuchsfahrzeuge zur Verfügung\citep{Hegerhorst.2018}. Die der Abbildung~\ref{fig:DimensionVonAuto} entsprechenden Abmessungen von diesen Versuchsfahrzeugen werden in Tabelle~\ref{tab:Abmessung von Versuchsfahrzeuge} aufgelistet.
\begin{table}[ht]
	\caption{Abmessung von Versuchsfahrzeuge}
	\label{tab:Abmessung von Versuchsfahrzeuge}
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Abmessung} & \textbf{Golf 7 (TIAMO)} & \textbf{Passat (TEASY 3)}\\
		\hline
		L & $4.3$ & $4.6$\\
		\hline
		W & $1.8$ & $1.6$\\
		\hline
		D2F & $3.5$ & $3.6$\\
		\hline
		D2E & $0.8$ & $1.0$\\
		\hline
		D2L & $0.9$ & $0.8$\\
		\hline
		D2R & $0.9$ & $0.8$\\
		\hline
	\end{tabular}
\end{table}
\subsubsection{Einbauposition der Ibeo-Laserscanner}
Die Anzahl und die Anordnung der im Versuchsfahrzeug installierten Laserscanner dienen auch als wichtigen Parametern bei der Implementierung, denn diese Informationen liefern den Startpunkt des Strahls jedes Sensors. In Abbildung~\ref{fig:AnordnungDerLaserscanner} sind die Einbauposition und der Erfassungsbereich jedes Sensors dargestellt. Dazu werden die tatsächlichen Werte in Tabelle~\ref{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei TIAMO} und Tabelle~\ref{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat} gegeben. In den Tabellen bezeichnet x die x-Koordinate im Fahrzeugkoordinatensystem und y die y-Koordinate. Der Winkel $\theta$ beschreibt die ausgesandte Richtung des Anfangsstrahls. Der Anfangsstrahl jedes Laserscanners ist gegen den Uhrzeigersinn zur Endstrahl. Der Winkelbereich des Erfassungsraum des Sensors ist nach der Tabelle~\ref{tab:technische Details von Ibeo LUX} auf $110^\circ$ begrenzt. Dieser Wert wird in der Praxis entsprechend der Performance des Umfeldmodells angepasst.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/AnordnungDerLaserscanner.pdf}
	\caption{Einbauposition und Erfassungsbereich der Laserscanner~\citep{Hegerhorst.2018}}
	\label{fig:AnordnungDerLaserscanner}
\end{figure}
\begin{table}[ht]
	\caption{Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Golf 7 (TIAMO))}
	\label{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei TIAMO}
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Sensor ID} & \textbf{x (m)} & \textbf{y (m)} & \textbf{Winkel $\theta$ des Anfangsstrahls ($^\circ$)}\\
		\hline
		1 & $3$ & $-0.9$ & $-10$\\
		\hline
		2 & $3$ & $0.9$ & $80$\\
		\hline
		3 & $-0.7$ & $0.9$ & $170$\\
		\hline
		4 & $-0.7$ & $-0.9$ & $-100$\\
		\hline
	\end{tabular}
\end{table}
\begin{table}[ht]
	\caption{Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat (TEASY 3)}
	\label{tab:Werte der Einbauposition und des Winkels des Anfangsstrahls jedes Sensors bei Passat}
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Sensor ID} & \textbf{x (m)} & \textbf{y (m)} & \textbf{Winkel $\theta$ des Anfangsstrahls ($^\circ$)}\\
		\hline
		1 & $3.3$ & $-0.8$ & $-35$\\
		\hline
		2 & $3.6$ & $0$ & $45$\\
		\hline
		3 & $3.3$ & $0.8$ & $125$\\
		\hline
		4 & $-0.5$ & $0.8$ & $145$\\
		\hline
		5 & $-1$ & $0$ & $-135$\\
		\hline
		6 & $-0.5$ & $-0.8$ & $-55$\\
		\hline
	\end{tabular}
\end{table}
\subsection{Framework ROS zur Implementierung}
Eine der zentralen Aufgaben dieser Arbeit handelt sich um die Konvertierung von dem am \ac{IfF} bereits bestehenden MATLAB/Simulink-Modell nach~\ac{ROS}. \ac{ROS} ist ein Framework zum Schreiben von Robotersoftware. Es handelt sich um eine Sammlung von Tools, Bibliotheken und Konventionen, die darauf abzielen, die Erstellung komplexer und robuster Roboterverhalten auf einer Vielzahl von Roboterplattformen zu vereinfachen\citep{Quigley.2015}. Obwohl diese Idee aus dem Bereich der Robotik stammt, machen ihre verschiedenen guten Eigenschaften ihre Investition in den Bereich des autonomen Fahrens sehr bedeutsam. Um eine klare Programmstruktur und eine genaue und effiziente Umsetzung des in Kapitel~\ref{Kapitel:Theoretische Grundlagen} genannten Umfeldmodells zu erhalten, ist eine kurze Einführung in die ROS-Grundlagen und Funktionsmodule in Bezug auf diesen Artikel erforderlich.
\subsubsection{Grundlagen der ROS-Architektur}
Die ROS-Architektur, die in Abbildung~\ref{fig:ROS-Architektur} dargestellt, wurde entworfen und in drei Abschnitte bzw. Konzeptebenen unterteilt, welche sich um die Dateisystemebene (engl. \emph{The Filesystem level}), die Berechnungsdiagrammebene (engl. \emph{The Computation Graph level}) und die Community-Ebene (engl. \emph{The Community level}) handeln~\citep{Fernandez.2015}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{pics/ROS-Architektur.pdf}
	\caption{ROS-Architektur}
	\label{fig:ROS-Architektur}
\end{figure}
\\Auf der Dateisystemebene wird eine Gruppe von Konzepten verwendet, um zu erklären, wie ROS intern gebildet wird. Ähnlich wie bei einem Betriebssystem ist ein ROS-Programm in Ordner unterteilt, und diese Ordner enthalten Dateien, die ihre Funktionen beschreiben~\citep{Fernandez.2015}. Hierbei sind die wichtigen Konzepte zu diesem Artikel \emph{Package} und \emph{Metapackage}. Das \emph{Package} ist die zentrale und grundlegende Dateiorganisationseinheit, die Programmierfunktionen in ROS vollständig realisieren kann. Es enthält im Allgemeinen ROS Laufzeitprozess (engl. \emph{runtime process}), Quellcode (engl. \emph{Sourcecode}), Konfigurationsdateien (engl. \emph{configuration files}) und das \emph{Package-manifest}, das zur Bereitstellung von Informationen von \emph{build dependencies}, \emph{run dependencies} und Lizenz verwendet wird. \emph{Metapackages} werden in der Regel nach einer ähnlichen Funktionalität gruppiert. Andere Grundkonzepte und Begriffe auf dieser Ebene sind aufgrund der Länge des Artikels nicht detailliert und finden sich in~\citep{Fernandez.2015}\citep{Koubaa.2016}.
\\Die Berechnungsdiagrammebene ist die relevanteste Ebene für diese Arbeit, auf der die Kommunikation zwischen Prozessen und Systemen stattfindet. Die Grundkonzepte auf dieser Ebene sind, wie in Abbildung~\ref{fig:Berechnungsdiagrammebene} dargestellt, \emph{Node}, \emph{ROS Master}, \emph{Parameter Server}, \emph{Message}, \emph{Topic}, \emph{Service} und \emph{ROS Bag}, die alle Daten auf unterschiedliche Weise für das Programm bereitstellen~\citep{Fernandez.2015}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Berechnungsdiagrammebene.pdf}
	\caption{Wichtige Grundkonzepte von Berechnungsdiagrammebene~\citep{Fernandez.2015}}
	\label{fig:Berechnungsdiagrammebene}
\end{figure}
\emph{Nodes} sind ausführbare Dateien (engl. \emph{executables}) in ROS und vervollständigen die erwartete Funktion und die zugehörigen Berechnungen. Die \emph{Nodes} können miteinander kommunizieren und Daten übertragen. Daher gibt es im Allgemeinen mehrere \emph{Nodes} in einem System, die unterschiedliche Funktionen ausgeführt haben. Der Datenaustausch zwischen \emph{Nodes} erfolgt über \emph{Messages}. ROS verwendet eine vereinfachte \emph{Message}-Beschreibungssprache, um Datentypen zu beschreiben, die von \emph{Nodes} publiziert (engl. \emph{published})~\citep{Fernandez.2015}. Damit kann ROS den richtigen Quellcode für diese \emph{Message}-Typen in mehreren Programmiersprachen (z.B. C++ oder Python) generieren. Zahlreiche vordefinierte \emph{Messages} in ROS können direkt zum Übertragen von Daten oder zum Erstellen neuer aufgabenorientierter \emph{Messages} verwendet werden. Dies erfolgt durch Definieren einer Datei mit \emph{.msg}-Extension. Wenn ein \emph{Node} Daten aussendet, heißt es, dass das \emph{Node} eine \emph{Topic} publizieren. Ein anderer \emph{Node} kann die \emph{Topic} abonnieren (engl. \emph{subscribe}), um die Daten abzurufen. Ein \emph{Node} kann eine \emph{Topic} nur abonnieren, wenn es denselben \emph{Message}-Typ hat. Eine \emph{Topic} kann verschiedene \emph{Subsribers} und auch verschiedene \emph{Publishers} haben. Wenn die Kommunikation zwischen \emph{Nodes} Empfang und Antwort (engl. \emph{receive and reply}) werden muss, sollten \emph{Services} anstelle von \emph{Topic} verwendet werden. \emph{Services} geben den Entwicklern die Möglichkeit, mit \emph{Nodes} zu interagieren. Mit \emph{Parameter Server} ist es möglich, Schlüssel (engl. \emph{keys}) zu verwenden, um Parameter an einem zentralen Ort zu speichern und Parameter während der Ausführung von \emph{Node} zu konfigurieren~\citep{Fernandez.2015}. Die oben genannte Kommunikation garantiert \emph{ROS Master}, der jede \emph{Node} verwalten. \emph{Nodes} werden zuerst beim \emph{Master} registriert, und dann integriert der \emph{Master} \emph{Nodes} in das gesamte ROS-Programm. Auf diesem Grund besteht der erste Schritt darin, den \emph{Master} zu starten, wenn das ROS-Programm gestartet wird. \emph{ROS Bag} ist ein Format zum Speichern und Wiedergeben aller Informationen der \emph{Messages}, \emph{Topics} und \emph{Services}, die gewünscht werden. In dieser Arbeit wird \emph{ROS Bag} verwendet, um die Sensordaten von dem Versuchsfahrzeug zu speichern. Wenn das \emph{ROS Bag} wiedergegeben ist, simuliert es die Datenwerte von Sensoren zu messen und erfassen, was ist praktisch zum Debuggen von Implementierungsalgorithmus.
\\Die Konzepte auf ROS-Community-Ebene sind die ROS-Ressourcen, die es separaten Communities ermöglichen, Software und Wissen auszutauschen~\citep{Fernandez.2015}. Zu den Ressourcen gehören unter anderem \emph{ROS Repositories}, \emph{ROS Distributions} und \emph{ROS Wiki}. Jedoch hat diese Ebene für diese Arbeit nur eine sehr geringe Relevanz. Aus diesem Grund ist die Auseinandersetzung damit im Rahmen dieser Arbeit zu verzichten.
\\Aufgrund des oben erwähnten Mechanismus und der Philosophie von ROS hat der Aufbau der Implementierung des Umfeldmodells in ROS einen starken Vorteil. Die dezentrale Kommunikationsmethode macht das Implementierungssystem klarer und einfacher. Außerdem sind Fehler im System leichter zu finden und sortieren. Die Aufteilung zwischen verschiedenen Funktionen erleichtert die spätere Systemerweiterung, z.B. Navigation bzw. kollisionsfreie Pfadplanung. Im Rahmen dieser Arbeit ist für die Implementierung \emph{ROS Kinetic Kame} mit \emph{Ubuntu 16.04 (Xenial)} in Benutzung.
\subsubsection{Visualisierung des Umfeldmodells in ROS}
\label{Visualisierung des Umfeldmodells in ROS}
Die Visualisierung des Umfeldmodells ist ebenso wichtig wie seine Entwicklung und Implementierung. Eine gute Visualisierung spiegelt den tatsächlichen Betriebszustand und die Performanz des Modells hervorragend wider. Dies hilft bei der Behebung von Programmfehlern und beim Datenaustausch mit anderen Funktionsmodulen oder Modellen im nachfolgenden Systemerweiterungsprozess. \ac{ROS} bietet eine Vielzahl von Tools zur Datenvisualisierung und zum Debuggen. Das wichtigste und am weitesten verbreitete ist \emph{Rviz}. \emph{Rviz} ist ein 3D-Visualisierungswerkzeug von ROS, mit dem Sensordaten und Statusinformationen visualisiert werden. \emph{Rviz} unterstützt umfangreiche Datentypen, die durch Laden verschiedener Display-Typen visualisiert werden. Jeder Display hat einen eindeutigen Namen. Wichtige Display-Typen und ihre entsprechenden \emph{Message}-Typen im Bereich des autonomen Fahrens sind in Tabelle~\ref{tab:RVIZ Display-Typen} aufgeführt. Aufgrund der Philosophie des verteilten Software-Frameworks von ROS muss das \emph{Rviz}-Visualisierungstool nur den passenden \emph{Message}-Typ und die passende \emph{Topic} auswählen, wenn Daten auf einer \emph{Topic} visualisiert werden sollen.
\begin{table}[ht]
	\caption{Display-Typen und ihre entsprechenden \emph{Message}-Typen in \emph{Rviz}}
	\label{tab:RVIZ Display-Typen}
	\small
	\centering
	%\setlength\tabcolsep{2pt}
	\begin{tabular}{|c|c|c|}
		
		\hline
		\textbf{Display-Typ} & \textbf{\emph{Message}-Typ} & \textbf{Beschreibung}\\
		\hline
		Grid Cells & nav\_msgs/GridCells & Zellen aus einem Raster\\
		\hline
		Point Cloud 2 & sensor\_msgs/PointCloud2 & Daten aus einer Punktwolke\\
		\hline
		Map & nav\_msgs/OccupancyGrid & eine Karte in der Grundebene\\
		\hline
		Path & nav\_msgs/Path & ein Pfad\\
		\hline
		Pose & geometry\_msgs/PoseStamped & eine 3D-Pose\\
		\hline
		Pose Array & geometry\_msgs/PoseArray &mehrere Posen\\
		\hline
		Image & sensor\_msgs/Image & ein neues Rendering-Bild\\
		\hline
		Laser Scan & sensor\_msgs/LaserScan & Daten von einem Laserscan\\
		\hline
		Odometry & nav\_msgs/Odometry & Kilometerzähler-Posen aus der Zeit\\
		\hline
		TF & tf2\_msgs/TFMessage & die Koordinatentransformation\\
		\hline
	\end{tabular}
\end{table}
\\Für das Umfeldmodell gibt es zwei grundlegende Visualisierungsoptionen. Zum einen ist Display-Typ \emph{Map}, den \emph{Message}-Typ \emph{nav\_msgs/OccupancyGrid} anzeigt. Die Variablen in \emph{nav\_msgs/OccupancyGrid} umfassen die Positionskoordinaten des Kartenankerpunkts, die Auflösung sowie die Länge und Breite der Karte und die Kartendaten (engl. \emph{Map data}) in jeder Gitterzelle. \emph{Map data} werden in zwei Situationen betrachtet. Einer ist, dass der Belegungszustand unbekannt ist und der Wert in diesem Fall -1 ist. Die andere ist, dass die Wahrscheinlichkeit der Belegung bekannt ist und der Wert in diesem Fall 0 bis 100 beträgt. Wie in Abbildung~\ref{fig:Display_Map} gezeigt, wenn \emph{Map data} von einer Gitterzelle $-1$ ist, wird die Zellenfläche ausgegraut dargestellt. Wenn \emph{Map data} von $0$ auf $100$ steigt, verändert sich die entsprechende Zelle in einem Farbverlauf von Weiß zu Schwarz.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Display_Map.pdf}
	\caption{Display mit Map}
	\label{fig:Display_Map}
\end{figure}
\\Die zweite Möglichkeit der Visualisierung eines Umfeldmodells in \emph{Rviz} ist die Verwendung von \emph{GridCells}.  Die Daten von \emph{Topic} mit \emph{Message}-Typ \emph{nav\_msgs/GridCells} sind dabei dargestellt. Darin handelt sich um die Informationen über die Länge und Breite sowie die Koordinaten jeder Zelle. \emph{GridCells}-Display ist nur für die Visualisierung des vom Entwickler angegebenen Bereichs verantwortlich. Es ist von der Belegungswahrscheinlichkeit getrennt und wird einfach, leicht und flexibel. Je nach Aufgabe des Entwicklers oder Debugging-Anforderungen können unterschiedliche Wahrscheinlichkeitsbereiche angezeigt werden. Darüber hinaus ermöglicht es einen starken Kontrast von Farben mit unterschiedlichen Belegungswahrscheinlichkeiten. Im Gegensatz dazu ist die Graustufendarstellung von dem oben erwähnten \emph{Map} nicht offensichtlich und für die Programmentwicklung und die Erkennung der Datenkorrektheit nicht geeignet. Ein Anwendungsbeispiel besteht darin, wie in Abbildung~\ref{fig:Display_GridCell} gezeigt, Gitterzellen mit unterschiedlichen Belegungswahrscheinlichkeiten in verschiedenen \emph{Topics} zu organisieren und dann die verschiedenen \emph{Topics} mit verschiedenen offensichtlichen Farben zu visualisieren. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Display_GridCell.pdf}
	\caption{Display mit \emph{GridCells}}
	\label{fig:Display_GridCell}
\end{figure}
Neben der Flexibilität bietet \emph{GridCells}-Display einige gute Vorteile gegenüber \emph{Map}-Display. Zunächst kann die jeder Gitterzelle zugewiesenen zusätzlichen Informationstypen und -werten selbst definiert werden, was eine direktere Bedingung für die zukünftige Erweiterung und Verbesserung des Modells darstellt. Selbst wenn nur die Belegungswahrscheinlichkeit zu berücksichtigen ist, kann die Wahrscheinlichkeit (0 bis 100) als Ganzes betrachtet werden, anstatt den Wert -1 allein zu verwenden bzw. umrechnen, um das Unbekannte auszudrücken. Darüber hinaus erleichtert die Verwendung von \emph{GridCells}-Display die anschließende Binärisierung von Werten und Bildern. Wie in Abbildung~\ref{fig:Dispaly_Grid_Cell_Binary} gezeigt, kann die Binärisierung durch Einstellen des Schwellenwerts, der durch Experimente oder Deep-Learning erhalten wurde, leicht erzielt werden. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Dispaly_Grid_Cell_Binary.pdf}
	\caption{Display mit \emph{GridCells} nach Binärisierung}
	\label{fig:Dispaly_Grid_Cell_Binary}
\end{figure}
Daher im Rahmen dieser Arbeit wird \emph{GridCells}-Display verwendet, um eine Visualisierung zu erreichen. Es gibt aber ein kleines Problem, das bei der Verwendung von \emph{GridCells} besondere Aufmerksamkeit und Lösung erfordert. Durch tatsächliche Experimente ist bekannt, dass bei sehr großen Positionskoordinaten von \emph{GridCells} (z. B. 10 bis 6 Potenzen) die Darstellung von Gitterzellen in \emph{Rviz} deformiert wird oder sogar verschwindt. Daher können bei der Implementierung des Modells die vom GPS erhaltenen UTM-Koordinateninformationen nicht direkt als Koordinaten für die Anzeige der Gitterzellen verwendet werden. Vor der eigentlichen Visualisierung werden zwei Abweichungen \emph{X\_VISUAL\_OFFSET} und \emph{Y\_VISUAL\_OFFSET} so eingestellt, dass der Koordinatenwert der Zellen nahe am Ursprung liegt, wodurch die Genauigkeit der Visualisierung sichergestellt wird. Dieses Abweichungspaar wird durch die anfänglichen Fahrzeugkoordinateninformationen bestimmt, die bei der Initialisierung des Modells erhalten werden, was sich in der nächsten Erläuterung des Funktionsblocks widerspiegelt.

\subsection{Koordinatensysteme}
Daten von verschiedenen Informationsquellen bzw. Sensoren sind häufig mittels unterschiedlichen Koordinatensystemen gegeben. Aus diesem Grund wird die Konvertierung zwischen verschiedenen Koordinatensystemen bei der Realisierung des Umfeldmodells oft durchgeführt. Hierbei gibt es 3 wesentliche Koordinatensysteme, deren Klärung für das Verständnis der nachfolgenden Funktionsbausteine dieser Arbeit sehr hilfreich ist. Wie in Abbildung~\ref{fig:Koordinaten3} gezeigt, sind diese 3 Koordinatensysteme Weltkoordinatensystem (engl. \emph{Global Coordinate System}, als \ac{GCS} abgekürzt), Ankerkoordinatensystem (engl. \emph{Anchor Coordinate System}, als \ac{ACS} abgekürzt) und Fahrzeugkoordinatensystem (engl. \emph{Vehicle Coordinate System}, als \ac{VCS} abgekürzt).
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Koordinaten3.pdf}
	\caption{3 wesentliche Koordinatensysteme im Umfeldmodell}
	\label{fig:Koordinaten3}
\end{figure}
\subsubsection{\ac{GCS}}
\label{Abschnitt:GCS}
Das Weltkoordinatensystem ist das grundlegendste Koordinatensystem. Die vom GPS-Sensor erhaltenen Informationen zur Fahrzeugpose basieren auf dem Weltkoordinatensystem. Im tatsächlichen Gebrauch sind dafür zwei Umrechnungen erforderlich. Das erste ist die Notwendigkeit, die Abweichung zwischen dem Ursprung des Fahrzeugkoordinatensystems (der Mitte der Hinterachse des Fahrzeugs) und dem tatsächlichen Standort der GPS-Antenne (einer bestimmten Position auf dem Dach) zu kompensieren. Außerdem ist die Beschreibung bzw. die Berechnung der geographischen Koordinaten mittels UTM-Koordinatensystem (engl. \emph{Universal Transverse Mercator coordinate system}) notwendig. Diese beiden Berechnungen werden nach~\citep{Hegerhorst.2018} im Vorverarbeitungsprozess unter Verwendung einiger Algorithmen vom \ac{IfF} abgeschlossen und werden hier nicht ausführlich erläutert. Außerdem ist das UTM-Koordinatensystem tatsächlich  ein nordweisendes, rechtsdrehendes Koordinatensystem. Jedoch wird nachher in Abschnitt~\ref{Abschnitt:GPS-Information} in ein gebräuchliches, linksdrehendes Koordinatensystem umgerechnet. Im Rahmen dieser Arbeit beziehen sich die Koordinaten im Weltkoordinatensystem auf die verarbeitete bzw. umgerechnete  UTM-Koordinateninformationen.
\subsubsection{\ac{VCS}}
In Abbildung~\ref{fig:Koordinaten3} wird das blaue Rechteck verwendet, um das Fahrzeug einfach darzustellen. Wie in Abschnitt~\ref{Abschnitt:DimensionVonAuto} erwähnt, liegt der Ursprung des Fahrzeugkoordinatensystems in der Mitte der Hinterachse des Fahrzeugs. Die X-Achse des VCS zeigt die Längsrichtung des Fahrzeugs nach vorne. Die Y-Achse verläuft senkrecht zur X-Achse und zeigt nach links des Fahrtrichtung. In dieser Arbeit sind die Punktwolkenpositionsinformationen des Laserscanners die mittels VCS angegebenen Originaldaten. Darüber hinaus erfordert die Darstellung des vom Fahrzeug abgedeckten Raums auch die Hilfe von Fahrzeugkoordinatensystem. Hierbei ist zu beachten, dass die Koordinateninformation der Punktwolke jedes Laserscanners tatsächlich auf dem unabhängigen Koordinatensystem jedes Laserscanners basiert. Unter dem bestehenden Rahmen von \ac{IfF} wird jedoch die Umrechnung zwischen jedem Sensorkoordinatensystem und dem Fahrzeugkoordinatensystem somit die Kombinierung aller Sensordaten während der Vorverarbeitung abgeschlossen. Schließlich wird in Form von \emph{ROS Bag} die Punktwolken aller Sensoren basierend auf den Koordinateninformationen des Fahrzeugkoordinatensystems bereitgestellt.

\subsubsection{\ac{ACS}}
Basierend auf den vorherigen Erfahrungen in ~\citep{Weiss.1306200715062007}~\citep{Pieringer.2013} ist Ankerkoordinatensystem ein Koordinatensystem, das bei der Diskretisierung des Raums hilft. Aufgrund des Speicherbedarfs und der Performanz ist es unmöglich und auch unnötig, Informationen über eine sehr große Umgebung aufzuzeichnen und zu aktualisieren. Daher ist ein Wahrnehmungsbereich des Fahrzeugs, wie das schwarze Quadrats in Abbildung~\ref{fig:Koordinaten3} geplant. Dieser Wahrnehmungsbereich befindet sich im umgebenden Raum des Fahrzeugs und bewegt sich mit der Änderung der Positionsinformationen des Fahrzeugs. Um die Position und Größe des Bereichs vollständig anzuzeigen, wird neben der Länge und Breite des Bereichs auch ein Ankerpunkt benötigt. Normalerweise wird dieser Ankerpunkt in der unteren linken Ecke des Wahrnehmungsbereichs eingerichtet. Das mit diesem Ankerpunkt als Ursprung festgelegte Koordinatensystem wird als Ankerkoordinatensystem bezeichnet. Es ist jedoch anzumerken, dass dieses Koordinatensystem nur mit der Position des Fahrzeugs verschoben wird. Die Richtung seiner Koordinatenachse ändert sich nicht, da das rotierende Koordinatensystem Aliasing und geringe Qualität des Umfeldmodells verursacht~\citep{Weiss.1306200715062007}~\citep{Hegerhorst.2018}. Zusätzlich wird innerhalb dieses Bereichs der Raum in eine Gitterzelle diskretisiert, siehe Abbildung~\ref{fig:Diskretisierung der Umgebung}. Der Ursprung des ACS ist der Ausgangspunkt der in Abschnitt~\ref{Abschnitt:Gitterbasierte Modelle} erwähnten Diskretisierung und auch die Null-Stelle des Index. Außerdem zeigt Abbildung ~\ref{fig:Diskretisierung der Umgebung} die Grenzen des Fahrzeugstandorts auf der Karte. Wenn sich die Position des Fahrzeugs nicht wesentlich ändert, muss die Position des Ursprungs des ACS nicht jederzeit aktualisiert werden. Um den Fahrbereich des Fahrzeugs weiter einzuschränken, wird der Fahrbereich im Allgemeinen nach~\citep{Weiss.1306200715062007}~\citep{Hegerhorst.2018} als mittlerer Teil der Karte festgelegt. Wenn nur das Fahrzeug den Bereich verlässt, wird das ACS aktualisiert, wodurch sich der Rechenaufwand verringern. Darüber hinaus wird in dieser Arbeit der Grenzwert des Bereichs parametrisiert und als Schnittstelle für das spätere Verwendung und Weiterentwicklung bereitgestellt.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\textwidth]{pics/Diskretisierung der Umgebung.pdf}
	\caption{Anordnung der Position des Autos auf der Karte~\citep{Hegerhorst.2018}}
	\label{fig:Diskretisierung der Umgebung}
\end{figure}
\subsubsection{Zusammenhang zwischen Koordinatensystemen}
Zwischen den oben erläuterten Koordinatensystemen besteht ein Zusammenhang und die Umrechnung zwischen GCS, ACS und VCS gewinnt bei Implementierung des Umfeldmodells an großer Bedeutung. Wenn die x-Koordinate des Ankerpunkts \emph{anchor\_x} und die x-Koordinate des Fahrzeugs \emph{pos\_x} in GCS bekannt sind, wie in Abbildung~\ref{fig:Koordinaten3} gezeigt, kann die x-Koordinate des Fahrzeugs in ACS durch die Formel \emph{offset\_x}$=$\emph{pox\_x}-\emph{anchor\_x} erhalten werden. Dabei ist die Umrechnung auf der y-Achse ist analog zur x-Achse. 
\\Darüber hinaus gibt es zwei Punkte, die besondere Aufmerksamkeit erfordern. Das erste ist die Aktualisierung bzw. Initialisierung von ACS. Im Modell wird auch die Zeit diskretisiert, um sich an Computerberechnungen anzupassen. Zu jedem einzelnen Zeitpunkt wird das ACS getestet, ob es sich bewegte und daher aktualisiert werden muss. Dieser Prozess kann durch das in Abbildung~\ref{fig:ACS_Update} gezeigte Programmablaufdiagramm dargestellt werden. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{pics/ACS_Update.pdf}
	\caption{Programmablaufplan der Aktualisierung von ACS}
	\label{fig:ACS_Update}
\end{figure}
Dabei repräsentieren \emph{X\_1} und \emph{X\_2} jeweils die linke und rechte Grenze der X-Achse des grün befahrbaren Bereichs in Abbildung~\ref{fig:Diskretisierung der Umgebung}. \emph{Y\_1} und \emph{Y\_2} repräsentieren jeweils die unteren und oberen Grenzen des Bereichs. Außerdem geben \emph{dx} und \emph{dy} als positive Werte die Entfernung an, um die der Ursprung des ACS verschoben werden muss. Diese Werte sind so parametriert, dass sie je nach Anwendungsszenario jederzeit geändert werden können. Dabei beschreiben \emph{pox\_x}, \emph{pox\_y} und \emph{offset\_x}, \emph{offset\_y} die Position des Fahrzeugs im Weltkoordinatensystem und im Ankerkoordinatensystem. Der Kern des Algorithmus besteht darin, zu überprüfen, ob die Position des Fahrzeugs eine bestimmte Grenze überschritten hat, und sich entsprechend zu bewegen. Wenn beispielsweise \emph{offset\_x}$>$\emph{X\_2} gilt ist, bedeutet dies, dass die Position des Fahrzeugs die rechte Grenze des befahrbaren Bereichs berührt oder überschritten hat. In diesem Fall bewegt sich der Anker nach rechts, indem der Wert der x-Koordinate erhöht wird, sodass das Fahrzeug immer in der Mitte der Rasterkarte bleibt. Dieser ganze Prozess wird als Funktionsmodul mit der Bezeichnung \emph{Update ACS} betrachtet und zum Entwerfen der Initialisierung von ACS verwendet, wie in Abbildung~\ref{fig:InitializationOfACS} dargestellt. Die Initialisierung des ACS erfolgt gleichzeitig mit der Initialisierung des gesamten Umfeldmodells. Wenn gültige Fahrzeugpositionsinformationen erhalten werden, werden die Anfangskoordinaten des Fahrzeugs auch der Anfangsposition des Ankers zugewiesen, wodurch die Anzahl der Bewegungen des ACS verringert wird. Anschließend wird mit Hilfe vom Aktualisierungsmodul die Position des Ankers automatisch angepasst, bis sich die Fahrzeugposition innerhalb des eingestellten Fahrbereichs befindet.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/InitializationOfACS.pdf}
	\caption{Initialisierung von ACS}
	\label{fig:InitializationOfACS}
\end{figure}
\\Der zweite Punkt ist, dass Punktwolkeninformationen unter VCS in Koordinaten unter ACS umgerechnet werden müssen, da der Ausgangspunkt der Diskretisierung der Anker ist. Dieser Punkt wird nachstehend in Abschnitt~\ref{Laserscanner-Information} erläutert. 
\subsection{Verarbeitung von Sensordaten}
\label{Verarbeitung von Sensordaten}
Für das Umfeldmodell in dieser Arbeit sind die beiden wichtigsten Sensorinformationen GPS-Informationen von dGPS-Moduls und Hindernisinformationen von Laserscannern. Unter Verwendung des vorhandenen Frameworks und Algorithmus in \ac{IfF} werden GPS-Informationen in Form von UTM-Koordinaten angegeben. Wie in Kapitel~\ref{Kapitel:Theoretische Grundlagen} erwähnt, werden im Rahmen dieser Arbeit die beiden Themen Eigenlokalisierung und Umfeldmodellierung entkoppelt, und der Schwerpunkt liegt auf der Umfeldmodellierung. Daher wird hier in Hinsicht auf die Erfassung und Verarbeitung der Daten Laserscannern vertieft eingegangen.
\subsubsection{GPS-Information}
\label{Abschnitt:GPS-Information}
Die wesentliche Information, die GPS liefert, ist die Pose des Fahrzeugs, die die Positionsinformation \emph{pos\_x} mit \emph{pos\_y} und Orientierungsinformation $pos\_psi$ enthält. Hierbei ist aber zu beachten, dass das ausgewählte UTM-Koordinatensystem ein nordweisendes, rechtsdrehendes Koordinatensystem ist~\citep{Hegerhorst.2018}. Daher ist es bei der tatsächlichen Verarbeitung erforderlich, den Richtungswinkel in dem in Abschnitt~\ref{Abschnitt:GCS} erwähnten linksdrehendes Koordinatensystem GCS durch Berechnung mittels Formel~\ref{Gleichung:Richtungswinkel umrechnen} zu berechnen. Dabei bezeichnet \emph{car\_get\_psi} die ursprüngliche Datengröße des Fahrzeugrichtungswinkels. Diese Umrechnungsbeziehung kann durch Abbildung~\ref{fig:Richtungswinkel umrechnen} visuell dargestellt werden.
\begin{equation}\label{Gleichung:Richtungswinkel umrechnen}
	pos\_psy=-car\_get\_psi+90^\circ
\end{equation}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.26\textwidth]{pics/RichtungswinkelUmrechnen.pdf}
	\caption{Umrechnung des Orientierungswinkels in GCS}
	\label{fig:Richtungswinkel umrechnen}
\end{figure}
\subsubsection{Laserscanner-Information}
\label{Laserscanner-Information}
Die Daten von Ibeo-Laserscanner haben zwei Ausgabeformate. Eines sind Rohdaten, die auf einer Punktwolke basieren, und das andere sind Objektinformationen nach der Verarbeitung von Rohdaten. Die geometrische Form des Objekts ist ein Rechteck bzw. eine Box. Das vorhandene Framework in \ac{IfF} verwendet hauptsächlich Objektinformation, um ein Umfeldmodell bzw. eine Rasterkarte zu erstellen. In~\citep{Hegerhorst.2018} werden die Positions- und Größeninformationen von Objekten verwendet, gefolgt von Kartierung statischer Hindernisse. Wie in Abbildung~\ref{fig:KartierungMitObjekt} gezeigt, besteht der Kernschritt des Algorithmus darin, die Pose des Objekts in der Rasterkarte zu bestimmen, es als Punktwolkeninformation zu diskretisieren bzw. umzurechnen und schließlich die belegten Zellen zu markieren. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/KartierungMitObjekt.pdf}
	\caption{Kartierungsalgorithmus mit Objektinformation von Laserscanner~\citep{Hegerhorst.2018}}
	\label{fig:KartierungMitObjekt}
\end{figure}
Die Verwendung dieses Ansatzes weist jedoch mehrere Nachteile auf. Wie in Kapitel~\ref{Kapitel:Theoretische Grundlagen} erläutert, besteht einer der Vorteile der Verwendung des gitterbasierten Modells darin, dass es Hindernisse beliebiger Form beschreiben kann. Bei Verwendung der Objektinformationen werden Hindernisse in diesem Fall jedoch immer durch Rechtecke dargestellt, wodurch dieser Vorteil zunichte gemacht wird. Außerdem werden in tatsächlichen Anwendungen z. B. mehrere diskrete Punkte als kontinuierliches Hindernis falsch eingeschätzt. Außerdem werden die Scanpunkte langer gerader Objekte hart durch einer Box dargestellt und daher in kleinere Boxen aufgeteilt oder gar nicht nicht ausgegeben\citep{Hegerhorst.2018}.  Dies führt zu Ungenauigkeiten und geringer Qualität des Modells. Schließlich erfordert die Verwendung von Objektinformationen einen weiteren Schritt zur Umwandlung in eine Punktwolke, was den Rechenaufwand erhöht. Es ist effizient und natürlicher, die Punktwolkeninformationen des Laserscanners direkt zu verwenden.
\\Als nächstes wird die Verarbeitung von Punktwolkeninformationen mittels des in Abbildung~\ref{fig:PAP_PCL} gezeigte Flussdiagramm ausführlich erläutert.
\begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.28\textwidth]{pics/PAP_PCL.pdf}
 	\caption{Programmablaufplan der Laserscannerdaten}
 	\label{fig:PAP_PCL}
\end{figure}
Der Ibeo-Laserscanner liefert über den ROS-Treiber verschiedene Dateninformationen und publiziert diese zu den entsprechenden \emph{Topics}. Das wichtigste ist, dass \emph{Topic} \emph{as\_tx/point\_cloud} Information liefert, deren \emph{Message}-Typ \emph{sensor\_msgs/PointCloud2} ist. Es ist anzumerken, dass diese Daten tatsächlich mit Datentyp \textless \emph{pcl::PointXYZL}\textgreater~von \ac{PCL}-Standardbibliothek gekapselt und geliefert werden. Daher wird in der tatsächlichen Codeimplementierung Zeiger (engl. \emph{pointer}) verwendet, um die vier Beschreibungsinformationen der Punktwolke in \textless \emph{pcl::PointXYZL}\textgreater~zu lesen. Sie handelt sich um x-, y- und z-Koordinaten des Fahrzeugkoordinatensystems und der Schicht (engl. \emph{layer}), in der sich die Punktwolke befindet.
\\Im Versuchsfahrzeug Passat (siehe Abbildung~\ref{fig:AnordnungDerLaserscanner}) sind Sensor mit ID 2 und Sensor mit ID 5 mit Ibeo-LUX-8L ausgestattet. Die restlichen Laserscanner sind Ibeo-LUX-4L. Ibeo-LUX-8L wird tatsächlich durch die Drehung des Objektivs konstruiert, um den vertikalen Erfassungsbereich zu verdoppeln. Wenn es in Kombination mit Ibeo-LUX-4L verwendet wird, ist der Erfassungsbereich zu zwei benachbarten Zeitpunkten bei derselben Frequenz inkonsistent. Beispielsweise ist die bei Zeitpunkt $t_1$ erfasste Punktwolke nur in den Schichten $0$ bis $3$ verteilt, während die bei $t_2$ erfasste Punktwolke sich einschließlich in den Schichten 4 bis 7 befinden. Diese Inkonsistenz kann durch \bb{} die Korrektheit und die Stabilität des Modells beeinträchtigen. Aus diesem Grund wird im Funktionsblock \emph{Layes Filter} das Datenframe, das 4 bis 7 Schichten von Punktwolkeninformationen enthält, ausgefiltert. Diese Methode ist direkt und einfach und verbessert nachweislich die Stabilität des Modells.
\\Im Funktionsblock \emph{Change VCS to ACS} wird die im Fahrzeugkoordinatensystem vorliegende Position jedes Punkt von Punktwolke in Ankerkoordinatensystem umgerechnet. Um die Umrechnung durchzuführen, ist ein~\ac{HCS}, wie in Abbildung~\ref{fig:VCS2ACS} gezeigt, erstellt.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/VCS2ACS.pdf}
	\caption{Darstellung eines Hilfskoordinatensystem}
	\label{fig:VCS2ACS}
\end{figure}
Dann lässt sich die Koordinatenumwandlung in 2 Schritte zerlegen. Der erste Schritt besteht darin, das Referenzkoordinatensystem jedes Punktes von \ac{ACS} in \ac{HCS} umzuwandeln. Die mathematische Beschreibung dieses Schritts ist in Gleichung~\ref{Gleichung:RotaionTransform} gezeigt.
\begin{equation}\label{Gleichung:RotaionTransform}
	{}^{H}\textbf{P}_{}={}^{H}\textbf{R}_{V}~{}^{V}\textbf{P}_{}
\end{equation} 
Dabei bezeichnet ${}^{V}\textbf{P}_{}$ und ${}^{H}\textbf{P}_{}$ den Koordinatenvektor eines bestimmten Punktes in \ac{VCS} bzw. in \ac{HCS}. Die lassen sich mit~Gleichung~\ref{Gleichung:V_P} und~\ref{Gleichung:H_P} beschreiben. 
\begin{equation}
	\label{Gleichung:V_P}
	{}^{V}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{V}{x}_{}\\
		{}^{V}{y}_{}\\
	\end{pmatrix}
\end{equation}
\begin{equation}
	\label{Gleichung:H_P}
	{}^{H}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{H}{x}_{}\\
		{}^{H}{y}_{}\\
	\end{pmatrix}
\end{equation}
${}^{H}\textbf{R}_{V}$ ist als Drehmatrix bzw. Rotationsmatrix genannt und ihre konkrete Beschreibung befindet sich in Gleichung~\ref{Gleichung:RotaionMatrix}. Darunter wird der Wert von $pos\_psi$ direkt für $\psi$ verwendet, da \ac{GCS} und \ac{ACS} immer in die gleiche Richtung zeigen. 
\begin{equation}
	\label{Gleichung:RotaionMatrix}
	{}^{H}\textbf{R}_{V} = 
	\begin{pmatrix}
		cos(\psi) & -sin(\psi)\\
		sin(\psi) & cos(\psi)\\
	\end{pmatrix}
\end{equation}
Der zweite Schritt ist die Umwandlung von \ac{HCS} in \ac{ACS}, die durch eine einfache Vektoraddition erhalten wird. Die mathematische Formel befindet sich in~\ref{Gleichung:HCS2ACS}. Analog bezeichnet ${}^{A}\textbf{P}_{}$ den Positionsvektor in \ac{ACS}. Offset-Vektor \emph{D} stellt die Abweichung von \ac{ACS} und \ac{HCS} dar, sodass kein bestimmtes Koordinatensystem angegeben werden muss.
\begin{equation}\label{Gleichung:HCS2ACS}
	{}^{A}\textbf{P}_{}={}^{H}\textbf{P}_{}+\textbf{D}
\end{equation}
mit
\begin{equation*}
	\textbf{D} = 
	\begin{pmatrix}
		offset\_x\\
		offset\_y\\
	\end{pmatrix}
\end{equation*} und \begin{equation*}
	{}^{A}\textbf{P}_{} = 
	\begin{pmatrix}
		{}^{A}{x}_{}\\
		{}^{A}{y}_{}\\
	\end{pmatrix}
\end{equation*}
Zusammenfassend können die x-Koordinate und die y-Koordinate des Punktes in \ac{ACS} unter Verwendung der Gleichungen~\ref{Gleichung:XinACS} bzw. \ref{Gleichung:YinACS} berechnet werden.
\begin{equation}\label{Gleichung:XinACS}
	{}^{A}{x}_{}=cos(\psi)\times{}^{V}{x}_{}-sin(\psi)\times{}^{V}{y}_{}+offset\_x
\end{equation}
\begin{equation}\label{Gleichung:YinACS}
	{}^{A}{y}_{}=sin(\psi)\times{}^{V}{x}_{}+cos(\psi)\times{}^{V}{y}_{}+offset\_y
\end{equation}
Funktionsblock \emph{Range~Filter} in Abbildung~\ref{fig:PAP_PCL} handelt sich um, dass alle Punkte von der Punktwolke außer Erfassungsbereich bzw. Umfeldmodelldimension ausgefiltert werden. In Übereinstimmung mit dem IfF-Framework verfügt die Umfeldmodell bzw. Rasterkarte über 400$\times$400 Gitterzellen. Jede Gitterzelle ist \emph{0,25m}$\times$\emph{0,25m} groß. Daher wird auch die Auflösung der Rasterkarte als \emph{0,25m} bezeichnet. In diesem Fall werden alle erfasste Punkte herausgefiltert, deren x- oder y-Koordinate \emph{100m} in ACS überschreitet. Natürlich werden auch die Anzahl der Gitterzellen und die Auflösung der Karte so parametrisiert, dass sie sich entsprechend den tatsächlichen Anwendungsanforderungen ändern können. Durch das Anordnen des Funktionsblocks \emph{Range~Filter} vor \emph{Map~PCL~to~grid} können unnötige Daten im Voraus verworfen und nutzlose Berechnungen vermieden werden.
\\Obwohl das Umfeldmodell in dieser Arbeit ein zweidimensionales \og{} ist, enthält die vom Ibeo-Laserscanner erhaltene Punktwolke tatsächlich dreidimensionale Informationen. Daher hat es die Höheninformationen des Punktes $z$. Im Funktionsblock \emph{Height~Fitler } ist die zu erfassende Höhe begrenzt und zu hohe oder zu niedrige Punkte werden herausgefiltert. Dies kann erstens die abnormalen Punktwolkeninformationen beseitigen und zweitens die Anzahl von Punktwolken unterschiedlicher Höhe an derselben Stelle auf der Karte verringern, wodurch die Berechnungslast verringert wird. Der Grund liegt daran, dass der Beitrag von der Punktwolke am selben 2D-Ort mit einer unterschiedlichen Höhen zum 2D-Umfeldmodell gleich und redundant ist. 
\\Im Funktionsblock \emph{Map~PCL~to~grid} wird die Punktwolke in den diskretisierten Gitterzellen weiter abgebildet. In der Implementierung wird ein zweidimensionales 400$\times$400-Array erstellt, und jedes Element von dem Array hat Indexe in X- und Y-Richtung. Jede Punktwolkeninformation wird durch Gleichung~\ref{Gleichung:Index_X} und~\ref{Gleichung:Index_Y} in einen Gitterindex umgewandelt, wobei dieses Gitter als belegt markiert wird. Im Rahmen dieser Arbeit wird das Ergebnis in einem zweidimensionalen Array namens \emph{pcl\_grid} gespeichert.
\begin{equation}
	\label{Gleichung:Index_X}
	Index\_x\approx {}^{A}{x}_{}/GS
\end{equation}
\begin{equation}
	\label{Gleichung:Index_Y}
	Index\_y\approx {}^{A}{y}_{}/GS
\end{equation}
In der Gleichungen ist \emph{GS (Grid Spacing)} die Auflösung der Rasterkarte. Die Rundung in den Gleichungen bedeutet, dass die berechneten Daten abgerundet werden müssen, bevor sie als Indexparameter verwendet werden können. Darüber hinaus hat das wiederholte Markieren einer Zeller keine Auswirkung.
\subsubsection{Synchronisation der Sensordaten}
\label{Synchronization der Sensordaten}
Unterschiedliche Sensordaten stammen aus in \ac{ROS} unterschiedlichen Kanälen bzw. \emph{Topics}. Die Sicherstellung der Zeitsynchronisation dieser Daten ist für die Echtzeitgenauigkeit des Modells sehr wichtig. Bleiben beispielsweise die Sensorinformationen von Lidar hinter den Informationen von GPS zurück, wird es dazu führen, dass die Hindernisinformationen um das Fahrzeug nicht rechtzeitig aktualisiert werden und das Modell daher ungenau ist. In \ac{ROS} wird jede Informationsübertragung von einem Zeitstempel (engl. \emph{timestamp}) begleitet. Der \emph{ApproximateTime~Policy} Algorithmus in der Bibliothek (engl. \emph{library}) von \emph{message\_filters} wird verwendet, um sicherzustellen, dass die Zeitstempel von Sensorinformationen aus verschiedenen Datenquellen sehr nahe oder fast gleich sind, z. B. 10 Femtosekunde (fs). Informationen, die diesen Schwellenwert überschreiten, werden als ungültig betrachtet und verworfen. Dieses Verfahren stellt nicht nur die Synchronisation von Sensordaten sicher, sondern kann auch die aktuellen Rahmendaten filtern, wenn eine bestimmte Datenquelle abnormal ist, wodurch die Genauigkeit der Daten sichergestellt wird.
\subsection{Implementierung von \og{}}
Nach der Einführung von Koordinatensystemen und der Beschreibung der Sensordatenverarbeitung wird in diesem Abschnitt der Kern des Modells, die Implementierung von \og{}, erläutert. Sie umfasst die Implementierung von 2 Ebenen, wie in Abbildung~\ref{fig:EbeneVonOccupancyGrid} dargestellt.
\subsubsection{Raumdiskretisierung}
In dieser Ebene wird die Umgebung um das Fahrzeug diskretisiert und als 2D-Rasterkarte beschrieben. Im ersten Schritt werden die Länge und Breite des Erfassungsbereichs bestimmt, und im zweiten Schritt wird die Auflösung der Rasterkarte bzw. die Größe jeder Gitterzelle festgestellt. Daraus ergibt sich die Anzahl der Zelle im gesamten Modell. Diese Werte sind parametrisiert und bieten eine Schnittstelle für nachfolgende Änderungen gemäß verschiedenen Anwendungsszenarien. Im Rahmen dieser Arbeit wird das Umfeldmodell zur Anpassung an das IfF-Framework als 400$\times$400-Gitter beschrieben, wobei jede Gitterzelle 0,1\emph{m}$\times$0,1\emph{m} Quadrat ist. Dies bedeutet, dass der Fahrzeugerkennungsbereich eine Fläche von 40\emph{m}$\times$400\emph{m} beträgt. Es ist sehr natürlich, ein zweidimensionales Array in C++ zu verwenden, um dieses Raster zu beschreiben, das eine bestimmte Zelle im Raum direkt indizieren und den entsprechenden zusätzlichen Wert ablesen kann. Hierbei werden zwei zweidimensionale Arrays erstellt, nämlich \emph{current\_grid} und \emph{history\_grid}. Ersteres wird verwendet, um die vom inversen Sensormodell erhaltenen Wahrscheinlichkeitsverteilungen zu speichern, nämlich $p(m_i|z_t)$ in Gleichung~\ref{Gleichung:Ableitung_06}. Letzteres wird verwendet, um die historisch akkumulierten A-posteriori-Wahrscheinlichkeit nach der Bayes-Filterung zu speichern, die in Gleichung~~\ref{Gleichung:Ableitung_06} als $p(m_i|z_{1:t-1})$ bezeichnet wird. Der berechnete $bel_t(m_i)$ wird als A-posteriori-Wahrscheinlichkeit im \emph{history\_grid} des nächsten Zeitpunkts verwendet.
\subsubsection{Probabilistischer Ansatz}
\label{Probabilistischer Ansatz}
Der erste Schritt in dieser Ebene ist die Zuweisung von \emph{current\_grid}, bei der die aktuelle Belegungswahrscheinlichkeit jeder Zelle gemäß den Sensordaten ermittelt wird. Dies bedeutet die Implementierung des in Abschnitt~\ref{Abschnitt:Das zu verwendende Sesormodell} genannten inversen Sensormodells. Wie in Abschnitt~\ref{Abschnitt:Das zu verwendende Sesormodell} erwähnt, wird das in dieser Arbeit verwendete Sensormodell durch zwei eindimensionale abschnittsweise definierte Funktionen beschrieben und für einen einzelnen Strahl verwendet. Die verschiedenen Lichtstrahlen, die von jedem Sensor emittiert werden, werden von demselben Modell beschrieben. 
\\Der Implementierungsalgorithmus kann durch das in Abbildung~\ref{fig:ImplementierungDesSensormodells} gezeigte Flussdiagramm dargestellt werden.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/ImplementierungDesSensormodells.pdf}
	\caption{Implementierung des inversen Sensormodells}
	\label{fig:ImplementierungDesSensormodells}
\end{figure}
Hier werden zwei Schleifen verwendet. Die äußere Schleife repräsentiert die Behandlung verschiedener Laserscanner am Fahrzeug. Die Zahl \emph{laser\_num} repräsentiert die Anzahl der Sensoren im Fahrzeug. Die innere Schleife bezeichnet die Verarbeitung verschiedener emittierter Lichtstrahlen von einem einzelnen Sensor. Dabei ist \emph{beam\_num} die Anzahl dieser Strahlen ist, die mit Hilfe vom Dividieren des horizontalen Öffnungswinkels des Laserscanners durch die horizontale Winkelauflösung erreicht wird.
\\Der Funktionsblock \emph{Calculate~position~of~laser~i~in~ACS} dient zur Bestimmung der Ortskoordinaten des Laserscanners, dessen ID $i$ ist. Die Positionsinformationen des Sensors als Eingabeparameter des Umfeldmodells werden angegeben, während das Fahrzeugkoordinatensystem als das Referenzsystem dient. Die Erstellung des Umfeldmodells basiert auf dem Ankerkoordinatensystem, daher müssen die Koordinaten der Sensorposition auch in ACS bestimmt werden. Das Wesentliche dieses Problems ist immer noch das in Abschnitt~\ref{Laserscanner-Information} erwähnte Problem der Konvertierung von VCS in ACS, daher wird die Erörterung hierbei nicht wiederholt.
\\Den Zellen in Strahlrichtung werden je nach Abstand zum Laserscanner unterschiedliche Wahrscheinlichkeitswerte im Funktionsblock \emph{Probability~distribution} zugeordnet. Als eine Linie wird der eindimensionale Strahl vom berühmten Bresenham-Algorithmus
realisiert. Wie in Abbildung~\ref{fig:Raycasting} gezeigt, wird beispielsweise der aktuell verarbeitete Lichtstrahl durch eine blaue durchgezogene Linie dargestellt. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/Raycasting.pdf}
	\caption{Raycasting mit Bresenham-Algorithmus}
	\label{fig:Raycasting}
\end{figure}
Der rote Punkt zeigt die aktuelle Position des zu verarbeitenden Sensors an und dient als Startpunkt des Strahls. Der schwarze Punkt repräsentiert die Position des Objekts und dient als Ende des Strahls. Unter Anwendung von dem Bresenham-Algorithmus werden die Zellen, denen tatsächlich Wahrscheinlichkeitswerte zugewiesen werden, grau dargestellt. Der grün gestrichelte Teil stellt den Bereich dar, den der Sensor scannen kann. In diesem Bereich wird in verschiedene Richtungen durch die oben erwähnte innere Schleife mit dem Schritt von der Winkelauflösung abgetastet. Dies wird auch als Raycasting bezeichnet. In Bezug auf den spezifischen Wahrscheinlichkeitswert haben die Elemente von \emph{current\_grird}, das den Zellen entspricht, die in dem in Abschnitt~\ref{Laserscanner-Information} genannten \emph{pcl\_grid} als belegt markiert sind, den Wert von \emph{p\_fill}. Wird beispielsweise die Position $(3, 4)$ von \emph{pcl\_grid} als belegt markiert, wird der Wert \emph{p\_fill} dem Element $(3, 4)$ des Arrays von \emph{current\_grird} zugewiesen. Den Zellen innerhalb des minimal erkennbaren Abstands wird \emph{p\_clear} zugewiesen. Die Wahrscheinlichkeitsverteilung der in der Mitte bestehenden Zellen  werden durch eine lineare Funktion dargestellt, und ihre Steigung wird durch eine Variable \emph{p\_slope} dargestellt. Der Sensor erkennt, dass sich an einem bestimmten Ort ein Hindernis befindet, oder der Sensor liefert die Information, dass sich kein Hindernis befindet. Diese beiden Situationen weisen eine unterschiedliche Genauigkeit auf. Die Variable \emph{p\_fill} und \emph{p\_clear} sind jeweils ein Indikator für die Genauigkeit dieser beiden Situationen. Die Variable \emph{p\_slope} verkörpert, wie weit die Sensordaten von der Entfernung zwischen dem Objekt und dem Laserscanner beeinflusst werden. Die oben genannten drei Variablen müssen entsprechend den tatsächlichen Anwendungen und Szenarien sowie den Eigenschaften und der Qualität der verwendeten Sensoren angepasst werden. Anderen Zellen in der Karte wird ein Wahrscheinlichkeitswert von $50\%$ als Bereiche zugewiesen, die vom Sensor nicht erkannt werden können.
\\Nach Abschluss der Zuweisung aller Elemente im  \emph{current\_grird} besteht der nächste Schritt in dieser Ebene darin, den \bb{} zu verwenden, um die Belegungswahrscheinlichkeit jeder Zelle mit dem aktuellen Zeitstempel zu aktualisieren. Hierbei wird das Array \emph{history\_grid} verwendet, um die Belegungswahrscheinlichkeiten des letzten Zeitstempels zu speichern. Der Berechnungsprozess wird durch Gleichung~\ref{Gleichung:Ableitung_06} realisiert. Für jede Zelle repräsentiert der Term $p(m_i|z_t)$ den in  \emph{current\_grird} gespeicherten Wert und der Term $p(m_i|z_{1:t-1})$ den in \emph{history\_grid} gespeicherten Wert. Der berechnete Term $bel_t(m_i)$ wird als der Wert in \emph{history\_grid} des nächsten Zeitstempels verwendet. Es ist erwähnenswert, dass jedem Element von \emph{history\_grid} im Ausgangszustand $50\%$ zugewiesen werden, da keine Vorkenntnisse über die Umgebung vorliegen. Bevor der \bb{} angewendet wird, muss außerdem überprüft werden, ob die Karte verschoben wurde. Wenn der Ort der Karte bzw. des Ankerpunkts nicht mit dem Ort des vorherigen Zeitstempels übereinstimmt, muss das Array \emph{history\_grid} entsprechend der Bewegungsrichtung und dem Schritt der Bewegung aktualisiert werden. Wie in Abbildung~\ref{fig:MoveOfMap} gezeigt, wird ein 16$\times$16-Raster verwendet, um dieses Problem zu veranschaulichen. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{pics/MoveOfMap.pdf}
	\caption{Aktualisierung vom Array \emph{history\_grid} aufgrund der Verschiebung der Karte}
	\label{fig:MoveOfMap}
\end{figure}
Der obere Teil der Abbildung zeigt die Karte mit dem Zeitstempel \emph{t} und der untere Teil zeigt die verschobene Karte mit dem Zeitstempel \emph{t+1}. In der oberen linken Ecke, der unteren rechten Ecke und der Mitte dieser Karte befinden sich Hindernisse, die durch schwarze Quadrate gekennzeichnet sind. Gleichzeitig wird ein 16$\times$16-Array erstellt und Wahrscheinlichkeitswerte zugewiesen. Es wird angenommen, dass zum Zeitpunkt \emph{t+1} die Karte $4$ Zellen nach rechts verschoben wurde. Dann entspricht der Bereich, der durch Elemente dargestellt wird, deren x im neuen \emph{history\_grid} gleich $0$ bis $11$ ist, dem Bereich, der durch Elemente von $4$ bis $15$ im alten \emph{history\_grid} dargestellt wird. Die grün markierten Bereiche werden im Modell nicht mehr berücksichtigt. Im rot angezeigten Bereich sind keine Sensordaten zu diesem Zeitpunkt vorhanden sind. Daher sollten die Elemente in diesem Bereich mit einem Wahrscheinlichkeitswert von $50\%$ initialisiert werden. Der eigentliche Prozess muss die vier Bewegungsrichtungen und Bewegungsentfernungen berücksichtigen.
\subsection{Zusätzliche Features}
Nach der Erstellung des Umfeldmodells werden dem System einige zusätzliche Funktionen für die spätere Erweiterung und den Informationsaustausch mit anderen Systemen hinzugefügt.
\subsubsection{Ausgangsinformationsfluss}
Am Ausgang des Systems sind, wie in Abbildung~\ref{fig:OutputFluss} dargestellt, zwei wichtige Ausgabedaten geplant. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/OutputFluss.pdf}
	\caption{Ausgangsinformationsfluss}
	\label{fig:OutputFluss}
\end{figure}
Die erste besteht darin, das Array auszugeben, das \og{} im aktuellen Modell darstellt. Jedes Element des Arrays hat seine Belegungswahrscheinlichkeit. Aufgrund der Eigenschaften des \emph{ROS Message} muss das Ausgabearray ein eindimensionales Array sein. Daher muss in diesem Schritt das im System vorhandene zweidimensionale Array in ein eindimensionales Array eingekapselt werden. In einem anderen \emph{ROS Node} , der die Daten empfängt, können das wieder in ein zweidimensionales Array umgerechnet werden. Zu diesem Zweck muss die Größe jeder Dimension des Arrays angegeben werden. Da die Wahrscheinlichkeitsgenauigkeit von $1\%$ ausreichend ist, ist die jeder Zelle zugewiesene Wahrscheinlichkeit eine Ganzzahl zwischen 0 und 100. In diesem Fall wird das Array aufgrund Speicherbedarf als Uint8-Datentyp erstellt. Die Variable \emph{if\_publish} wird verwendet, um zu entscheiden, ob die \emph{ROS Message} im entsprechenden \emph{ROS Topic} geliefert werden soll.
\\Die zweite ausgegebene Information wird verwendet, um die Daten in einer relevanten \emph{ROS Topic} zur Visualisierung in \emph{Rviz} zu liefern. Der Parameter \emph{display\_mode} legt fest, wie das umfeldmodell visualisiert wird. Wie in Abschnitt~\ref{Visualisierung des Umfeldmodells in ROS} erwähnt, umfassen die Visualisierungstypen \emph{GridCells} und \emph{binarized~GridCells}.
\subsubsection{Visualisierung des Fahrzeugs}
Die Bestimmung der räumlichen Position des vom Fahrzeug abgedeckten Bereichs im Modell ist nicht Teil des Umgfeldmodells, aber hilfreich für die spätere kollisionsfreie Navigation. Gleichzeitig trägt die Visualisierung dieses Bereichs zur Vollständigkeit der Umfeldmodellvisualisierung bei. Um den vom Fahrzeug abgedeckten Bereich zu beschreiben, wird gemäß den Daten in Tabelle~\ref{tab:Abmessung von Versuchsfahrzeuge} und der Position des Ursprungs des Fahrzeugkoordinatensystems ein Rechteck erstellt, das den Fahrzeugbereich abdeckt. Dann wird das Rechteck in Punkte diskretisiert, um eine Punktwolke zu bilden. Wie die Position der Punktwolke von VCS in ACS umrechnet und dann kartiert wird, wurde in Abschnitt~\ref{Laserscanner-Information} erläutert. Analog dazu kann das Fahrzeug auch durch einige nahe gelegene Zellen dargestellt werden, die mittels einer einzigen \emph{ROS Topic} in \emph{Rviz} visualisiert werden können. Das tatsächliche Visualisierungsergebnis sind in Abbildung~\ref{fig:Dispaly_Grid_Cell_Binary} als den blauen Bereich dargestellt.
\subsubsection{Visualisierung von Bewegungspfaden}
Für die Bedürfnisse der nachfolgenden Navigation wird im Rahmen dieser Arbeit auch die Visualisierung des Bewegungspfades realisiert. Die Aufgabe besteht darin, eine Funktion zu erstellen, deren Eingabeparameter eine Reihe bzw. ein Vektor von UTM-Koordinatenpositionen des Fahrzeugs ist. Entsprechend den Parametern dieses Vektors wird der durch diese Positionen bestimmte Pfad visualisiert. In \ac{ROS} wird \emph{Message}-Typ \emph{nav::path} für die Implementierung verwendet. Die Pose des Fahrzeugs wird hier als Parameter eingeführt. Da der Winkel von \emph{Message}-Typ \emph{nav::path} durch die Quaternion bestimmt wird, muss hierbei zusätzlich ein Algorithmus zur Konvertierung vom Gierwinkel in die Quaternion verwendet werden. Da keine Planungsdaten in dieser Arbeit für die Navigation vorhanden sind, werden die vom Fahrzeug zurückgelegten Pose-Informationen aufgezeichnet und als Parameter an die Funktion zur Visualisierung des Pfades übergeben. Das tatsächliche Ergebnis ist in Abbildung~\ref{fig:path} als eine grüne Linie dargestellt, bei dem die Wirksamkeit der Funktion überprüft werden kann. Diese Funktion kann als Werkzeug verwendet werden, das während der tatsächlichen Pfadplanung aufgerufen wird.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.6\textwidth]{pics/path.pdf}
	\caption{Visualisierung von Bewegungspfaden}
	\label{fig:path}
\end{figure}
